{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from rnn import MyRNNModelV1,MyDeepRNNModelV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22 samples, validate on 3 samples\n",
      "Epoch 1/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 400.2271 - val_loss: 572.8537\n",
      "Epoch 2/500\n",
      "22/22 [==============================] - 0s 185us/step - loss: 395.4757 - val_loss: 567.1197\n",
      "Epoch 3/500\n",
      "22/22 [==============================] - 0s 216us/step - loss: 390.9377 - val_loss: 561.4759\n",
      "Epoch 4/500\n",
      "22/22 [==============================] - 0s 183us/step - loss: 386.5044 - val_loss: 555.8918\n",
      "Epoch 5/500\n",
      "22/22 [==============================] - 0s 204us/step - loss: 382.1995 - val_loss: 550.3280\n",
      "Epoch 6/500\n",
      "22/22 [==============================] - 0s 171us/step - loss: 377.9889 - val_loss: 544.7446\n",
      "Epoch 7/500\n",
      "22/22 [==============================] - 0s 164us/step - loss: 373.7883 - val_loss: 539.1896\n",
      "Epoch 8/500\n",
      "22/22 [==============================] - 0s 187us/step - loss: 369.5401 - val_loss: 533.6431\n",
      "Epoch 9/500\n",
      "22/22 [==============================] - 0s 204us/step - loss: 365.4233 - val_loss: 527.9256\n",
      "Epoch 10/500\n",
      "22/22 [==============================] - 0s 157us/step - loss: 361.1177 - val_loss: 522.1170\n",
      "Epoch 11/500\n",
      "22/22 [==============================] - 0s 164us/step - loss: 356.8780 - val_loss: 516.1487\n",
      "Epoch 12/500\n",
      "22/22 [==============================] - 0s 203us/step - loss: 352.5622 - val_loss: 510.2068\n",
      "Epoch 13/500\n",
      "22/22 [==============================] - 0s 217us/step - loss: 348.0006 - val_loss: 504.4041\n",
      "Epoch 14/500\n",
      "22/22 [==============================] - 0s 168us/step - loss: 343.9669 - val_loss: 498.5811\n",
      "Epoch 15/500\n",
      "22/22 [==============================] - 0s 172us/step - loss: 339.3945 - val_loss: 492.9675\n",
      "Epoch 16/500\n",
      "22/22 [==============================] - 0s 187us/step - loss: 335.3063 - val_loss: 487.4248\n",
      "Epoch 17/500\n",
      "22/22 [==============================] - 0s 235us/step - loss: 331.1357 - val_loss: 481.9944\n",
      "Epoch 18/500\n",
      "22/22 [==============================] - 0s 196us/step - loss: 327.1442 - val_loss: 476.5027\n",
      "Epoch 19/500\n",
      "22/22 [==============================] - 0s 191us/step - loss: 322.9828 - val_loss: 470.9537\n",
      "Epoch 20/500\n",
      "22/22 [==============================] - 0s 209us/step - loss: 318.9354 - val_loss: 465.4267\n",
      "Epoch 21/500\n",
      "22/22 [==============================] - 0s 166us/step - loss: 314.7026 - val_loss: 459.9056\n",
      "Epoch 22/500\n",
      "22/22 [==============================] - 0s 210us/step - loss: 310.6572 - val_loss: 454.2659\n",
      "Epoch 23/500\n",
      "22/22 [==============================] - 0s 244us/step - loss: 306.3868 - val_loss: 448.5637\n",
      "Epoch 24/500\n",
      "22/22 [==============================] - 0s 161us/step - loss: 302.0847 - val_loss: 442.7041\n",
      "Epoch 25/500\n",
      "22/22 [==============================] - 0s 171us/step - loss: 298.0010 - val_loss: 436.7998\n",
      "Epoch 26/500\n",
      "22/22 [==============================] - 0s 253us/step - loss: 293.7132 - val_loss: 431.1143\n",
      "Epoch 27/500\n",
      "22/22 [==============================] - 0s 211us/step - loss: 289.5632 - val_loss: 425.8625\n",
      "Epoch 28/500\n",
      "22/22 [==============================] - 0s 179us/step - loss: 285.5307 - val_loss: 421.3479\n",
      "Epoch 29/500\n",
      "22/22 [==============================] - 0s 162us/step - loss: 282.0437 - val_loss: 417.4888\n",
      "Epoch 30/500\n",
      "22/22 [==============================] - 0s 323us/step - loss: 278.8606 - val_loss: 413.9971\n",
      "Epoch 31/500\n",
      "22/22 [==============================] - 0s 231us/step - loss: 275.9942 - val_loss: 410.7059\n",
      "Epoch 32/500\n",
      "22/22 [==============================] - 0s 169us/step - loss: 273.3498 - val_loss: 407.6229\n",
      "Epoch 33/500\n",
      "22/22 [==============================] - 0s 227us/step - loss: 270.7277 - val_loss: 404.7721\n",
      "Epoch 34/500\n",
      "22/22 [==============================] - 0s 176us/step - loss: 268.2383 - val_loss: 402.0565\n",
      "Epoch 35/500\n",
      "22/22 [==============================] - 0s 182us/step - loss: 265.7436 - val_loss: 399.3206\n",
      "Epoch 36/500\n",
      "22/22 [==============================] - 0s 222us/step - loss: 263.3651 - val_loss: 396.5427\n",
      "Epoch 37/500\n",
      "22/22 [==============================] - 0s 213us/step - loss: 260.7900 - val_loss: 393.7746\n",
      "Epoch 38/500\n",
      "22/22 [==============================] - 0s 206us/step - loss: 258.4987 - val_loss: 390.9138\n",
      "Epoch 39/500\n",
      "22/22 [==============================] - 0s 156us/step - loss: 255.9883 - val_loss: 387.9818\n",
      "Epoch 40/500\n",
      "22/22 [==============================] - 0s 346us/step - loss: 253.4754 - val_loss: 384.6996\n",
      "Epoch 41/500\n",
      "22/22 [==============================] - 0s 225us/step - loss: 250.9775 - val_loss: 380.6974\n",
      "Epoch 42/500\n",
      "22/22 [==============================] - 0s 157us/step - loss: 248.3836 - val_loss: 375.9559\n",
      "Epoch 43/500\n",
      "22/22 [==============================] - 0s 180us/step - loss: 245.6575 - val_loss: 370.5580\n",
      "Epoch 44/500\n",
      "22/22 [==============================] - 0s 215us/step - loss: 243.1479 - val_loss: 364.3840\n",
      "Epoch 45/500\n",
      "22/22 [==============================] - 0s 229us/step - loss: 240.3807 - val_loss: 357.5960\n",
      "Epoch 46/500\n",
      "22/22 [==============================] - 0s 260us/step - loss: 237.3138 - val_loss: 350.5624\n",
      "Epoch 47/500\n",
      "22/22 [==============================] - 0s 191us/step - loss: 234.1876 - val_loss: 344.1557\n",
      "Epoch 48/500\n",
      "22/22 [==============================] - 0s 221us/step - loss: 230.7479 - val_loss: 338.3686\n",
      "Epoch 49/500\n",
      "22/22 [==============================] - 0s 225us/step - loss: 226.9409 - val_loss: 332.9755\n",
      "Epoch 50/500\n",
      "22/22 [==============================] - 0s 218us/step - loss: 223.0385 - val_loss: 327.7473\n",
      "Epoch 51/500\n",
      "22/22 [==============================] - 0s 174us/step - loss: 219.8480 - val_loss: 322.8078\n",
      "Epoch 52/500\n",
      "22/22 [==============================] - 0s 213us/step - loss: 215.9693 - val_loss: 318.5321\n",
      "Epoch 53/500\n",
      "22/22 [==============================] - 0s 239us/step - loss: 213.0070 - val_loss: 314.6173\n",
      "Epoch 54/500\n",
      "22/22 [==============================] - 0s 178us/step - loss: 210.4421 - val_loss: 311.2394\n",
      "Epoch 55/500\n",
      "22/22 [==============================] - 0s 174us/step - loss: 207.5592 - val_loss: 308.4205\n",
      "Epoch 56/500\n",
      "22/22 [==============================] - 0s 171us/step - loss: 205.4870 - val_loss: 305.8251\n",
      "Epoch 57/500\n",
      "22/22 [==============================] - 0s 148us/step - loss: 203.4475 - val_loss: 303.4820\n",
      "Epoch 58/500\n",
      "22/22 [==============================] - 0s 304us/step - loss: 201.6387 - val_loss: 301.3206\n",
      "Epoch 59/500\n",
      "22/22 [==============================] - 0s 299us/step - loss: 200.0076 - val_loss: 299.2309\n",
      "Epoch 60/500\n",
      "22/22 [==============================] - 0s 260us/step - loss: 198.5398 - val_loss: 297.1348\n",
      "Epoch 61/500\n",
      "22/22 [==============================] - 0s 190us/step - loss: 197.0042 - val_loss: 295.1116\n",
      "Epoch 62/500\n",
      "22/22 [==============================] - 0s 211us/step - loss: 195.6124 - val_loss: 293.0885\n",
      "Epoch 63/500\n",
      "22/22 [==============================] - 0s 163us/step - loss: 194.1408 - val_loss: 291.1385\n",
      "Epoch 64/500\n",
      "22/22 [==============================] - 0s 242us/step - loss: 192.7761 - val_loss: 289.1500\n",
      "Epoch 65/500\n",
      "22/22 [==============================] - 0s 221us/step - loss: 191.4208 - val_loss: 287.1112\n",
      "Epoch 66/500\n",
      "22/22 [==============================] - 0s 163us/step - loss: 190.0167 - val_loss: 285.1906\n",
      "Epoch 67/500\n",
      "22/22 [==============================] - 0s 228us/step - loss: 188.6422 - val_loss: 283.3704\n",
      "Epoch 68/500\n",
      "22/22 [==============================] - 0s 186us/step - loss: 187.3716 - val_loss: 281.5650\n",
      "Epoch 69/500\n",
      "22/22 [==============================] - 0s 209us/step - loss: 186.1639 - val_loss: 279.7723\n",
      "Epoch 70/500\n",
      "22/22 [==============================] - 0s 161us/step - loss: 184.8712 - val_loss: 278.0414\n",
      "Epoch 71/500\n",
      "22/22 [==============================] - 0s 231us/step - loss: 183.7479 - val_loss: 276.2862\n",
      "Epoch 72/500\n",
      "22/22 [==============================] - 0s 171us/step - loss: 182.5203 - val_loss: 274.5661\n",
      "Epoch 73/500\n",
      "22/22 [==============================] - 0s 231us/step - loss: 181.3552 - val_loss: 272.8645\n",
      "Epoch 74/500\n",
      "22/22 [==============================] - 0s 219us/step - loss: 180.2134 - val_loss: 271.1367\n",
      "Epoch 75/500\n",
      "22/22 [==============================] - 0s 180us/step - loss: 179.0219 - val_loss: 269.3803\n",
      "Epoch 76/500\n",
      "22/22 [==============================] - 0s 257us/step - loss: 177.8087 - val_loss: 267.6006\n",
      "Epoch 77/500\n",
      "22/22 [==============================] - 0s 206us/step - loss: 176.5766 - val_loss: 265.7993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500\n",
      "22/22 [==============================] - 0s 177us/step - loss: 175.3555 - val_loss: 263.9630\n",
      "Epoch 79/500\n",
      "22/22 [==============================] - 0s 238us/step - loss: 174.1914 - val_loss: 262.1499\n",
      "Epoch 80/500\n",
      "22/22 [==============================] - 0s 160us/step - loss: 172.9854 - val_loss: 260.3985\n",
      "Epoch 81/500\n",
      "22/22 [==============================] - 0s 202us/step - loss: 171.7639 - val_loss: 258.7592\n",
      "Epoch 82/500\n",
      "22/22 [==============================] - 0s 156us/step - loss: 170.6121 - val_loss: 257.1475\n",
      "Epoch 83/500\n",
      "22/22 [==============================] - 0s 160us/step - loss: 169.5253 - val_loss: 255.4488\n",
      "Epoch 84/500\n",
      "22/22 [==============================] - 0s 179us/step - loss: 168.4043 - val_loss: 253.7283\n",
      "Epoch 85/500\n",
      "22/22 [==============================] - 0s 221us/step - loss: 167.2135 - val_loss: 252.0315\n",
      "Epoch 86/500\n",
      "22/22 [==============================] - 0s 162us/step - loss: 166.1713 - val_loss: 250.3371\n",
      "Epoch 87/500\n",
      "22/22 [==============================] - 0s 162us/step - loss: 165.0160 - val_loss: 248.7232\n",
      "Epoch 88/500\n",
      "22/22 [==============================] - 0s 207us/step - loss: 163.9321 - val_loss: 247.1239\n",
      "Epoch 89/500\n",
      "22/22 [==============================] - 0s 198us/step - loss: 162.8667 - val_loss: 245.5312\n",
      "Epoch 90/500\n",
      "22/22 [==============================] - 0s 158us/step - loss: 161.8373 - val_loss: 243.9284\n",
      "Epoch 91/500\n",
      "22/22 [==============================] - 0s 181us/step - loss: 160.7740 - val_loss: 242.3536\n",
      "Epoch 92/500\n",
      "22/22 [==============================] - 0s 199us/step - loss: 159.7325 - val_loss: 240.8316\n",
      "Epoch 93/500\n",
      "22/22 [==============================] - 0s 178us/step - loss: 158.7862 - val_loss: 239.3780\n",
      "Epoch 94/500\n",
      "22/22 [==============================] - 0s 161us/step - loss: 157.8345 - val_loss: 237.9958\n",
      "Epoch 95/500\n",
      "22/22 [==============================] - 0s 156us/step - loss: 156.9354 - val_loss: 236.6541\n",
      "Epoch 96/500\n",
      "22/22 [==============================] - 0s 190us/step - loss: 156.0567 - val_loss: 235.3375\n",
      "Epoch 97/500\n",
      "22/22 [==============================] - 0s 177us/step - loss: 155.1457 - val_loss: 234.0333\n",
      "Epoch 98/500\n",
      "22/22 [==============================] - 0s 176us/step - loss: 154.2431 - val_loss: 232.6673\n",
      "Epoch 99/500\n",
      "22/22 [==============================] - 0s 169us/step - loss: 153.3603 - val_loss: 231.2144\n",
      "Epoch 100/500\n",
      "22/22 [==============================] - 0s 208us/step - loss: 152.4637 - val_loss: 229.7200\n",
      "Epoch 101/500\n",
      "22/22 [==============================] - 0s 184us/step - loss: 151.4563 - val_loss: 228.2918\n",
      "Epoch 102/500\n",
      "22/22 [==============================] - 0s 148us/step - loss: 150.5776 - val_loss: 226.8878\n",
      "Epoch 103/500\n",
      "22/22 [==============================] - 0s 170us/step - loss: 149.6483 - val_loss: 225.5441\n",
      "Epoch 104/500\n",
      "22/22 [==============================] - 0s 207us/step - loss: 148.8304 - val_loss: 224.2135\n",
      "Epoch 105/500\n",
      "22/22 [==============================] - 0s 170us/step - loss: 147.9176 - val_loss: 222.9334\n",
      "Epoch 106/500\n",
      "22/22 [==============================] - 0s 161us/step - loss: 147.0703 - val_loss: 221.6937\n",
      "Epoch 107/500\n",
      "22/22 [==============================] - 0s 168us/step - loss: 146.3017 - val_loss: 220.4200\n",
      "Epoch 108/500\n",
      "22/22 [==============================] - 0s 226us/step - loss: 145.4488 - val_loss: 219.0905\n",
      "Epoch 109/500\n",
      "22/22 [==============================] - 0s 155us/step - loss: 144.5649 - val_loss: 217.7100\n",
      "Epoch 110/500\n",
      "22/22 [==============================] - 0s 268us/step - loss: 143.6942 - val_loss: 216.2994\n",
      "Epoch 111/500\n",
      "22/22 [==============================] - 0s 185us/step - loss: 142.8097 - val_loss: 214.8743\n",
      "Epoch 112/500\n",
      "22/22 [==============================] - 0s 197us/step - loss: 141.9353 - val_loss: 213.5015\n",
      "Epoch 113/500\n",
      "22/22 [==============================] - 0s 162us/step - loss: 141.0405 - val_loss: 212.1787\n",
      "Epoch 114/500\n",
      "22/22 [==============================] - 0s 193us/step - loss: 140.1657 - val_loss: 210.8693\n",
      "Epoch 115/500\n",
      "22/22 [==============================] - 0s 198us/step - loss: 139.3276 - val_loss: 209.5438\n",
      "Epoch 116/500\n",
      "22/22 [==============================] - 0s 183us/step - loss: 138.5354 - val_loss: 208.2495\n",
      "Epoch 117/500\n",
      "22/22 [==============================] - 0s 159us/step - loss: 137.6404 - val_loss: 206.9965\n",
      "Epoch 118/500\n",
      "22/22 [==============================] - 0s 402us/step - loss: 136.8958 - val_loss: 205.6367\n",
      "Epoch 119/500\n",
      "22/22 [==============================] - 0s 198us/step - loss: 136.0292 - val_loss: 204.2848\n",
      "Epoch 120/500\n",
      "22/22 [==============================] - 0s 163us/step - loss: 135.1475 - val_loss: 202.8972\n",
      "Epoch 121/500\n",
      "22/22 [==============================] - 0s 240us/step - loss: 134.2830 - val_loss: 201.5055\n",
      "Epoch 122/500\n",
      "22/22 [==============================] - 0s 193us/step - loss: 133.4676 - val_loss: 200.1350\n",
      "Epoch 123/500\n",
      "22/22 [==============================] - 0s 160us/step - loss: 132.5380 - val_loss: 198.7982\n",
      "Epoch 124/500\n",
      "22/22 [==============================] - 0s 177us/step - loss: 131.7431 - val_loss: 197.4075\n",
      "Epoch 125/500\n",
      "22/22 [==============================] - 0s 175us/step - loss: 130.8062 - val_loss: 196.0761\n",
      "Epoch 126/500\n",
      "22/22 [==============================] - 0s 169us/step - loss: 130.0194 - val_loss: 194.6820\n",
      "Epoch 127/500\n",
      "22/22 [==============================] - 0s 185us/step - loss: 129.1615 - val_loss: 193.2458\n",
      "Epoch 128/500\n",
      "22/22 [==============================] - 0s 231us/step - loss: 128.1791 - val_loss: 191.8098\n",
      "Epoch 129/500\n",
      "22/22 [==============================] - 0s 176us/step - loss: 127.3736 - val_loss: 190.3675\n",
      "Epoch 130/500\n",
      "22/22 [==============================] - 0s 223us/step - loss: 126.4430 - val_loss: 189.0422\n",
      "Epoch 131/500\n",
      "22/22 [==============================] - 0s 185us/step - loss: 125.6717 - val_loss: 187.7442\n",
      "Epoch 132/500\n",
      "22/22 [==============================] - 0s 191us/step - loss: 124.8695 - val_loss: 186.5259\n",
      "Epoch 133/500\n",
      "22/22 [==============================] - 0s 215us/step - loss: 124.0915 - val_loss: 185.3390\n",
      "Epoch 134/500\n",
      "22/22 [==============================] - 0s 171us/step - loss: 123.3385 - val_loss: 184.1538\n",
      "Epoch 135/500\n",
      "22/22 [==============================] - 0s 190us/step - loss: 122.5259 - val_loss: 182.9667\n",
      "Epoch 136/500\n",
      "22/22 [==============================] - 0s 165us/step - loss: 121.8364 - val_loss: 181.7448\n",
      "Epoch 137/500\n",
      "22/22 [==============================] - 0s 248us/step - loss: 121.0024 - val_loss: 180.6183\n",
      "Epoch 138/500\n",
      "22/22 [==============================] - 0s 225us/step - loss: 120.3279 - val_loss: 179.5227\n",
      "Epoch 139/500\n",
      "22/22 [==============================] - 0s 178us/step - loss: 119.5311 - val_loss: 178.4418\n",
      "Epoch 140/500\n",
      "22/22 [==============================] - 0s 164us/step - loss: 118.8474 - val_loss: 177.2868\n",
      "Epoch 141/500\n",
      "22/22 [==============================] - 0s 159us/step - loss: 118.0300 - val_loss: 176.1444\n",
      "Epoch 142/500\n",
      "22/22 [==============================] - 0s 163us/step - loss: 117.2964 - val_loss: 175.0321\n",
      "Epoch 143/500\n",
      "22/22 [==============================] - 0s 191us/step - loss: 116.5520 - val_loss: 173.9518\n",
      "Epoch 144/500\n",
      "22/22 [==============================] - 0s 197us/step - loss: 115.8694 - val_loss: 172.8156\n",
      "Epoch 145/500\n",
      "22/22 [==============================] - 0s 172us/step - loss: 115.1658 - val_loss: 171.7024\n",
      "Epoch 146/500\n",
      "22/22 [==============================] - 0s 196us/step - loss: 114.4424 - val_loss: 170.6297\n",
      "Epoch 147/500\n",
      "22/22 [==============================] - 0s 165us/step - loss: 113.7387 - val_loss: 169.5291\n",
      "Epoch 148/500\n",
      "22/22 [==============================] - 0s 171us/step - loss: 113.0579 - val_loss: 168.3919\n",
      "Epoch 149/500\n",
      "22/22 [==============================] - 0s 190us/step - loss: 112.3502 - val_loss: 167.2718\n",
      "Epoch 150/500\n",
      "22/22 [==============================] - 0s 199us/step - loss: 111.6381 - val_loss: 166.1727\n",
      "Epoch 151/500\n",
      "22/22 [==============================] - 0s 163us/step - loss: 110.9466 - val_loss: 165.1113\n",
      "Epoch 152/500\n",
      "22/22 [==============================] - 0s 169us/step - loss: 110.2641 - val_loss: 164.0183\n",
      "Epoch 153/500\n",
      "22/22 [==============================] - 0s 186us/step - loss: 109.5882 - val_loss: 162.9013\n",
      "Epoch 154/500\n",
      "22/22 [==============================] - 0s 189us/step - loss: 108.9069 - val_loss: 161.8053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/500\n",
      "22/22 [==============================] - 0s 198us/step - loss: 108.2087 - val_loss: 160.7563\n",
      "Epoch 156/500\n",
      "22/22 [==============================] - 0s 189us/step - loss: 107.5349 - val_loss: 159.7364\n",
      "Epoch 157/500\n",
      "22/22 [==============================] - 0s 227us/step - loss: 106.9483 - val_loss: 158.6992\n",
      "Epoch 158/500\n",
      "22/22 [==============================] - 0s 189us/step - loss: 106.3029 - val_loss: 157.6885\n",
      "Epoch 159/500\n",
      "22/22 [==============================] - 0s 165us/step - loss: 105.6938 - val_loss: 156.7247\n",
      "Epoch 160/500\n",
      "22/22 [==============================] - 0s 259us/step - loss: 105.0891 - val_loss: 155.7930\n",
      "Epoch 161/500\n",
      "22/22 [==============================] - 0s 173us/step - loss: 104.5191 - val_loss: 154.8452\n",
      "Epoch 162/500\n",
      "22/22 [==============================] - 0s 208us/step - loss: 103.9012 - val_loss: 153.9020\n",
      "Epoch 163/500\n",
      "22/22 [==============================] - 0s 171us/step - loss: 103.3637 - val_loss: 152.9279\n",
      "Epoch 164/500\n",
      "22/22 [==============================] - 0s 201us/step - loss: 102.7452 - val_loss: 151.9623\n",
      "Epoch 165/500\n",
      "22/22 [==============================] - 0s 182us/step - loss: 102.1376 - val_loss: 150.9684\n",
      "Epoch 166/500\n",
      "22/22 [==============================] - 0s 159us/step - loss: 101.5402 - val_loss: 149.9674\n",
      "Epoch 167/500\n",
      "22/22 [==============================] - 0s 187us/step - loss: 100.9029 - val_loss: 148.9734\n",
      "Epoch 168/500\n",
      "22/22 [==============================] - 0s 175us/step - loss: 100.2971 - val_loss: 147.9782\n",
      "Epoch 169/500\n",
      "22/22 [==============================] - 0s 158us/step - loss: 99.7252 - val_loss: 146.9852\n",
      "Epoch 170/500\n",
      "22/22 [==============================] - 0s 155us/step - loss: 99.0922 - val_loss: 146.0094\n",
      "Epoch 171/500\n",
      "22/22 [==============================] - 0s 151us/step - loss: 98.5042 - val_loss: 145.0590\n",
      "Epoch 172/500\n",
      "22/22 [==============================] - 0s 141us/step - loss: 97.9443 - val_loss: 144.1333\n",
      "Epoch 173/500\n",
      "22/22 [==============================] - 0s 151us/step - loss: 97.3455 - val_loss: 143.1704\n",
      "Epoch 174/500\n",
      "22/22 [==============================] - 0s 150us/step - loss: 96.7534 - val_loss: 142.1628\n",
      "Epoch 175/500\n",
      "22/22 [==============================] - 0s 141us/step - loss: 96.1659 - val_loss: 141.1701\n",
      "Epoch 176/500\n",
      "22/22 [==============================] - 0s 155us/step - loss: 95.5301 - val_loss: 140.2266\n",
      "Epoch 177/500\n",
      "22/22 [==============================] - 0s 176us/step - loss: 94.9934 - val_loss: 139.2815\n",
      "Epoch 178/500\n",
      "22/22 [==============================] - 0s 178us/step - loss: 94.4423 - val_loss: 138.3508\n",
      "Epoch 179/500\n",
      "22/22 [==============================] - 0s 194us/step - loss: 93.8480 - val_loss: 137.4560\n",
      "Epoch 180/500\n",
      "22/22 [==============================] - 0s 166us/step - loss: 93.3433 - val_loss: 136.5732\n",
      "Epoch 181/500\n",
      "22/22 [==============================] - 0s 151us/step - loss: 92.7701 - val_loss: 135.6584\n",
      "Epoch 182/500\n",
      "22/22 [==============================] - 0s 152us/step - loss: 92.2369 - val_loss: 134.7251\n",
      "Epoch 183/500\n",
      "22/22 [==============================] - 0s 156us/step - loss: 91.6506 - val_loss: 133.7934\n",
      "Epoch 184/500\n",
      "22/22 [==============================] - 0s 161us/step - loss: 91.1078 - val_loss: 132.7919\n",
      "Epoch 185/500\n",
      "22/22 [==============================] - 0s 150us/step - loss: 90.4549 - val_loss: 131.7894\n",
      "Epoch 186/500\n",
      "22/22 [==============================] - 0s 174us/step - loss: 89.8731 - val_loss: 130.7940\n",
      "Epoch 187/500\n",
      "22/22 [==============================] - 0s 144us/step - loss: 89.2890 - val_loss: 129.8557\n",
      "Epoch 188/500\n",
      "22/22 [==============================] - 0s 167us/step - loss: 88.6960 - val_loss: 128.9014\n",
      "Epoch 189/500\n",
      "22/22 [==============================] - 0s 159us/step - loss: 88.1613 - val_loss: 127.9184\n",
      "Epoch 190/500\n",
      "22/22 [==============================] - 0s 172us/step - loss: 87.5996 - val_loss: 126.9986\n",
      "Epoch 191/500\n",
      "22/22 [==============================] - 0s 203us/step - loss: 87.0344 - val_loss: 126.1511\n",
      "Epoch 192/500\n",
      "22/22 [==============================] - 0s 185us/step - loss: 86.5566 - val_loss: 125.3003\n",
      "Epoch 193/500\n",
      "22/22 [==============================] - 0s 144us/step - loss: 85.9929 - val_loss: 124.4208\n",
      "Epoch 194/500\n",
      "22/22 [==============================] - 0s 146us/step - loss: 85.5253 - val_loss: 123.4989\n",
      "Epoch 195/500\n",
      "22/22 [==============================] - 0s 148us/step - loss: 84.9341 - val_loss: 122.6369\n",
      "Epoch 196/500\n",
      "22/22 [==============================] - 0s 164us/step - loss: 84.4294 - val_loss: 121.7783\n",
      "Epoch 197/500\n",
      "22/22 [==============================] - 0s 160us/step - loss: 83.9020 - val_loss: 120.9366\n",
      "Epoch 198/500\n",
      "22/22 [==============================] - 0s 144us/step - loss: 83.3749 - val_loss: 120.0748\n",
      "Epoch 199/500\n",
      "22/22 [==============================] - 0s 174us/step - loss: 82.8917 - val_loss: 119.1873\n",
      "Epoch 200/500\n",
      "22/22 [==============================] - 0s 171us/step - loss: 82.3702 - val_loss: 118.3285\n",
      "Epoch 201/500\n",
      "22/22 [==============================] - 0s 170us/step - loss: 81.8507 - val_loss: 117.5309\n",
      "Epoch 202/500\n",
      "22/22 [==============================] - 0s 183us/step - loss: 81.4139 - val_loss: 116.7305\n",
      "Epoch 203/500\n",
      "22/22 [==============================] - 0s 274us/step - loss: 80.9105 - val_loss: 115.9202\n",
      "Epoch 204/500\n",
      "22/22 [==============================] - 0s 185us/step - loss: 80.4483 - val_loss: 115.0900\n",
      "Epoch 205/500\n",
      "22/22 [==============================] - 0s 168us/step - loss: 79.9036 - val_loss: 114.2565\n",
      "Epoch 206/500\n",
      "22/22 [==============================] - 0s 202us/step - loss: 79.4357 - val_loss: 113.3880\n",
      "Epoch 207/500\n",
      "22/22 [==============================] - 0s 175us/step - loss: 78.9032 - val_loss: 112.5243\n",
      "Epoch 208/500\n",
      "22/22 [==============================] - 0s 191us/step - loss: 78.4685 - val_loss: 111.6752\n",
      "Epoch 209/500\n",
      "22/22 [==============================] - 0s 177us/step - loss: 77.9198 - val_loss: 110.8779\n",
      "Epoch 210/500\n",
      "22/22 [==============================] - 0s 216us/step - loss: 77.4319 - val_loss: 110.0700\n",
      "Epoch 211/500\n",
      "22/22 [==============================] - 0s 200us/step - loss: 76.9809 - val_loss: 109.2306\n",
      "Epoch 212/500\n",
      "22/22 [==============================] - 0s 159us/step - loss: 76.4812 - val_loss: 108.3798\n",
      "Epoch 213/500\n",
      "22/22 [==============================] - 0s 212us/step - loss: 75.9347 - val_loss: 107.5428\n",
      "Epoch 214/500\n",
      "22/22 [==============================] - 0s 160us/step - loss: 75.4436 - val_loss: 106.7047\n",
      "Epoch 215/500\n",
      "22/22 [==============================] - 0s 167us/step - loss: 74.9615 - val_loss: 105.8728\n",
      "Epoch 216/500\n",
      "22/22 [==============================] - 0s 163us/step - loss: 74.5148 - val_loss: 105.0479\n",
      "Epoch 217/500\n",
      "22/22 [==============================] - 0s 193us/step - loss: 74.0539 - val_loss: 104.2762\n",
      "Epoch 218/500\n",
      "22/22 [==============================] - 0s 171us/step - loss: 73.5888 - val_loss: 103.5673\n",
      "Epoch 219/500\n",
      "22/22 [==============================] - 0s 178us/step - loss: 73.1568 - val_loss: 102.8998\n",
      "Epoch 220/500\n",
      "22/22 [==============================] - 0s 149us/step - loss: 72.8112 - val_loss: 102.2519\n",
      "Epoch 221/500\n",
      "22/22 [==============================] - 0s 215us/step - loss: 72.4198 - val_loss: 101.6238\n",
      "Epoch 222/500\n",
      "22/22 [==============================] - 0s 173us/step - loss: 72.0220 - val_loss: 100.9861\n",
      "Epoch 223/500\n",
      "22/22 [==============================] - 0s 170us/step - loss: 71.6290 - val_loss: 100.3055\n",
      "Epoch 224/500\n",
      "22/22 [==============================] - 0s 163us/step - loss: 71.2399 - val_loss: 99.5687\n",
      "Epoch 225/500\n",
      "22/22 [==============================] - 0s 261us/step - loss: 70.8195 - val_loss: 98.8366\n",
      "Epoch 226/500\n",
      "22/22 [==============================] - 0s 166us/step - loss: 70.3810 - val_loss: 98.1157\n",
      "Epoch 227/500\n",
      "22/22 [==============================] - 0s 162us/step - loss: 69.9710 - val_loss: 97.4071\n",
      "Epoch 228/500\n",
      "22/22 [==============================] - 0s 232us/step - loss: 69.5452 - val_loss: 96.7534\n",
      "Epoch 229/500\n",
      "22/22 [==============================] - 0s 264us/step - loss: 69.1500 - val_loss: 96.0927\n",
      "Epoch 230/500\n",
      "22/22 [==============================] - 0s 154us/step - loss: 68.7665 - val_loss: 95.3667\n",
      "Epoch 231/500\n",
      "22/22 [==============================] - 0s 158us/step - loss: 68.3582 - val_loss: 94.6252\n",
      "Epoch 232/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 222us/step - loss: 67.9046 - val_loss: 93.8975\n",
      "Epoch 233/500\n",
      "22/22 [==============================] - 0s 184us/step - loss: 67.5048 - val_loss: 93.1589\n",
      "Epoch 234/500\n",
      "22/22 [==============================] - 0s 159us/step - loss: 67.0787 - val_loss: 92.4309\n",
      "Epoch 235/500\n",
      "22/22 [==============================] - 0s 155us/step - loss: 66.6319 - val_loss: 91.7190\n",
      "Epoch 236/500\n",
      "22/22 [==============================] - 0s 222us/step - loss: 66.1892 - val_loss: 91.0200\n",
      "Epoch 237/500\n",
      "22/22 [==============================] - 0s 234us/step - loss: 65.8421 - val_loss: 90.3282\n",
      "Epoch 238/500\n",
      "22/22 [==============================] - 0s 218us/step - loss: 65.4396 - val_loss: 89.6746\n",
      "Epoch 239/500\n",
      "22/22 [==============================] - 0s 162us/step - loss: 65.0677 - val_loss: 89.0236\n",
      "Epoch 240/500\n",
      "22/22 [==============================] - 0s 173us/step - loss: 64.6740 - val_loss: 88.4230\n",
      "Epoch 241/500\n",
      "22/22 [==============================] - 0s 194us/step - loss: 64.3231 - val_loss: 87.8549\n",
      "Epoch 242/500\n",
      "22/22 [==============================] - 0s 187us/step - loss: 64.0115 - val_loss: 87.2840\n",
      "Epoch 243/500\n",
      "22/22 [==============================] - 0s 147us/step - loss: 63.6578 - val_loss: 86.6998\n",
      "Epoch 244/500\n",
      "22/22 [==============================] - 0s 150us/step - loss: 63.3332 - val_loss: 86.1030\n",
      "Epoch 245/500\n",
      "22/22 [==============================] - 0s 214us/step - loss: 63.0060 - val_loss: 85.4919\n",
      "Epoch 246/500\n",
      "22/22 [==============================] - 0s 166us/step - loss: 62.6446 - val_loss: 84.9245\n",
      "Epoch 247/500\n",
      "22/22 [==============================] - 0s 181us/step - loss: 62.2831 - val_loss: 84.3764\n",
      "Epoch 248/500\n",
      "22/22 [==============================] - 0s 183us/step - loss: 61.9771 - val_loss: 83.7843\n",
      "Epoch 249/500\n",
      "22/22 [==============================] - 0s 228us/step - loss: 61.6181 - val_loss: 83.1791\n",
      "Epoch 250/500\n",
      "22/22 [==============================] - 0s 188us/step - loss: 61.2640 - val_loss: 82.5893\n",
      "Epoch 251/500\n",
      "22/22 [==============================] - 0s 164us/step - loss: 60.9202 - val_loss: 81.9997\n",
      "Epoch 252/500\n",
      "22/22 [==============================] - 0s 176us/step - loss: 60.5857 - val_loss: 81.3457\n",
      "Epoch 253/500\n",
      "22/22 [==============================] - 0s 226us/step - loss: 60.2001 - val_loss: 80.6843\n",
      "Epoch 254/500\n",
      "22/22 [==============================] - 0s 177us/step - loss: 59.8345 - val_loss: 80.0301\n",
      "Epoch 255/500\n",
      "22/22 [==============================] - 0s 175us/step - loss: 59.4251 - val_loss: 79.3851\n",
      "Epoch 256/500\n",
      "22/22 [==============================] - 0s 190us/step - loss: 59.0692 - val_loss: 78.7026\n",
      "Epoch 257/500\n",
      "22/22 [==============================] - 0s 191us/step - loss: 58.6462 - val_loss: 78.0511\n",
      "Epoch 258/500\n",
      "22/22 [==============================] - 0s 162us/step - loss: 58.3043 - val_loss: 77.4218\n",
      "Epoch 259/500\n",
      "22/22 [==============================] - 0s 173us/step - loss: 57.9406 - val_loss: 76.8474\n",
      "Epoch 260/500\n",
      "22/22 [==============================] - 0s 169us/step - loss: 57.6266 - val_loss: 76.2943\n",
      "Epoch 261/500\n",
      "22/22 [==============================] - 0s 228us/step - loss: 57.2847 - val_loss: 75.7513\n",
      "Epoch 262/500\n",
      "22/22 [==============================] - 0s 192us/step - loss: 56.9598 - val_loss: 75.1916\n",
      "Epoch 263/500\n",
      "22/22 [==============================] - 0s 188us/step - loss: 56.6557 - val_loss: 74.6398\n",
      "Epoch 264/500\n",
      "22/22 [==============================] - 0s 260us/step - loss: 56.3309 - val_loss: 74.0980\n",
      "Epoch 265/500\n",
      "22/22 [==============================] - 0s 153us/step - loss: 56.0201 - val_loss: 73.5368\n",
      "Epoch 266/500\n",
      "22/22 [==============================] - 0s 177us/step - loss: 55.6988 - val_loss: 72.9678\n",
      "Epoch 267/500\n",
      "22/22 [==============================] - 0s 184us/step - loss: 55.3738 - val_loss: 72.4187\n",
      "Epoch 268/500\n",
      "22/22 [==============================] - 0s 188us/step - loss: 55.0582 - val_loss: 71.8841\n",
      "Epoch 269/500\n",
      "22/22 [==============================] - 0s 162us/step - loss: 54.7739 - val_loss: 71.3285\n",
      "Epoch 270/500\n",
      "22/22 [==============================] - 0s 188us/step - loss: 54.4228 - val_loss: 70.8129\n",
      "Epoch 271/500\n",
      "22/22 [==============================] - 0s 192us/step - loss: 54.1283 - val_loss: 70.2778\n",
      "Epoch 272/500\n",
      "22/22 [==============================] - 0s 340us/step - loss: 53.8182 - val_loss: 69.7256\n",
      "Epoch 273/500\n",
      "22/22 [==============================] - 0s 194us/step - loss: 53.5451 - val_loss: 69.1626\n",
      "Epoch 274/500\n",
      "22/22 [==============================] - 0s 224us/step - loss: 53.1838 - val_loss: 68.6509\n",
      "Epoch 275/500\n",
      "22/22 [==============================] - 0s 210us/step - loss: 52.8967 - val_loss: 68.1465\n",
      "Epoch 276/500\n",
      "22/22 [==============================] - 0s 234us/step - loss: 52.5778 - val_loss: 67.6377\n",
      "Epoch 277/500\n",
      "22/22 [==============================] - 0s 150us/step - loss: 52.2915 - val_loss: 67.0886\n",
      "Epoch 278/500\n",
      "22/22 [==============================] - 0s 206us/step - loss: 51.9716 - val_loss: 66.5128\n",
      "Epoch 279/500\n",
      "22/22 [==============================] - 0s 227us/step - loss: 51.6193 - val_loss: 65.9319\n",
      "Epoch 280/500\n",
      "22/22 [==============================] - 0s 164us/step - loss: 51.3142 - val_loss: 65.3151\n",
      "Epoch 281/500\n",
      "22/22 [==============================] - 0s 241us/step - loss: 50.9709 - val_loss: 64.7347\n",
      "Epoch 282/500\n",
      "22/22 [==============================] - 0s 212us/step - loss: 50.6121 - val_loss: 64.1957\n",
      "Epoch 283/500\n",
      "22/22 [==============================] - 0s 272us/step - loss: 50.3019 - val_loss: 63.6369\n",
      "Epoch 284/500\n",
      "22/22 [==============================] - 0s 186us/step - loss: 49.9809 - val_loss: 63.0503\n",
      "Epoch 285/500\n",
      "22/22 [==============================] - 0s 170us/step - loss: 49.6485 - val_loss: 62.4687\n",
      "Epoch 286/500\n",
      "22/22 [==============================] - 0s 212us/step - loss: 49.3289 - val_loss: 61.9077\n",
      "Epoch 287/500\n",
      "22/22 [==============================] - 0s 183us/step - loss: 49.0132 - val_loss: 61.3964\n",
      "Epoch 288/500\n",
      "22/22 [==============================] - 0s 192us/step - loss: 48.7174 - val_loss: 60.9186\n",
      "Epoch 289/500\n",
      "22/22 [==============================] - 0s 204us/step - loss: 48.4280 - val_loss: 60.4513\n",
      "Epoch 290/500\n",
      "22/22 [==============================] - 0s 182us/step - loss: 48.1786 - val_loss: 59.9470\n",
      "Epoch 291/500\n",
      "22/22 [==============================] - 0s 250us/step - loss: 47.8746 - val_loss: 59.4131\n",
      "Epoch 292/500\n",
      "22/22 [==============================] - 0s 205us/step - loss: 47.5584 - val_loss: 58.8740\n",
      "Epoch 293/500\n",
      "22/22 [==============================] - 0s 173us/step - loss: 47.2608 - val_loss: 58.3252\n",
      "Epoch 294/500\n",
      "22/22 [==============================] - 0s 179us/step - loss: 46.9557 - val_loss: 57.7976\n",
      "Epoch 295/500\n",
      "22/22 [==============================] - 0s 183us/step - loss: 46.6134 - val_loss: 57.3095\n",
      "Epoch 296/500\n",
      "22/22 [==============================] - 0s 178us/step - loss: 46.3205 - val_loss: 56.7925\n",
      "Epoch 297/500\n",
      "22/22 [==============================] - 0s 174us/step - loss: 46.0591 - val_loss: 56.2375\n",
      "Epoch 298/500\n",
      "22/22 [==============================] - 0s 245us/step - loss: 45.7544 - val_loss: 55.7073\n",
      "Epoch 299/500\n",
      "22/22 [==============================] - 0s 178us/step - loss: 45.4178 - val_loss: 55.2277\n",
      "Epoch 300/500\n",
      "22/22 [==============================] - 0s 188us/step - loss: 45.1776 - val_loss: 54.7424\n",
      "Epoch 301/500\n",
      "22/22 [==============================] - 0s 159us/step - loss: 44.8684 - val_loss: 54.2841\n",
      "Epoch 302/500\n",
      "22/22 [==============================] - 0s 217us/step - loss: 44.6104 - val_loss: 53.8230\n",
      "Epoch 303/500\n",
      "22/22 [==============================] - 0s 271us/step - loss: 44.3436 - val_loss: 53.3534\n",
      "Epoch 304/500\n",
      "22/22 [==============================] - 0s 189us/step - loss: 44.0834 - val_loss: 52.8747\n",
      "Epoch 305/500\n",
      "22/22 [==============================] - 0s 240us/step - loss: 43.8114 - val_loss: 52.3972\n",
      "Epoch 306/500\n",
      "22/22 [==============================] - 0s 155us/step - loss: 43.5218 - val_loss: 51.9588\n",
      "Epoch 307/500\n",
      "22/22 [==============================] - 0s 167us/step - loss: 43.2743 - val_loss: 51.5490\n",
      "Epoch 308/500\n",
      "22/22 [==============================] - 0s 154us/step - loss: 43.0584 - val_loss: 51.1624\n",
      "Epoch 309/500\n",
      "22/22 [==============================] - 0s 208us/step - loss: 42.8177 - val_loss: 50.7781\n",
      "Epoch 310/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 198us/step - loss: 42.6016 - val_loss: 50.3636\n",
      "Epoch 311/500\n",
      "22/22 [==============================] - 0s 154us/step - loss: 42.3545 - val_loss: 49.9450\n",
      "Epoch 312/500\n",
      "22/22 [==============================] - 0s 151us/step - loss: 42.1222 - val_loss: 49.5308\n",
      "Epoch 313/500\n",
      "22/22 [==============================] - 0s 205us/step - loss: 41.8885 - val_loss: 49.1452\n",
      "Epoch 314/500\n",
      "22/22 [==============================] - 0s 201us/step - loss: 41.6437 - val_loss: 48.7560\n",
      "Epoch 315/500\n",
      "22/22 [==============================] - 0s 149us/step - loss: 41.4547 - val_loss: 48.3262\n",
      "Epoch 316/500\n",
      "22/22 [==============================] - 0s 164us/step - loss: 41.1711 - val_loss: 47.9306\n",
      "Epoch 317/500\n",
      "22/22 [==============================] - 0s 202us/step - loss: 40.9343 - val_loss: 47.5072\n",
      "Epoch 318/500\n",
      "22/22 [==============================] - 0s 191us/step - loss: 40.7038 - val_loss: 47.0470\n",
      "Epoch 319/500\n",
      "22/22 [==============================] - 0s 203us/step - loss: 40.4288 - val_loss: 46.5997\n",
      "Epoch 320/500\n",
      "22/22 [==============================] - 0s 170us/step - loss: 40.1767 - val_loss: 46.1640\n",
      "Epoch 321/500\n",
      "22/22 [==============================] - 0s 157us/step - loss: 39.9502 - val_loss: 45.7345\n",
      "Epoch 322/500\n",
      "22/22 [==============================] - 0s 214us/step - loss: 39.6707 - val_loss: 45.3380\n",
      "Epoch 323/500\n",
      "22/22 [==============================] - 0s 191us/step - loss: 39.4487 - val_loss: 44.9530\n",
      "Epoch 324/500\n",
      "22/22 [==============================] - 0s 157us/step - loss: 39.2298 - val_loss: 44.5887\n",
      "Epoch 325/500\n",
      "22/22 [==============================] - 0s 160us/step - loss: 39.0033 - val_loss: 44.2403\n",
      "Epoch 326/500\n",
      "22/22 [==============================] - 0s 238us/step - loss: 38.8246 - val_loss: 43.8868\n",
      "Epoch 327/500\n",
      "22/22 [==============================] - 0s 175us/step - loss: 38.6042 - val_loss: 43.5686\n",
      "Epoch 328/500\n",
      "22/22 [==============================] - 0s 172us/step - loss: 38.4366 - val_loss: 43.2562\n",
      "Epoch 329/500\n",
      "22/22 [==============================] - 0s 195us/step - loss: 38.2470 - val_loss: 42.9429\n",
      "Epoch 330/500\n",
      "22/22 [==============================] - 0s 263us/step - loss: 38.0453 - val_loss: 42.5917\n",
      "Epoch 331/500\n",
      "22/22 [==============================] - 0s 167us/step - loss: 37.8573 - val_loss: 42.2093\n",
      "Epoch 332/500\n",
      "22/22 [==============================] - 0s 198us/step - loss: 37.6259 - val_loss: 41.8530\n",
      "Epoch 333/500\n",
      "22/22 [==============================] - 0s 183us/step - loss: 37.4154 - val_loss: 41.4859\n",
      "Epoch 334/500\n",
      "22/22 [==============================] - 0s 196us/step - loss: 37.2157 - val_loss: 41.1170\n",
      "Epoch 335/500\n",
      "22/22 [==============================] - 0s 163us/step - loss: 36.9820 - val_loss: 40.7741\n",
      "Epoch 336/500\n",
      "22/22 [==============================] - 0s 161us/step - loss: 36.7896 - val_loss: 40.4294\n",
      "Epoch 337/500\n",
      "22/22 [==============================] - 0s 256us/step - loss: 36.5819 - val_loss: 40.0921\n",
      "Epoch 338/500\n",
      "22/22 [==============================] - 0s 155us/step - loss: 36.3824 - val_loss: 39.7512\n",
      "Epoch 339/500\n",
      "22/22 [==============================] - 0s 164us/step - loss: 36.2116 - val_loss: 39.4132\n",
      "Epoch 340/500\n",
      "22/22 [==============================] - 0s 195us/step - loss: 35.9921 - val_loss: 39.0920\n",
      "Epoch 341/500\n",
      "22/22 [==============================] - 0s 205us/step - loss: 35.8056 - val_loss: 38.7690\n",
      "Epoch 342/500\n",
      "22/22 [==============================] - 0s 158us/step - loss: 35.5971 - val_loss: 38.4550\n",
      "Epoch 343/500\n",
      "22/22 [==============================] - 0s 172us/step - loss: 35.4345 - val_loss: 38.0994\n",
      "Epoch 344/500\n",
      "22/22 [==============================] - 0s 331us/step - loss: 35.2148 - val_loss: 37.7536\n",
      "Epoch 345/500\n",
      "22/22 [==============================] - 0s 166us/step - loss: 35.0199 - val_loss: 37.4371\n",
      "Epoch 346/500\n",
      "22/22 [==============================] - 0s 171us/step - loss: 34.8430 - val_loss: 37.1357\n",
      "Epoch 347/500\n",
      "22/22 [==============================] - 0s 181us/step - loss: 34.6649 - val_loss: 36.8435\n",
      "Epoch 348/500\n",
      "22/22 [==============================] - 0s 198us/step - loss: 34.4946 - val_loss: 36.5620\n",
      "Epoch 349/500\n",
      "22/22 [==============================] - 0s 199us/step - loss: 34.3159 - val_loss: 36.2838\n",
      "Epoch 350/500\n",
      "22/22 [==============================] - 0s 218us/step - loss: 34.1534 - val_loss: 35.9872\n",
      "Epoch 351/500\n",
      "22/22 [==============================] - 0s 233us/step - loss: 33.9786 - val_loss: 35.7060\n",
      "Epoch 352/500\n",
      "22/22 [==============================] - 0s 185us/step - loss: 33.8086 - val_loss: 35.4187\n",
      "Epoch 353/500\n",
      "22/22 [==============================] - 0s 234us/step - loss: 33.6228 - val_loss: 35.1134\n",
      "Epoch 354/500\n",
      "22/22 [==============================] - 0s 181us/step - loss: 33.4490 - val_loss: 34.7982\n",
      "Epoch 355/500\n",
      "22/22 [==============================] - 0s 255us/step - loss: 33.2674 - val_loss: 34.4918\n",
      "Epoch 356/500\n",
      "22/22 [==============================] - 0s 154us/step - loss: 33.0718 - val_loss: 34.1791\n",
      "Epoch 357/500\n",
      "22/22 [==============================] - 0s 179us/step - loss: 32.9124 - val_loss: 33.8695\n",
      "Epoch 358/500\n",
      "22/22 [==============================] - 0s 178us/step - loss: 32.7147 - val_loss: 33.5682\n",
      "Epoch 359/500\n",
      "22/22 [==============================] - 0s 200us/step - loss: 32.5609 - val_loss: 33.2455\n",
      "Epoch 360/500\n",
      "22/22 [==============================] - 0s 170us/step - loss: 32.3598 - val_loss: 32.9443\n",
      "Epoch 361/500\n",
      "22/22 [==============================] - 0s 165us/step - loss: 32.1815 - val_loss: 32.6328\n",
      "Epoch 362/500\n",
      "22/22 [==============================] - 0s 169us/step - loss: 31.9929 - val_loss: 32.3239\n",
      "Epoch 363/500\n",
      "22/22 [==============================] - 0s 275us/step - loss: 31.7995 - val_loss: 32.0205\n",
      "Epoch 364/500\n",
      "22/22 [==============================] - 0s 164us/step - loss: 31.6169 - val_loss: 31.7383\n",
      "Epoch 365/500\n",
      "22/22 [==============================] - 0s 183us/step - loss: 31.4503 - val_loss: 31.4611\n",
      "Epoch 366/500\n",
      "22/22 [==============================] - 0s 222us/step - loss: 31.2541 - val_loss: 31.1647\n",
      "Epoch 367/500\n",
      "22/22 [==============================] - 0s 164us/step - loss: 31.1039 - val_loss: 30.8500\n",
      "Epoch 368/500\n",
      "22/22 [==============================] - 0s 235us/step - loss: 30.9018 - val_loss: 30.5636\n",
      "Epoch 369/500\n",
      "22/22 [==============================] - 0s 278us/step - loss: 30.7307 - val_loss: 30.2719\n",
      "Epoch 370/500\n",
      "22/22 [==============================] - 0s 195us/step - loss: 30.5739 - val_loss: 29.9655\n",
      "Epoch 371/500\n",
      "22/22 [==============================] - 0s 169us/step - loss: 30.4008 - val_loss: 29.6584\n",
      "Epoch 372/500\n",
      "22/22 [==============================] - 0s 170us/step - loss: 30.2030 - val_loss: 29.3713\n",
      "Epoch 373/500\n",
      "22/22 [==============================] - 0s 201us/step - loss: 30.0172 - val_loss: 29.0944\n",
      "Epoch 374/500\n",
      "22/22 [==============================] - 0s 210us/step - loss: 29.8498 - val_loss: 28.8083\n",
      "Epoch 375/500\n",
      "22/22 [==============================] - 0s 184us/step - loss: 29.6791 - val_loss: 28.5158\n",
      "Epoch 376/500\n",
      "22/22 [==============================] - 0s 197us/step - loss: 29.4805 - val_loss: 28.2222\n",
      "Epoch 377/500\n",
      "22/22 [==============================] - 0s 190us/step - loss: 29.3288 - val_loss: 27.9186\n",
      "Epoch 378/500\n",
      "22/22 [==============================] - 0s 209us/step - loss: 29.1420 - val_loss: 27.6468\n",
      "Epoch 379/500\n",
      "22/22 [==============================] - 0s 165us/step - loss: 28.9845 - val_loss: 27.3968\n",
      "Epoch 380/500\n",
      "22/22 [==============================] - 0s 261us/step - loss: 28.8207 - val_loss: 27.1545\n",
      "Epoch 381/500\n",
      "22/22 [==============================] - 0s 165us/step - loss: 28.6914 - val_loss: 26.8927\n",
      "Epoch 382/500\n",
      "22/22 [==============================] - 0s 153us/step - loss: 28.5364 - val_loss: 26.6421\n",
      "Epoch 383/500\n",
      "22/22 [==============================] - 0s 141us/step - loss: 28.3795 - val_loss: 26.4064\n",
      "Epoch 384/500\n",
      "22/22 [==============================] - 0s 225us/step - loss: 28.2164 - val_loss: 26.1831\n",
      "Epoch 385/500\n",
      "22/22 [==============================] - 0s 171us/step - loss: 28.0750 - val_loss: 25.9360\n",
      "Epoch 386/500\n",
      "22/22 [==============================] - 0s 193us/step - loss: 27.9238 - val_loss: 25.6726\n",
      "Epoch 387/500\n",
      "22/22 [==============================] - 0s 190us/step - loss: 27.7530 - val_loss: 25.4036\n",
      "Epoch 388/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 173us/step - loss: 27.5867 - val_loss: 25.1267\n",
      "Epoch 389/500\n",
      "22/22 [==============================] - 0s 216us/step - loss: 27.4313 - val_loss: 24.8456\n",
      "Epoch 390/500\n",
      "22/22 [==============================] - 0s 167us/step - loss: 27.2417 - val_loss: 24.5814\n",
      "Epoch 391/500\n",
      "22/22 [==============================] - 0s 222us/step - loss: 27.0940 - val_loss: 24.3309\n",
      "Epoch 392/500\n",
      "22/22 [==============================] - 0s 184us/step - loss: 26.9478 - val_loss: 24.0938\n",
      "Epoch 393/500\n",
      "22/22 [==============================] - 0s 246us/step - loss: 26.7909 - val_loss: 23.8725\n",
      "Epoch 394/500\n",
      "22/22 [==============================] - 0s 165us/step - loss: 26.6549 - val_loss: 23.6396\n",
      "Epoch 395/500\n",
      "22/22 [==============================] - 0s 153us/step - loss: 26.5020 - val_loss: 23.4114\n",
      "Epoch 396/500\n",
      "22/22 [==============================] - 0s 171us/step - loss: 26.3573 - val_loss: 23.1786\n",
      "Epoch 397/500\n",
      "22/22 [==============================] - 0s 228us/step - loss: 26.2163 - val_loss: 22.9470\n",
      "Epoch 398/500\n",
      "22/22 [==============================] - 0s 147us/step - loss: 26.0748 - val_loss: 22.7311\n",
      "Epoch 399/500\n",
      "22/22 [==============================] - 0s 168us/step - loss: 25.9432 - val_loss: 22.5247\n",
      "Epoch 400/500\n",
      "22/22 [==============================] - 0s 230us/step - loss: 25.8072 - val_loss: 22.3327\n",
      "Epoch 401/500\n",
      "22/22 [==============================] - 0s 184us/step - loss: 25.6908 - val_loss: 22.1535\n",
      "Epoch 402/500\n",
      "22/22 [==============================] - 0s 167us/step - loss: 25.5786 - val_loss: 21.9880\n",
      "Epoch 403/500\n",
      "22/22 [==============================] - 0s 159us/step - loss: 25.4654 - val_loss: 21.8146\n",
      "Epoch 404/500\n",
      "22/22 [==============================] - 0s 230us/step - loss: 25.3477 - val_loss: 21.6116\n",
      "Epoch 405/500\n",
      "22/22 [==============================] - 0s 163us/step - loss: 25.2142 - val_loss: 21.3943\n",
      "Epoch 406/500\n",
      "22/22 [==============================] - 0s 160us/step - loss: 25.0969 - val_loss: 21.1801\n",
      "Epoch 407/500\n",
      "22/22 [==============================] - 0s 156us/step - loss: 24.9532 - val_loss: 20.9783\n",
      "Epoch 408/500\n",
      "22/22 [==============================] - 0s 179us/step - loss: 24.8418 - val_loss: 20.7707\n",
      "Epoch 409/500\n",
      "22/22 [==============================] - 0s 176us/step - loss: 24.6909 - val_loss: 20.5736\n",
      "Epoch 410/500\n",
      "22/22 [==============================] - 0s 193us/step - loss: 24.5649 - val_loss: 20.3686\n",
      "Epoch 411/500\n",
      "22/22 [==============================] - 0s 175us/step - loss: 24.4328 - val_loss: 20.1807\n",
      "Epoch 412/500\n",
      "22/22 [==============================] - 0s 231us/step - loss: 24.3115 - val_loss: 19.9964\n",
      "Epoch 413/500\n",
      "22/22 [==============================] - 0s 154us/step - loss: 24.2051 - val_loss: 19.8164\n",
      "Epoch 414/500\n",
      "22/22 [==============================] - 0s 167us/step - loss: 24.0717 - val_loss: 19.6486\n",
      "Epoch 415/500\n",
      "22/22 [==============================] - 0s 176us/step - loss: 23.9799 - val_loss: 19.4715\n",
      "Epoch 416/500\n",
      "22/22 [==============================] - 0s 246us/step - loss: 23.8622 - val_loss: 19.3073\n",
      "Epoch 417/500\n",
      "22/22 [==============================] - 0s 179us/step - loss: 23.7418 - val_loss: 19.1365\n",
      "Epoch 418/500\n",
      "22/22 [==============================] - 0s 207us/step - loss: 23.6414 - val_loss: 18.9457\n",
      "Epoch 419/500\n",
      "22/22 [==============================] - 0s 209us/step - loss: 23.5156 - val_loss: 18.7604\n",
      "Epoch 420/500\n",
      "22/22 [==============================] - 0s 200us/step - loss: 23.4022 - val_loss: 18.5914\n",
      "Epoch 421/500\n",
      "22/22 [==============================] - 0s 170us/step - loss: 23.2737 - val_loss: 18.4204\n",
      "Epoch 422/500\n",
      "22/22 [==============================] - 0s 177us/step - loss: 23.1680 - val_loss: 18.2459\n",
      "Epoch 423/500\n",
      "22/22 [==============================] - 0s 213us/step - loss: 23.0538 - val_loss: 18.0600\n",
      "Epoch 424/500\n",
      "22/22 [==============================] - 0s 165us/step - loss: 22.9191 - val_loss: 17.8755\n",
      "Epoch 425/500\n",
      "22/22 [==============================] - 0s 168us/step - loss: 22.8155 - val_loss: 17.6879\n",
      "Epoch 426/500\n",
      "22/22 [==============================] - 0s 171us/step - loss: 22.6935 - val_loss: 17.5304\n",
      "Epoch 427/500\n",
      "22/22 [==============================] - 0s 250us/step - loss: 22.5745 - val_loss: 17.3699\n",
      "Epoch 428/500\n",
      "22/22 [==============================] - 0s 171us/step - loss: 22.4647 - val_loss: 17.1996\n",
      "Epoch 429/500\n",
      "22/22 [==============================] - 0s 187us/step - loss: 22.3437 - val_loss: 17.0263\n",
      "Epoch 430/500\n",
      "22/22 [==============================] - 0s 269us/step - loss: 22.2284 - val_loss: 16.8292\n",
      "Epoch 431/500\n",
      "22/22 [==============================] - 0s 188us/step - loss: 22.0864 - val_loss: 16.6254\n",
      "Epoch 432/500\n",
      "22/22 [==============================] - 0s 231us/step - loss: 21.9609 - val_loss: 16.3992\n",
      "Epoch 433/500\n",
      "22/22 [==============================] - 0s 166us/step - loss: 21.7991 - val_loss: 16.1712\n",
      "Epoch 434/500\n",
      "22/22 [==============================] - 0s 299us/step - loss: 21.6646 - val_loss: 15.9504\n",
      "Epoch 435/500\n",
      "22/22 [==============================] - 0s 220us/step - loss: 21.5158 - val_loss: 15.7454\n",
      "Epoch 436/500\n",
      "22/22 [==============================] - 0s 169us/step - loss: 21.3844 - val_loss: 15.5532\n",
      "Epoch 437/500\n",
      "22/22 [==============================] - 0s 283us/step - loss: 21.2444 - val_loss: 15.3748\n",
      "Epoch 438/500\n",
      "22/22 [==============================] - 0s 163us/step - loss: 21.1335 - val_loss: 15.1904\n",
      "Epoch 439/500\n",
      "22/22 [==============================] - 0s 165us/step - loss: 20.9909 - val_loss: 15.0239\n",
      "Epoch 440/500\n",
      "22/22 [==============================] - 0s 211us/step - loss: 20.8800 - val_loss: 14.8413\n",
      "Epoch 441/500\n",
      "22/22 [==============================] - 0s 178us/step - loss: 20.7496 - val_loss: 14.6681\n",
      "Epoch 442/500\n",
      "22/22 [==============================] - 0s 212us/step - loss: 20.6271 - val_loss: 14.4978\n",
      "Epoch 443/500\n",
      "22/22 [==============================] - 0s 158us/step - loss: 20.5222 - val_loss: 14.3188\n",
      "Epoch 444/500\n",
      "22/22 [==============================] - 0s 227us/step - loss: 20.3884 - val_loss: 14.1408\n",
      "Epoch 445/500\n",
      "22/22 [==============================] - 0s 201us/step - loss: 20.2732 - val_loss: 13.9605\n",
      "Epoch 446/500\n",
      "22/22 [==============================] - 0s 183us/step - loss: 20.1471 - val_loss: 13.7961\n",
      "Epoch 447/500\n",
      "22/22 [==============================] - 0s 178us/step - loss: 20.0421 - val_loss: 13.6311\n",
      "Epoch 448/500\n",
      "22/22 [==============================] - 0s 194us/step - loss: 19.9135 - val_loss: 13.4797\n",
      "Epoch 449/500\n",
      "22/22 [==============================] - 0s 179us/step - loss: 19.8185 - val_loss: 13.3322\n",
      "Epoch 450/500\n",
      "22/22 [==============================] - 0s 175us/step - loss: 19.7028 - val_loss: 13.1875\n",
      "Epoch 451/500\n",
      "22/22 [==============================] - 0s 218us/step - loss: 19.6116 - val_loss: 13.0405\n",
      "Epoch 452/500\n",
      "22/22 [==============================] - 0s 166us/step - loss: 19.5004 - val_loss: 12.9064\n",
      "Epoch 453/500\n",
      "22/22 [==============================] - 0s 178us/step - loss: 19.4053 - val_loss: 12.7752\n",
      "Epoch 454/500\n",
      "22/22 [==============================] - 0s 186us/step - loss: 19.3134 - val_loss: 12.6636\n",
      "Epoch 455/500\n",
      "22/22 [==============================] - 0s 291us/step - loss: 19.2103 - val_loss: 12.5468\n",
      "Epoch 456/500\n",
      "22/22 [==============================] - 0s 210us/step - loss: 19.1095 - val_loss: 12.4058\n",
      "Epoch 457/500\n",
      "22/22 [==============================] - 0s 161us/step - loss: 19.0158 - val_loss: 12.2427\n",
      "Epoch 458/500\n",
      "22/22 [==============================] - 0s 204us/step - loss: 18.9067 - val_loss: 12.0767\n",
      "Epoch 459/500\n",
      "22/22 [==============================] - 0s 192us/step - loss: 18.7898 - val_loss: 11.9242\n",
      "Epoch 460/500\n",
      "22/22 [==============================] - 0s 226us/step - loss: 18.6697 - val_loss: 11.7701\n",
      "Epoch 461/500\n",
      "22/22 [==============================] - 0s 153us/step - loss: 18.5610 - val_loss: 11.6100\n",
      "Epoch 462/500\n",
      "22/22 [==============================] - 0s 225us/step - loss: 18.4794 - val_loss: 11.4579\n",
      "Epoch 463/500\n",
      "22/22 [==============================] - 0s 188us/step - loss: 18.3546 - val_loss: 11.3290\n",
      "Epoch 464/500\n",
      "22/22 [==============================] - 0s 178us/step - loss: 18.2721 - val_loss: 11.2049\n",
      "Epoch 465/500\n",
      "22/22 [==============================] - 0s 277us/step - loss: 18.1655 - val_loss: 11.1018\n",
      "Epoch 466/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 283us/step - loss: 18.0667 - val_loss: 11.0145\n",
      "Epoch 467/500\n",
      "22/22 [==============================] - 0s 152us/step - loss: 17.9827 - val_loss: 10.8935\n",
      "Epoch 468/500\n",
      "22/22 [==============================] - 0s 189us/step - loss: 17.8882 - val_loss: 10.7563\n",
      "Epoch 469/500\n",
      "22/22 [==============================] - 0s 185us/step - loss: 17.7950 - val_loss: 10.6141\n",
      "Epoch 470/500\n",
      "22/22 [==============================] - 0s 175us/step - loss: 17.6980 - val_loss: 10.4760\n",
      "Epoch 471/500\n",
      "22/22 [==============================] - 0s 149us/step - loss: 17.6001 - val_loss: 10.3508\n",
      "Epoch 472/500\n",
      "22/22 [==============================] - 0s 161us/step - loss: 17.5092 - val_loss: 10.2188\n",
      "Epoch 473/500\n",
      "22/22 [==============================] - 0s 257us/step - loss: 17.4207 - val_loss: 10.0865\n",
      "Epoch 474/500\n",
      "22/22 [==============================] - 0s 223us/step - loss: 17.3233 - val_loss: 9.9552\n",
      "Epoch 475/500\n",
      "22/22 [==============================] - 0s 169us/step - loss: 17.2035 - val_loss: 9.8333\n",
      "Epoch 476/500\n",
      "22/22 [==============================] - 0s 160us/step - loss: 17.1119 - val_loss: 9.7015\n",
      "Epoch 477/500\n",
      "22/22 [==============================] - 0s 327us/step - loss: 16.9926 - val_loss: 9.5777\n",
      "Epoch 478/500\n",
      "22/22 [==============================] - 0s 239us/step - loss: 16.9129 - val_loss: 9.4486\n",
      "Epoch 479/500\n",
      "22/22 [==============================] - 0s 179us/step - loss: 16.8038 - val_loss: 9.3367\n",
      "Epoch 480/500\n",
      "22/22 [==============================] - 0s 178us/step - loss: 16.7083 - val_loss: 9.2325\n",
      "Epoch 481/500\n",
      "22/22 [==============================] - 0s 229us/step - loss: 16.6168 - val_loss: 9.1303\n",
      "Epoch 482/500\n",
      "22/22 [==============================] - 0s 166us/step - loss: 16.5390 - val_loss: 9.0159\n",
      "Epoch 483/500\n",
      "22/22 [==============================] - 0s 169us/step - loss: 16.4550 - val_loss: 8.9037\n",
      "Epoch 484/500\n",
      "22/22 [==============================] - 0s 165us/step - loss: 16.3593 - val_loss: 8.7937\n",
      "Epoch 485/500\n",
      "22/22 [==============================] - 0s 247us/step - loss: 16.2746 - val_loss: 8.6637\n",
      "Epoch 486/500\n",
      "22/22 [==============================] - 0s 157us/step - loss: 16.1744 - val_loss: 8.5346\n",
      "Epoch 487/500\n",
      "22/22 [==============================] - 0s 203us/step - loss: 16.0807 - val_loss: 8.4236\n",
      "Epoch 488/500\n",
      "22/22 [==============================] - 0s 236us/step - loss: 15.9873 - val_loss: 8.3301\n",
      "Epoch 489/500\n",
      "22/22 [==============================] - 0s 171us/step - loss: 15.9142 - val_loss: 8.2402\n",
      "Epoch 490/500\n",
      "22/22 [==============================] - 0s 156us/step - loss: 15.8261 - val_loss: 8.1573\n",
      "Epoch 491/500\n",
      "22/22 [==============================] - 0s 344us/step - loss: 15.7480 - val_loss: 8.0754\n",
      "Epoch 492/500\n",
      "22/22 [==============================] - 0s 161us/step - loss: 15.6670 - val_loss: 7.9789\n",
      "Epoch 493/500\n",
      "22/22 [==============================] - 0s 173us/step - loss: 15.5941 - val_loss: 7.8739\n",
      "Epoch 494/500\n",
      "22/22 [==============================] - 0s 188us/step - loss: 15.4992 - val_loss: 7.7597\n",
      "Epoch 495/500\n",
      "22/22 [==============================] - 0s 271us/step - loss: 15.4039 - val_loss: 7.6436\n",
      "Epoch 496/500\n",
      "22/22 [==============================] - 0s 165us/step - loss: 15.3089 - val_loss: 7.5212\n",
      "Epoch 497/500\n",
      "22/22 [==============================] - 0s 183us/step - loss: 15.2259 - val_loss: 7.3994\n",
      "Epoch 498/500\n",
      "22/22 [==============================] - 0s 254us/step - loss: 15.1216 - val_loss: 7.3141\n",
      "Epoch 499/500\n",
      "22/22 [==============================] - 0s 174us/step - loss: 15.0199 - val_loss: 7.2208\n",
      "Epoch 500/500\n",
      "22/22 [==============================] - 0s 174us/step - loss: 14.9446 - val_loss: 7.1104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[6.0102143]], dtype=float32),\n",
       " array([[7.1531663]], dtype=float32),\n",
       " array([[8.150739]], dtype=float32),\n",
       " array([[9.170023]], dtype=float32),\n",
       " array([[10.207016]], dtype=float32),\n",
       " array([[11.232786]], dtype=float32),\n",
       " array([[12.225167]], dtype=float32),\n",
       " array([[13.189014]], dtype=float32),\n",
       " array([[14.168154]], dtype=float32),\n",
       " array([[15.191155]], dtype=float32),\n",
       " array([[16.19788]], dtype=float32),\n",
       " array([[17.094429]], dtype=float32),\n",
       " array([[18.031693]], dtype=float32),\n",
       " array([[19.196915]], dtype=float32),\n",
       " array([[19.954847]], dtype=float32),\n",
       " array([[20.171795]], dtype=float32),\n",
       " array([[20.212263]], dtype=float32),\n",
       " array([[20.219105]], dtype=float32),\n",
       " array([[20.220247]], dtype=float32),\n",
       " array([[20.220432]], dtype=float32),\n",
       " array([[20.220463]], dtype=float32),\n",
       " array([[20.22047]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.22047]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.22047]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.22047]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.22047]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.22047]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.22047]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.22047]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.22047]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.22047]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.22047]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.22047]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.22047]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.220472]], dtype=float32),\n",
       " array([[20.22047]], dtype=float32)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "myrnn_model_v1 = MyRNNModelV1(maxlen=5)\n",
    "myrnn_model_v1.load_data([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30])\n",
    "myrnn_model_v1.build()\n",
    "myrnn_model_v1.train()\n",
    "myrnn_model_v1.predict(df_list=[1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18 samples, validate on 2 samples\n",
      "Epoch 1/500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 586.0362 - val_loss: 321.8217\n",
      "Epoch 2/500\n",
      "18/18 [==============================] - 0s 229us/step - loss: 583.8327 - val_loss: 319.8930\n",
      "Epoch 3/500\n",
      "18/18 [==============================] - 0s 308us/step - loss: 581.5438 - val_loss: 317.9267\n",
      "Epoch 4/500\n",
      "18/18 [==============================] - 0s 205us/step - loss: 579.1268 - val_loss: 315.9119\n",
      "Epoch 5/500\n",
      "18/18 [==============================] - 0s 224us/step - loss: 576.6974 - val_loss: 313.8522\n",
      "Epoch 6/500\n",
      "18/18 [==============================] - 0s 275us/step - loss: 574.2220 - val_loss: 311.7257\n",
      "Epoch 7/500\n",
      "18/18 [==============================] - 0s 289us/step - loss: 571.6840 - val_loss: 309.5424\n",
      "Epoch 8/500\n",
      "18/18 [==============================] - 0s 200us/step - loss: 569.0107 - val_loss: 307.2978\n",
      "Epoch 9/500\n",
      "18/18 [==============================] - 0s 272us/step - loss: 566.3208 - val_loss: 304.9879\n",
      "Epoch 10/500\n",
      "18/18 [==============================] - 0s 299us/step - loss: 563.5455 - val_loss: 302.6103\n",
      "Epoch 11/500\n",
      "18/18 [==============================] - 0s 198us/step - loss: 560.6949 - val_loss: 300.1423\n",
      "Epoch 12/500\n",
      "18/18 [==============================] - 0s 226us/step - loss: 557.7708 - val_loss: 297.6060\n",
      "Epoch 13/500\n",
      "18/18 [==============================] - 0s 399us/step - loss: 554.8230 - val_loss: 294.9832\n",
      "Epoch 14/500\n",
      "18/18 [==============================] - 0s 204us/step - loss: 551.8016 - val_loss: 292.2668\n",
      "Epoch 15/500\n",
      "18/18 [==============================] - 0s 500us/step - loss: 548.7858 - val_loss: 289.4456\n",
      "Epoch 16/500\n",
      "18/18 [==============================] - 0s 203us/step - loss: 545.6933 - val_loss: 286.5186\n",
      "Epoch 17/500\n",
      "18/18 [==============================] - 0s 210us/step - loss: 542.5523 - val_loss: 283.4735\n",
      "Epoch 18/500\n",
      "18/18 [==============================] - 0s 304us/step - loss: 539.3582 - val_loss: 280.2911\n",
      "Epoch 19/500\n",
      "18/18 [==============================] - 0s 309us/step - loss: 536.0860 - val_loss: 276.9862\n",
      "Epoch 20/500\n",
      "18/18 [==============================] - 0s 198us/step - loss: 532.7201 - val_loss: 273.5354\n",
      "Epoch 21/500\n",
      "18/18 [==============================] - 0s 245us/step - loss: 529.2419 - val_loss: 269.9066\n",
      "Epoch 22/500\n",
      "18/18 [==============================] - 0s 372us/step - loss: 525.6003 - val_loss: 266.1230\n",
      "Epoch 23/500\n",
      "18/18 [==============================] - 0s 245us/step - loss: 521.8114 - val_loss: 262.2197\n",
      "Epoch 24/500\n",
      "18/18 [==============================] - 0s 350us/step - loss: 517.8808 - val_loss: 258.1339\n",
      "Epoch 25/500\n",
      "18/18 [==============================] - 0s 342us/step - loss: 513.7871 - val_loss: 253.8800\n",
      "Epoch 26/500\n",
      "18/18 [==============================] - 0s 204us/step - loss: 509.4668 - val_loss: 249.4424\n",
      "Epoch 27/500\n",
      "18/18 [==============================] - 0s 343us/step - loss: 505.0266 - val_loss: 244.8633\n",
      "Epoch 28/500\n",
      "18/18 [==============================] - 0s 295us/step - loss: 500.3539 - val_loss: 240.1076\n",
      "Epoch 29/500\n",
      "18/18 [==============================] - 0s 297us/step - loss: 495.5092 - val_loss: 235.2259\n",
      "Epoch 30/500\n",
      "18/18 [==============================] - 0s 419us/step - loss: 490.4200 - val_loss: 230.2508\n",
      "Epoch 31/500\n",
      "18/18 [==============================] - 0s 238us/step - loss: 485.2410 - val_loss: 225.2200\n",
      "Epoch 32/500\n",
      "18/18 [==============================] - 0s 254us/step - loss: 479.7955 - val_loss: 220.2141\n",
      "Epoch 33/500\n",
      "18/18 [==============================] - 0s 319us/step - loss: 474.4210 - val_loss: 215.2811\n",
      "Epoch 34/500\n",
      "18/18 [==============================] - 0s 335us/step - loss: 468.6142 - val_loss: 210.5300\n",
      "Epoch 35/500\n",
      "18/18 [==============================] - 0s 241us/step - loss: 462.5604 - val_loss: 205.9902\n",
      "Epoch 36/500\n",
      "18/18 [==============================] - 0s 412us/step - loss: 456.7604 - val_loss: 201.7252\n",
      "Epoch 37/500\n",
      "18/18 [==============================] - 0s 220us/step - loss: 450.1014 - val_loss: 197.7454\n",
      "Epoch 38/500\n",
      "18/18 [==============================] - 0s 346us/step - loss: 443.7088 - val_loss: 194.0427\n",
      "Epoch 39/500\n",
      "18/18 [==============================] - 0s 261us/step - loss: 437.2767 - val_loss: 190.6094\n",
      "Epoch 40/500\n",
      "18/18 [==============================] - 0s 232us/step - loss: 430.2346 - val_loss: 187.4556\n",
      "Epoch 41/500\n",
      "18/18 [==============================] - 0s 271us/step - loss: 424.5192 - val_loss: 184.5266\n",
      "Epoch 42/500\n",
      "18/18 [==============================] - 0s 246us/step - loss: 418.1065 - val_loss: 181.8395\n",
      "Epoch 43/500\n",
      "18/18 [==============================] - 0s 372us/step - loss: 411.8953 - val_loss: 179.3794\n",
      "Epoch 44/500\n",
      "18/18 [==============================] - 0s 240us/step - loss: 405.6195 - val_loss: 177.1237\n",
      "Epoch 45/500\n",
      "18/18 [==============================] - 0s 381us/step - loss: 400.5366 - val_loss: 175.0208\n",
      "Epoch 46/500\n",
      "18/18 [==============================] - 0s 209us/step - loss: 395.3404 - val_loss: 173.0824\n",
      "Epoch 47/500\n",
      "18/18 [==============================] - 0s 322us/step - loss: 391.0298 - val_loss: 171.2554\n",
      "Epoch 48/500\n",
      "18/18 [==============================] - 0s 292us/step - loss: 387.1890 - val_loss: 169.5160\n",
      "Epoch 49/500\n",
      "18/18 [==============================] - 0s 209us/step - loss: 383.2439 - val_loss: 167.8538\n",
      "Epoch 50/500\n",
      "18/18 [==============================] - 0s 326us/step - loss: 379.5472 - val_loss: 166.2349\n",
      "Epoch 51/500\n",
      "18/18 [==============================] - 0s 329us/step - loss: 376.6060 - val_loss: 164.6156\n",
      "Epoch 52/500\n",
      "18/18 [==============================] - 0s 203us/step - loss: 373.8151 - val_loss: 162.9736\n",
      "Epoch 53/500\n",
      "18/18 [==============================] - 0s 375us/step - loss: 370.8550 - val_loss: 161.3010\n",
      "Epoch 54/500\n",
      "18/18 [==============================] - 0s 276us/step - loss: 368.4669 - val_loss: 159.5663\n",
      "Epoch 55/500\n",
      "18/18 [==============================] - 0s 250us/step - loss: 366.1277 - val_loss: 157.7649\n",
      "Epoch 56/500\n",
      "18/18 [==============================] - 0s 317us/step - loss: 363.8974 - val_loss: 155.8961\n",
      "Epoch 57/500\n",
      "18/18 [==============================] - 0s 389us/step - loss: 361.7203 - val_loss: 153.9664\n",
      "Epoch 58/500\n",
      "18/18 [==============================] - 0s 321us/step - loss: 359.6376 - val_loss: 151.9896\n",
      "Epoch 59/500\n",
      "18/18 [==============================] - 0s 260us/step - loss: 357.6189 - val_loss: 149.9871\n",
      "Epoch 60/500\n",
      "18/18 [==============================] - 0s 252us/step - loss: 355.6511 - val_loss: 147.9908\n",
      "Epoch 61/500\n",
      "18/18 [==============================] - 0s 262us/step - loss: 353.5822 - val_loss: 146.0360\n",
      "Epoch 62/500\n",
      "18/18 [==============================] - 0s 281us/step - loss: 351.6001 - val_loss: 144.1333\n",
      "Epoch 63/500\n",
      "18/18 [==============================] - 0s 245us/step - loss: 349.4935 - val_loss: 142.3107\n",
      "Epoch 64/500\n",
      "18/18 [==============================] - 0s 234us/step - loss: 347.4619 - val_loss: 140.5836\n",
      "Epoch 65/500\n",
      "18/18 [==============================] - 0s 272us/step - loss: 345.3195 - val_loss: 138.9704\n",
      "Epoch 66/500\n",
      "18/18 [==============================] - 0s 254us/step - loss: 343.1460 - val_loss: 137.4810\n",
      "Epoch 67/500\n",
      "18/18 [==============================] - 0s 244us/step - loss: 340.9088 - val_loss: 136.1115\n",
      "Epoch 68/500\n",
      "18/18 [==============================] - 0s 329us/step - loss: 338.5979 - val_loss: 134.8508\n",
      "Epoch 69/500\n",
      "18/18 [==============================] - 0s 220us/step - loss: 336.0846 - val_loss: 133.6821\n",
      "Epoch 70/500\n",
      "18/18 [==============================] - 0s 227us/step - loss: 333.7132 - val_loss: 132.5779\n",
      "Epoch 71/500\n",
      "18/18 [==============================] - 0s 354us/step - loss: 331.1299 - val_loss: 131.5326\n",
      "Epoch 72/500\n",
      "18/18 [==============================] - 0s 239us/step - loss: 328.5586 - val_loss: 130.5296\n",
      "Epoch 73/500\n",
      "18/18 [==============================] - 0s 220us/step - loss: 326.0099 - val_loss: 129.5601\n",
      "Epoch 74/500\n",
      "18/18 [==============================] - 0s 381us/step - loss: 323.3943 - val_loss: 128.6179\n",
      "Epoch 75/500\n",
      "18/18 [==============================] - 0s 261us/step - loss: 320.8093 - val_loss: 127.6984\n",
      "Epoch 76/500\n",
      "18/18 [==============================] - 0s 223us/step - loss: 318.4592 - val_loss: 126.7904\n",
      "Epoch 77/500\n",
      "18/18 [==============================] - 0s 253us/step - loss: 316.1541 - val_loss: 125.8969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500\n",
      "18/18 [==============================] - 0s 216us/step - loss: 314.1762 - val_loss: 125.0083\n",
      "Epoch 79/500\n",
      "18/18 [==============================] - 0s 259us/step - loss: 312.2128 - val_loss: 124.1279\n",
      "Epoch 80/500\n",
      "18/18 [==============================] - 0s 216us/step - loss: 310.4470 - val_loss: 123.2592\n",
      "Epoch 81/500\n",
      "18/18 [==============================] - 0s 398us/step - loss: 308.7175 - val_loss: 122.3975\n",
      "Epoch 82/500\n",
      "18/18 [==============================] - 0s 264us/step - loss: 307.2048 - val_loss: 121.5393\n",
      "Epoch 83/500\n",
      "18/18 [==============================] - 0s 205us/step - loss: 305.7174 - val_loss: 120.6830\n",
      "Epoch 84/500\n",
      "18/18 [==============================] - 0s 305us/step - loss: 304.2748 - val_loss: 119.8278\n",
      "Epoch 85/500\n",
      "18/18 [==============================] - 0s 208us/step - loss: 302.8939 - val_loss: 118.9710\n",
      "Epoch 86/500\n",
      "18/18 [==============================] - 0s 199us/step - loss: 301.5271 - val_loss: 118.1116\n",
      "Epoch 87/500\n",
      "18/18 [==============================] - 0s 392us/step - loss: 300.2003 - val_loss: 117.2468\n",
      "Epoch 88/500\n",
      "18/18 [==============================] - 0s 201us/step - loss: 298.8501 - val_loss: 116.3779\n",
      "Epoch 89/500\n",
      "18/18 [==============================] - 0s 211us/step - loss: 297.5313 - val_loss: 115.4953\n",
      "Epoch 90/500\n",
      "18/18 [==============================] - 0s 228us/step - loss: 296.2041 - val_loss: 114.5940\n",
      "Epoch 91/500\n",
      "18/18 [==============================] - 0s 261us/step - loss: 294.8808 - val_loss: 113.6683\n",
      "Epoch 92/500\n",
      "18/18 [==============================] - 0s 320us/step - loss: 293.5676 - val_loss: 112.7131\n",
      "Epoch 93/500\n",
      "18/18 [==============================] - 0s 242us/step - loss: 292.2859 - val_loss: 111.7196\n",
      "Epoch 94/500\n",
      "18/18 [==============================] - 0s 274us/step - loss: 290.9847 - val_loss: 110.6862\n",
      "Epoch 95/500\n",
      "18/18 [==============================] - 0s 241us/step - loss: 289.6695 - val_loss: 109.6165\n",
      "Epoch 96/500\n",
      "18/18 [==============================] - 0s 223us/step - loss: 288.3321 - val_loss: 108.5128\n",
      "Epoch 97/500\n",
      "18/18 [==============================] - 0s 396us/step - loss: 287.0193 - val_loss: 107.3753\n",
      "Epoch 98/500\n",
      "18/18 [==============================] - 0s 197us/step - loss: 285.6519 - val_loss: 106.2116\n",
      "Epoch 99/500\n",
      "18/18 [==============================] - 0s 221us/step - loss: 284.3089 - val_loss: 105.0272\n",
      "Epoch 100/500\n",
      "18/18 [==============================] - 0s 333us/step - loss: 282.9247 - val_loss: 103.8356\n",
      "Epoch 101/500\n",
      "18/18 [==============================] - 0s 212us/step - loss: 281.5064 - val_loss: 102.6488\n",
      "Epoch 102/500\n",
      "18/18 [==============================] - 0s 201us/step - loss: 280.1006 - val_loss: 101.4738\n",
      "Epoch 103/500\n",
      "18/18 [==============================] - 0s 357us/step - loss: 278.6157 - val_loss: 100.3239\n",
      "Epoch 104/500\n",
      "18/18 [==============================] - 0s 290us/step - loss: 277.1435 - val_loss: 99.2061\n",
      "Epoch 105/500\n",
      "18/18 [==============================] - 0s 201us/step - loss: 275.6417 - val_loss: 98.1322\n",
      "Epoch 106/500\n",
      "18/18 [==============================] - 0s 275us/step - loss: 274.0160 - val_loss: 97.1129\n",
      "Epoch 107/500\n",
      "18/18 [==============================] - 0s 273us/step - loss: 272.3572 - val_loss: 96.1488\n",
      "Epoch 108/500\n",
      "18/18 [==============================] - 0s 194us/step - loss: 270.8479 - val_loss: 95.2309\n",
      "Epoch 109/500\n",
      "18/18 [==============================] - 0s 203us/step - loss: 269.1468 - val_loss: 94.3724\n",
      "Epoch 110/500\n",
      "18/18 [==============================] - 0s 264us/step - loss: 267.4526 - val_loss: 93.5641\n",
      "Epoch 111/500\n",
      "18/18 [==============================] - 0s 226us/step - loss: 265.7637 - val_loss: 92.7971\n",
      "Epoch 112/500\n",
      "18/18 [==============================] - 0s 199us/step - loss: 264.0516 - val_loss: 92.0638\n",
      "Epoch 113/500\n",
      "18/18 [==============================] - 0s 281us/step - loss: 262.4887 - val_loss: 91.3501\n",
      "Epoch 114/500\n",
      "18/18 [==============================] - 0s 322us/step - loss: 260.8663 - val_loss: 90.6559\n",
      "Epoch 115/500\n",
      "18/18 [==============================] - 0s 224us/step - loss: 259.4147 - val_loss: 89.9700\n",
      "Epoch 116/500\n",
      "18/18 [==============================] - 0s 244us/step - loss: 258.0101 - val_loss: 89.2920\n",
      "Epoch 117/500\n",
      "18/18 [==============================] - 0s 223us/step - loss: 256.5293 - val_loss: 88.6253\n",
      "Epoch 118/500\n",
      "18/18 [==============================] - 0s 197us/step - loss: 255.2095 - val_loss: 87.9617\n",
      "Epoch 119/500\n",
      "18/18 [==============================] - 0s 218us/step - loss: 253.9718 - val_loss: 87.2980\n",
      "Epoch 120/500\n",
      "18/18 [==============================] - 0s 265us/step - loss: 252.7268 - val_loss: 86.6395\n",
      "Epoch 121/500\n",
      "18/18 [==============================] - 0s 248us/step - loss: 251.5916 - val_loss: 85.9796\n",
      "Epoch 122/500\n",
      "18/18 [==============================] - 0s 230us/step - loss: 250.3950 - val_loss: 85.3275\n",
      "Epoch 123/500\n",
      "18/18 [==============================] - 0s 306us/step - loss: 249.2583 - val_loss: 84.6783\n",
      "Epoch 124/500\n",
      "18/18 [==============================] - 0s 228us/step - loss: 248.1846 - val_loss: 84.0302\n",
      "Epoch 125/500\n",
      "18/18 [==============================] - 0s 226us/step - loss: 247.0510 - val_loss: 83.3899\n",
      "Epoch 126/500\n",
      "18/18 [==============================] - 0s 223us/step - loss: 245.9578 - val_loss: 82.7542\n",
      "Epoch 127/500\n",
      "18/18 [==============================] - 0s 247us/step - loss: 244.8997 - val_loss: 82.1205\n",
      "Epoch 128/500\n",
      "18/18 [==============================] - 0s 216us/step - loss: 243.8323 - val_loss: 81.4911\n",
      "Epoch 129/500\n",
      "18/18 [==============================] - 0s 223us/step - loss: 242.7731 - val_loss: 80.8668\n",
      "Epoch 130/500\n",
      "18/18 [==============================] - 0s 242us/step - loss: 241.7162 - val_loss: 80.2469\n",
      "Epoch 131/500\n",
      "18/18 [==============================] - 0s 231us/step - loss: 240.6795 - val_loss: 79.6300\n",
      "Epoch 132/500\n",
      "18/18 [==============================] - 0s 204us/step - loss: 239.6511 - val_loss: 79.0161\n",
      "Epoch 133/500\n",
      "18/18 [==============================] - 0s 272us/step - loss: 238.5899 - val_loss: 78.4078\n",
      "Epoch 134/500\n",
      "18/18 [==============================] - 0s 280us/step - loss: 237.6365 - val_loss: 77.7956\n",
      "Epoch 135/500\n",
      "18/18 [==============================] - 0s 217us/step - loss: 236.6089 - val_loss: 77.1887\n",
      "Epoch 136/500\n",
      "18/18 [==============================] - 0s 210us/step - loss: 235.5863 - val_loss: 76.5873\n",
      "Epoch 137/500\n",
      "18/18 [==============================] - 0s 319us/step - loss: 234.5733 - val_loss: 75.9891\n",
      "Epoch 138/500\n",
      "18/18 [==============================] - 0s 268us/step - loss: 233.5791 - val_loss: 75.3941\n",
      "Epoch 139/500\n",
      "18/18 [==============================] - 0s 209us/step - loss: 232.5787 - val_loss: 74.8026\n",
      "Epoch 140/500\n",
      "18/18 [==============================] - 0s 263us/step - loss: 231.5870 - val_loss: 74.2138\n",
      "Epoch 141/500\n",
      "18/18 [==============================] - 0s 233us/step - loss: 230.6184 - val_loss: 73.6263\n",
      "Epoch 142/500\n",
      "18/18 [==============================] - 0s 254us/step - loss: 229.6519 - val_loss: 73.0412\n",
      "Epoch 143/500\n",
      "18/18 [==============================] - 0s 231us/step - loss: 228.6753 - val_loss: 72.4605\n",
      "Epoch 144/500\n",
      "18/18 [==============================] - 0s 368us/step - loss: 227.6666 - val_loss: 71.8862\n",
      "Epoch 145/500\n",
      "18/18 [==============================] - 0s 254us/step - loss: 226.7204 - val_loss: 71.3128\n",
      "Epoch 146/500\n",
      "18/18 [==============================] - 0s 216us/step - loss: 225.7849 - val_loss: 70.7406\n",
      "Epoch 147/500\n",
      "18/18 [==============================] - 0s 283us/step - loss: 224.7722 - val_loss: 70.1771\n",
      "Epoch 148/500\n",
      "18/18 [==============================] - 0s 223us/step - loss: 223.8363 - val_loss: 69.6136\n",
      "Epoch 149/500\n",
      "18/18 [==============================] - 0s 225us/step - loss: 222.9135 - val_loss: 69.0507\n",
      "Epoch 150/500\n",
      "18/18 [==============================] - 0s 250us/step - loss: 221.9160 - val_loss: 68.4955\n",
      "Epoch 151/500\n",
      "18/18 [==============================] - 0s 217us/step - loss: 221.0248 - val_loss: 67.9378\n",
      "Epoch 152/500\n",
      "18/18 [==============================] - 0s 211us/step - loss: 220.0354 - val_loss: 67.3878\n",
      "Epoch 153/500\n",
      "18/18 [==============================] - 0s 277us/step - loss: 219.1506 - val_loss: 66.8357\n",
      "Epoch 154/500\n",
      "18/18 [==============================] - 0s 238us/step - loss: 218.2301 - val_loss: 66.2870\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 245us/step - loss: 217.2557 - val_loss: 65.7467\n",
      "Epoch 156/500\n",
      "18/18 [==============================] - 0s 202us/step - loss: 216.3569 - val_loss: 65.2070\n",
      "Epoch 157/500\n",
      "18/18 [==============================] - 0s 280us/step - loss: 215.4292 - val_loss: 64.6715\n",
      "Epoch 158/500\n",
      "18/18 [==============================] - 0s 242us/step - loss: 214.5014 - val_loss: 64.1396\n",
      "Epoch 159/500\n",
      "18/18 [==============================] - 0s 313us/step - loss: 213.6085 - val_loss: 63.6090\n",
      "Epoch 160/500\n",
      "18/18 [==============================] - 0s 235us/step - loss: 212.7196 - val_loss: 63.0804\n",
      "Epoch 161/500\n",
      "18/18 [==============================] - 0s 258us/step - loss: 211.8024 - val_loss: 62.5571\n",
      "Epoch 162/500\n",
      "18/18 [==============================] - 0s 199us/step - loss: 210.8980 - val_loss: 62.0377\n",
      "Epoch 163/500\n",
      "18/18 [==============================] - 0s 219us/step - loss: 209.9986 - val_loss: 61.5214\n",
      "Epoch 164/500\n",
      "18/18 [==============================] - 0s 236us/step - loss: 209.0893 - val_loss: 61.0095\n",
      "Epoch 165/500\n",
      "18/18 [==============================] - 0s 225us/step - loss: 208.2182 - val_loss: 60.4980\n",
      "Epoch 166/500\n",
      "18/18 [==============================] - 0s 268us/step - loss: 207.3351 - val_loss: 59.9888\n",
      "Epoch 167/500\n",
      "18/18 [==============================] - 0s 260us/step - loss: 206.4735 - val_loss: 59.4809\n",
      "Epoch 168/500\n",
      "18/18 [==============================] - 0s 246us/step - loss: 205.5572 - val_loss: 58.9798\n",
      "Epoch 169/500\n",
      "18/18 [==============================] - 0s 210us/step - loss: 204.6960 - val_loss: 58.4797\n",
      "Epoch 170/500\n",
      "18/18 [==============================] - 0s 268us/step - loss: 203.8190 - val_loss: 57.9825\n",
      "Epoch 171/500\n",
      "18/18 [==============================] - 0s 242us/step - loss: 202.9107 - val_loss: 57.4904\n",
      "Epoch 172/500\n",
      "18/18 [==============================] - 0s 236us/step - loss: 202.1083 - val_loss: 56.9939\n",
      "Epoch 173/500\n",
      "18/18 [==============================] - 0s 239us/step - loss: 201.2284 - val_loss: 56.5023\n",
      "Epoch 174/500\n",
      "18/18 [==============================] - 0s 215us/step - loss: 200.3592 - val_loss: 56.0144\n",
      "Epoch 175/500\n",
      "18/18 [==============================] - 0s 257us/step - loss: 199.4975 - val_loss: 55.5289\n",
      "Epoch 176/500\n",
      "18/18 [==============================] - ETA: 0s - loss: 175.620 - 0s 313us/step - loss: 198.6338 - val_loss: 55.0471\n",
      "Epoch 177/500\n",
      "18/18 [==============================] - 0s 209us/step - loss: 197.7731 - val_loss: 54.5680\n",
      "Epoch 178/500\n",
      "18/18 [==============================] - 0s 200us/step - loss: 196.9839 - val_loss: 54.0866\n",
      "Epoch 179/500\n",
      "18/18 [==============================] - 0s 261us/step - loss: 196.0552 - val_loss: 53.6155\n",
      "Epoch 180/500\n",
      "18/18 [==============================] - 0s 302us/step - loss: 195.2530 - val_loss: 53.1424\n",
      "Epoch 181/500\n",
      "18/18 [==============================] - 0s 214us/step - loss: 194.4252 - val_loss: 52.6712\n",
      "Epoch 182/500\n",
      "18/18 [==============================] - 0s 293us/step - loss: 193.5774 - val_loss: 52.2040\n",
      "Epoch 183/500\n",
      "18/18 [==============================] - 0s 195us/step - loss: 192.7688 - val_loss: 51.7384\n",
      "Epoch 184/500\n",
      "18/18 [==============================] - 0s 224us/step - loss: 191.8958 - val_loss: 51.2801\n",
      "Epoch 185/500\n",
      "18/18 [==============================] - 0s 296us/step - loss: 191.0849 - val_loss: 50.8223\n",
      "Epoch 186/500\n",
      "18/18 [==============================] - 0s 264us/step - loss: 190.2711 - val_loss: 50.3668\n",
      "Epoch 187/500\n",
      "18/18 [==============================] - 0s 307us/step - loss: 189.4684 - val_loss: 49.9133\n",
      "Epoch 188/500\n",
      "18/18 [==============================] - 0s 241us/step - loss: 188.6187 - val_loss: 49.4660\n",
      "Epoch 189/500\n",
      "18/18 [==============================] - 0s 224us/step - loss: 187.8066 - val_loss: 49.0208\n",
      "Epoch 190/500\n",
      "18/18 [==============================] - 0s 215us/step - loss: 187.0249 - val_loss: 48.5757\n",
      "Epoch 191/500\n",
      "18/18 [==============================] - 0s 212us/step - loss: 186.2307 - val_loss: 48.1332\n",
      "Epoch 192/500\n",
      "18/18 [==============================] - 0s 296us/step - loss: 185.3878 - val_loss: 47.6972\n",
      "Epoch 193/500\n",
      "18/18 [==============================] - 0s 219us/step - loss: 184.6162 - val_loss: 47.2615\n",
      "Epoch 194/500\n",
      "18/18 [==============================] - 0s 259us/step - loss: 183.8169 - val_loss: 46.8291\n",
      "Epoch 195/500\n",
      "18/18 [==============================] - 0s 346us/step - loss: 183.0355 - val_loss: 46.3988\n",
      "Epoch 196/500\n",
      "18/18 [==============================] - 0s 219us/step - loss: 182.2233 - val_loss: 45.9736\n",
      "Epoch 197/500\n",
      "18/18 [==============================] - 0s 252us/step - loss: 181.4088 - val_loss: 45.5524\n",
      "Epoch 198/500\n",
      "18/18 [==============================] - 0s 215us/step - loss: 180.6524 - val_loss: 45.1297\n",
      "Epoch 199/500\n",
      "18/18 [==============================] - 0s 301us/step - loss: 179.8812 - val_loss: 44.7082\n",
      "Epoch 200/500\n",
      "18/18 [==============================] - 0s 199us/step - loss: 179.1278 - val_loss: 44.2875\n",
      "Epoch 201/500\n",
      "18/18 [==============================] - 0s 229us/step - loss: 178.3165 - val_loss: 43.8730\n",
      "Epoch 202/500\n",
      "18/18 [==============================] - 0s 206us/step - loss: 177.5556 - val_loss: 43.4599\n",
      "Epoch 203/500\n",
      "18/18 [==============================] - 0s 289us/step - loss: 176.7647 - val_loss: 43.0508\n",
      "Epoch 204/500\n",
      "18/18 [==============================] - 0s 206us/step - loss: 175.9986 - val_loss: 42.6433\n",
      "Epoch 205/500\n",
      "18/18 [==============================] - 0s 216us/step - loss: 175.2628 - val_loss: 42.2352\n",
      "Epoch 206/500\n",
      "18/18 [==============================] - 0s 271us/step - loss: 174.4814 - val_loss: 41.8319\n",
      "Epoch 207/500\n",
      "18/18 [==============================] - 0s 201us/step - loss: 173.6907 - val_loss: 41.4329\n",
      "Epoch 208/500\n",
      "18/18 [==============================] - 0s 226us/step - loss: 172.9893 - val_loss: 41.0309\n",
      "Epoch 209/500\n",
      "18/18 [==============================] - 0s 231us/step - loss: 172.1883 - val_loss: 40.6357\n",
      "Epoch 210/500\n",
      "18/18 [==============================] - 0s 256us/step - loss: 171.4944 - val_loss: 40.2380\n",
      "Epoch 211/500\n",
      "18/18 [==============================] - 0s 199us/step - loss: 170.6817 - val_loss: 39.8486\n",
      "Epoch 212/500\n",
      "18/18 [==============================] - 0s 223us/step - loss: 169.9704 - val_loss: 39.4581\n",
      "Epoch 213/500\n",
      "18/18 [==============================] - 0s 226us/step - loss: 169.2125 - val_loss: 39.0715\n",
      "Epoch 214/500\n",
      "18/18 [==============================] - 0s 264us/step - loss: 168.4891 - val_loss: 38.6861\n",
      "Epoch 215/500\n",
      "18/18 [==============================] - 0s 230us/step - loss: 167.8004 - val_loss: 38.3006\n",
      "Epoch 216/500\n",
      "18/18 [==============================] - 0s 205us/step - loss: 167.0420 - val_loss: 37.9222\n",
      "Epoch 217/500\n",
      "18/18 [==============================] - 0s 337us/step - loss: 166.3166 - val_loss: 37.5479\n",
      "Epoch 218/500\n",
      "18/18 [==============================] - 0s 210us/step - loss: 165.6024 - val_loss: 37.1771\n",
      "Epoch 219/500\n",
      "18/18 [==============================] - 0s 244us/step - loss: 164.8335 - val_loss: 36.8138\n",
      "Epoch 220/500\n",
      "18/18 [==============================] - 0s 249us/step - loss: 164.1638 - val_loss: 36.4489\n",
      "Epoch 221/500\n",
      "18/18 [==============================] - 0s 245us/step - loss: 163.4377 - val_loss: 36.0882\n",
      "Epoch 222/500\n",
      "18/18 [==============================] - 0s 231us/step - loss: 162.7645 - val_loss: 35.7279\n",
      "Epoch 223/500\n",
      "18/18 [==============================] - 0s 212us/step - loss: 162.0136 - val_loss: 35.3743\n",
      "Epoch 224/500\n",
      "18/18 [==============================] - 0s 256us/step - loss: 161.3224 - val_loss: 35.0215\n",
      "Epoch 225/500\n",
      "18/18 [==============================] - 0s 268us/step - loss: 160.5868 - val_loss: 34.6728\n",
      "Epoch 226/500\n",
      "18/18 [==============================] - 0s 268us/step - loss: 159.9453 - val_loss: 34.3203\n",
      "Epoch 227/500\n",
      "18/18 [==============================] - 0s 246us/step - loss: 159.2342 - val_loss: 33.9714\n",
      "Epoch 228/500\n",
      "18/18 [==============================] - 0s 237us/step - loss: 158.5533 - val_loss: 33.6236\n",
      "Epoch 229/500\n",
      "18/18 [==============================] - 0s 394us/step - loss: 157.8681 - val_loss: 33.2779\n",
      "Epoch 230/500\n",
      "18/18 [==============================] - 0s 262us/step - loss: 157.2083 - val_loss: 32.9334\n",
      "Epoch 231/500\n",
      "18/18 [==============================] - 0s 215us/step - loss: 156.4899 - val_loss: 32.5951\n",
      "Epoch 232/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 295us/step - loss: 155.8039 - val_loss: 32.2595\n",
      "Epoch 233/500\n",
      "18/18 [==============================] - 0s 218us/step - loss: 155.1090 - val_loss: 31.9268\n",
      "Epoch 234/500\n",
      "18/18 [==============================] - 0s 291us/step - loss: 154.4799 - val_loss: 31.5926\n",
      "Epoch 235/500\n",
      "18/18 [==============================] - 0s 287us/step - loss: 153.7951 - val_loss: 31.2622\n",
      "Epoch 236/500\n",
      "18/18 [==============================] - 0s 254us/step - loss: 153.0961 - val_loss: 30.9363\n",
      "Epoch 237/500\n",
      "18/18 [==============================] - 0s 270us/step - loss: 152.4562 - val_loss: 30.6102\n",
      "Epoch 238/500\n",
      "18/18 [==============================] - 0s 273us/step - loss: 151.7820 - val_loss: 30.2870\n",
      "Epoch 239/500\n",
      "18/18 [==============================] - 0s 276us/step - loss: 151.1118 - val_loss: 29.9665\n",
      "Epoch 240/500\n",
      "18/18 [==============================] - 0s 200us/step - loss: 150.4932 - val_loss: 29.6452\n",
      "Epoch 241/500\n",
      "18/18 [==============================] - 0s 250us/step - loss: 149.8078 - val_loss: 29.3291\n",
      "Epoch 242/500\n",
      "18/18 [==============================] - 0s 255us/step - loss: 149.1855 - val_loss: 29.0135\n",
      "Epoch 243/500\n",
      "18/18 [==============================] - 0s 334us/step - loss: 148.5002 - val_loss: 28.7036\n",
      "Epoch 244/500\n",
      "18/18 [==============================] - 0s 273us/step - loss: 147.8614 - val_loss: 28.3952\n",
      "Epoch 245/500\n",
      "18/18 [==============================] - 0s 418us/step - loss: 147.2132 - val_loss: 28.0891\n",
      "Epoch 246/500\n",
      "18/18 [==============================] - 0s 340us/step - loss: 146.5845 - val_loss: 27.7842\n",
      "Epoch 247/500\n",
      "18/18 [==============================] - 0s 234us/step - loss: 145.9460 - val_loss: 27.4817\n",
      "Epoch 248/500\n",
      "18/18 [==============================] - 0s 315us/step - loss: 145.2952 - val_loss: 27.1826\n",
      "Epoch 249/500\n",
      "18/18 [==============================] - 0s 281us/step - loss: 144.6936 - val_loss: 26.8833\n",
      "Epoch 250/500\n",
      "18/18 [==============================] - 0s 218us/step - loss: 144.0738 - val_loss: 26.5865\n",
      "Epoch 251/500\n",
      "18/18 [==============================] - 0s 286us/step - loss: 143.4096 - val_loss: 26.2955\n",
      "Epoch 252/500\n",
      "18/18 [==============================] - 0s 267us/step - loss: 142.7752 - val_loss: 26.0068\n",
      "Epoch 253/500\n",
      "18/18 [==============================] - 0s 293us/step - loss: 142.2038 - val_loss: 25.7164\n",
      "Epoch 254/500\n",
      "18/18 [==============================] - 0s 310us/step - loss: 141.5808 - val_loss: 25.4296\n",
      "Epoch 255/500\n",
      "18/18 [==============================] - 0s 215us/step - loss: 140.9257 - val_loss: 25.1482\n",
      "Epoch 256/500\n",
      "18/18 [==============================] - 0s 302us/step - loss: 140.3215 - val_loss: 24.8675\n",
      "Epoch 257/500\n",
      "18/18 [==============================] - 0s 401us/step - loss: 139.7170 - val_loss: 24.5879\n",
      "Epoch 258/500\n",
      "18/18 [==============================] - 0s 234us/step - loss: 139.1041 - val_loss: 24.3104\n",
      "Epoch 259/500\n",
      "18/18 [==============================] - 0s 670us/step - loss: 138.5098 - val_loss: 24.0336\n",
      "Epoch 260/500\n",
      "18/18 [==============================] - 0s 236us/step - loss: 137.9112 - val_loss: 23.7586\n",
      "Epoch 261/500\n",
      "18/18 [==============================] - 0s 226us/step - loss: 137.2936 - val_loss: 23.4869\n",
      "Epoch 262/500\n",
      "18/18 [==============================] - 0s 335us/step - loss: 136.7075 - val_loss: 23.2161\n",
      "Epoch 263/500\n",
      "18/18 [==============================] - 0s 252us/step - loss: 136.0748 - val_loss: 22.9496\n",
      "Epoch 264/500\n",
      "18/18 [==============================] - 0s 395us/step - loss: 135.5009 - val_loss: 22.6826\n",
      "Epoch 265/500\n",
      "18/18 [==============================] - 0s 303us/step - loss: 134.9433 - val_loss: 22.4153\n",
      "Epoch 266/500\n",
      "18/18 [==============================] - 0s 294us/step - loss: 134.3248 - val_loss: 22.1528\n",
      "Epoch 267/500\n",
      "18/18 [==============================] - 0s 224us/step - loss: 133.7447 - val_loss: 21.8922\n",
      "Epoch 268/500\n",
      "18/18 [==============================] - 0s 400us/step - loss: 133.1773 - val_loss: 21.6331\n",
      "Epoch 269/500\n",
      "18/18 [==============================] - 0s 278us/step - loss: 132.5949 - val_loss: 21.3772\n",
      "Epoch 270/500\n",
      "18/18 [==============================] - 0s 243us/step - loss: 132.0132 - val_loss: 21.1247\n",
      "Epoch 271/500\n",
      "18/18 [==============================] - 0s 264us/step - loss: 131.4413 - val_loss: 20.8749\n",
      "Epoch 272/500\n",
      "18/18 [==============================] - 0s 679us/step - loss: 130.8325 - val_loss: 20.6300\n",
      "Epoch 273/500\n",
      "18/18 [==============================] - 0s 321us/step - loss: 130.2709 - val_loss: 20.3856\n",
      "Epoch 274/500\n",
      "18/18 [==============================] - 0s 216us/step - loss: 129.7697 - val_loss: 20.1389\n",
      "Epoch 275/500\n",
      "18/18 [==============================] - 0s 224us/step - loss: 129.1891 - val_loss: 19.8969\n",
      "Epoch 276/500\n",
      "18/18 [==============================] - 0s 278us/step - loss: 128.5954 - val_loss: 19.6598\n",
      "Epoch 277/500\n",
      "18/18 [==============================] - 0s 329us/step - loss: 128.0437 - val_loss: 19.4238\n",
      "Epoch 278/500\n",
      "18/18 [==============================] - 0s 228us/step - loss: 127.4660 - val_loss: 19.1907\n",
      "Epoch 279/500\n",
      "18/18 [==============================] - 0s 327us/step - loss: 126.9588 - val_loss: 18.9556\n",
      "Epoch 280/500\n",
      "18/18 [==============================] - 0s 216us/step - loss: 126.4224 - val_loss: 18.7221\n",
      "Epoch 281/500\n",
      "18/18 [==============================] - 0s 221us/step - loss: 125.8944 - val_loss: 18.4908\n",
      "Epoch 282/500\n",
      "18/18 [==============================] - 0s 376us/step - loss: 125.2992 - val_loss: 18.2657\n",
      "Epoch 283/500\n",
      "18/18 [==============================] - 0s 293us/step - loss: 124.7761 - val_loss: 18.0414\n",
      "Epoch 284/500\n",
      "18/18 [==============================] - 0s 370us/step - loss: 124.2100 - val_loss: 17.8206\n",
      "Epoch 285/500\n",
      "18/18 [==============================] - 0s 234us/step - loss: 123.7106 - val_loss: 17.5987\n",
      "Epoch 286/500\n",
      "18/18 [==============================] - 0s 237us/step - loss: 123.1938 - val_loss: 17.3785\n",
      "Epoch 287/500\n",
      "18/18 [==============================] - 0s 211us/step - loss: 122.6124 - val_loss: 17.1637\n",
      "Epoch 288/500\n",
      "18/18 [==============================] - 0s 269us/step - loss: 122.1222 - val_loss: 16.9479\n",
      "Epoch 289/500\n",
      "18/18 [==============================] - 0s 240us/step - loss: 121.5603 - val_loss: 16.7362\n",
      "Epoch 290/500\n",
      "18/18 [==============================] - 0s 210us/step - loss: 121.0544 - val_loss: 16.5244\n",
      "Epoch 291/500\n",
      "18/18 [==============================] - 0s 232us/step - loss: 120.5369 - val_loss: 16.3139\n",
      "Epoch 292/500\n",
      "18/18 [==============================] - 0s 281us/step - loss: 120.0218 - val_loss: 16.1049\n",
      "Epoch 293/500\n",
      "18/18 [==============================] - 0s 219us/step - loss: 119.4984 - val_loss: 15.8980\n",
      "Epoch 294/500\n",
      "18/18 [==============================] - 0s 202us/step - loss: 118.9953 - val_loss: 15.6925\n",
      "Epoch 295/500\n",
      "18/18 [==============================] - 0s 249us/step - loss: 118.4747 - val_loss: 15.4897\n",
      "Epoch 296/500\n",
      "18/18 [==============================] - 0s 219us/step - loss: 117.9669 - val_loss: 15.2888\n",
      "Epoch 297/500\n",
      "18/18 [==============================] - 0s 227us/step - loss: 117.4895 - val_loss: 15.0887\n",
      "Epoch 298/500\n",
      "18/18 [==============================] - 0s 359us/step - loss: 116.9524 - val_loss: 14.8933\n",
      "Epoch 299/500\n",
      "18/18 [==============================] - 0s 325us/step - loss: 116.4493 - val_loss: 14.6999\n",
      "Epoch 300/500\n",
      "18/18 [==============================] - 0s 198us/step - loss: 115.9393 - val_loss: 14.5088\n",
      "Epoch 301/500\n",
      "18/18 [==============================] - 0s 252us/step - loss: 115.4587 - val_loss: 14.3182\n",
      "Epoch 302/500\n",
      "18/18 [==============================] - 0s 245us/step - loss: 114.9762 - val_loss: 14.1287\n",
      "Epoch 303/500\n",
      "18/18 [==============================] - 0s 277us/step - loss: 114.4530 - val_loss: 13.9430\n",
      "Epoch 304/500\n",
      "18/18 [==============================] - 0s 282us/step - loss: 113.9693 - val_loss: 13.7579\n",
      "Epoch 305/500\n",
      "18/18 [==============================] - 0s 264us/step - loss: 113.4949 - val_loss: 13.5734\n",
      "Epoch 306/500\n",
      "18/18 [==============================] - 0s 275us/step - loss: 113.0146 - val_loss: 13.3903\n",
      "Epoch 307/500\n",
      "18/18 [==============================] - 0s 243us/step - loss: 112.5109 - val_loss: 13.2102\n",
      "Epoch 308/500\n",
      "18/18 [==============================] - 0s 277us/step - loss: 112.0549 - val_loss: 13.0302\n",
      "Epoch 309/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 284us/step - loss: 111.5558 - val_loss: 12.8533\n",
      "Epoch 310/500\n",
      "18/18 [==============================] - 0s 206us/step - loss: 111.0816 - val_loss: 12.6779\n",
      "Epoch 311/500\n",
      "18/18 [==============================] - 0s 276us/step - loss: 110.6160 - val_loss: 12.5038\n",
      "Epoch 312/500\n",
      "18/18 [==============================] - 0s 218us/step - loss: 110.1661 - val_loss: 12.3308\n",
      "Epoch 313/500\n",
      "18/18 [==============================] - 0s 216us/step - loss: 109.6593 - val_loss: 12.1623\n",
      "Epoch 314/500\n",
      "18/18 [==============================] - 0s 233us/step - loss: 109.1831 - val_loss: 11.9957\n",
      "Epoch 315/500\n",
      "18/18 [==============================] - 0s 244us/step - loss: 108.7254 - val_loss: 11.8299\n",
      "Epoch 316/500\n",
      "18/18 [==============================] - 0s 294us/step - loss: 108.2826 - val_loss: 11.6645\n",
      "Epoch 317/500\n",
      "18/18 [==============================] - 0s 201us/step - loss: 107.8526 - val_loss: 11.4999\n",
      "Epoch 318/500\n",
      "18/18 [==============================] - 0s 211us/step - loss: 107.3440 - val_loss: 11.3405\n",
      "Epoch 319/500\n",
      "18/18 [==============================] - 0s 257us/step - loss: 106.9115 - val_loss: 11.1815\n",
      "Epoch 320/500\n",
      "18/18 [==============================] - 0s 278us/step - loss: 106.4857 - val_loss: 11.0234\n",
      "Epoch 321/500\n",
      "18/18 [==============================] - 0s 254us/step - loss: 105.9989 - val_loss: 10.8697\n",
      "Epoch 322/500\n",
      "18/18 [==============================] - 0s 252us/step - loss: 105.5602 - val_loss: 10.7172\n",
      "Epoch 323/500\n",
      "18/18 [==============================] - 0s 220us/step - loss: 105.1334 - val_loss: 10.5657\n",
      "Epoch 324/500\n",
      "18/18 [==============================] - 0s 340us/step - loss: 104.6395 - val_loss: 10.4185\n",
      "Epoch 325/500\n",
      "18/18 [==============================] - 0s 197us/step - loss: 104.2528 - val_loss: 10.2693\n",
      "Epoch 326/500\n",
      "18/18 [==============================] - 0s 211us/step - loss: 103.7969 - val_loss: 10.1229\n",
      "Epoch 327/500\n",
      "18/18 [==============================] - 0s 267us/step - loss: 103.3531 - val_loss: 9.9783\n",
      "Epoch 328/500\n",
      "18/18 [==============================] - 0s 395us/step - loss: 102.9209 - val_loss: 9.8347\n",
      "Epoch 329/500\n",
      "18/18 [==============================] - 0s 301us/step - loss: 102.4802 - val_loss: 9.6926\n",
      "Epoch 330/500\n",
      "18/18 [==============================] - 0s 352us/step - loss: 102.0660 - val_loss: 9.5508\n",
      "Epoch 331/500\n",
      "18/18 [==============================] - 0s 234us/step - loss: 101.6605 - val_loss: 9.4096\n",
      "Epoch 332/500\n",
      "18/18 [==============================] - 0s 208us/step - loss: 101.1824 - val_loss: 9.2729\n",
      "Epoch 333/500\n",
      "18/18 [==============================] - 0s 230us/step - loss: 100.7783 - val_loss: 9.1360\n",
      "Epoch 334/500\n",
      "18/18 [==============================] - 0s 234us/step - loss: 100.3822 - val_loss: 8.9996\n",
      "Epoch 335/500\n",
      "18/18 [==============================] - 0s 327us/step - loss: 99.9403 - val_loss: 8.8663\n",
      "Epoch 336/500\n",
      "18/18 [==============================] - 0s 315us/step - loss: 99.5134 - val_loss: 8.7351\n",
      "Epoch 337/500\n",
      "18/18 [==============================] - 0s 280us/step - loss: 99.1139 - val_loss: 8.6048\n",
      "Epoch 338/500\n",
      "18/18 [==============================] - 0s 212us/step - loss: 98.7067 - val_loss: 8.4762\n",
      "Epoch 339/500\n",
      "18/18 [==============================] - 0s 244us/step - loss: 98.2754 - val_loss: 8.3504\n",
      "Epoch 340/500\n",
      "18/18 [==============================] - 0s 250us/step - loss: 97.8767 - val_loss: 8.2257\n",
      "Epoch 341/500\n",
      "18/18 [==============================] - 0s 252us/step - loss: 97.4476 - val_loss: 8.1037\n",
      "Epoch 342/500\n",
      "18/18 [==============================] - 0s 208us/step - loss: 97.1027 - val_loss: 7.9804\n",
      "Epoch 343/500\n",
      "18/18 [==============================] - 0s 385us/step - loss: 96.6468 - val_loss: 7.8617\n",
      "Epoch 344/500\n",
      "18/18 [==============================] - 0s 213us/step - loss: 96.2553 - val_loss: 7.7439\n",
      "Epoch 345/500\n",
      "18/18 [==============================] - 0s 289us/step - loss: 95.8767 - val_loss: 7.6265\n",
      "Epoch 346/500\n",
      "18/18 [==============================] - 0s 256us/step - loss: 95.4511 - val_loss: 7.5120\n",
      "Epoch 347/500\n",
      "18/18 [==============================] - 0s 212us/step - loss: 95.0797 - val_loss: 7.3975\n",
      "Epoch 348/500\n",
      "18/18 [==============================] - 0s 218us/step - loss: 94.7095 - val_loss: 7.2838\n",
      "Epoch 349/500\n",
      "18/18 [==============================] - 0s 399us/step - loss: 94.2707 - val_loss: 7.1739\n",
      "Epoch 350/500\n",
      "18/18 [==============================] - 0s 318us/step - loss: 93.9070 - val_loss: 7.0639\n",
      "Epoch 351/500\n",
      "18/18 [==============================] - 0s 218us/step - loss: 93.5319 - val_loss: 6.9548\n",
      "Epoch 352/500\n",
      "18/18 [==============================] - 0s 190us/step - loss: 93.1095 - val_loss: 6.8488\n",
      "Epoch 353/500\n",
      "18/18 [==============================] - 0s 273us/step - loss: 92.7784 - val_loss: 6.7416\n",
      "Epoch 354/500\n",
      "18/18 [==============================] - 0s 252us/step - loss: 92.3594 - val_loss: 6.6379\n",
      "Epoch 355/500\n",
      "18/18 [==============================] - 0s 319us/step - loss: 92.0010 - val_loss: 6.5345\n",
      "Epoch 356/500\n",
      "18/18 [==============================] - 0s 237us/step - loss: 91.6222 - val_loss: 6.4328\n",
      "Epoch 357/500\n",
      "18/18 [==============================] - 0s 212us/step - loss: 91.2297 - val_loss: 6.3334\n",
      "Epoch 358/500\n",
      "18/18 [==============================] - 0s 211us/step - loss: 90.8566 - val_loss: 6.2351\n",
      "Epoch 359/500\n",
      "18/18 [==============================] - 0s 246us/step - loss: 90.4989 - val_loss: 6.1377\n",
      "Epoch 360/500\n",
      "18/18 [==============================] - 0s 265us/step - loss: 90.1238 - val_loss: 6.0422\n",
      "Epoch 361/500\n",
      "18/18 [==============================] - 0s 215us/step - loss: 89.7716 - val_loss: 5.9480\n",
      "Epoch 362/500\n",
      "18/18 [==============================] - 0s 204us/step - loss: 89.3581 - val_loss: 5.8581\n",
      "Epoch 363/500\n",
      "18/18 [==============================] - 0s 269us/step - loss: 89.0241 - val_loss: 5.7689\n",
      "Epoch 364/500\n",
      "18/18 [==============================] - 0s 208us/step - loss: 88.6690 - val_loss: 5.6823\n",
      "Epoch 365/500\n",
      "18/18 [==============================] - 0s 223us/step - loss: 88.2945 - val_loss: 5.6021\n",
      "Epoch 366/500\n",
      "18/18 [==============================] - 0s 238us/step - loss: 87.8959 - val_loss: 5.5292\n",
      "Epoch 367/500\n",
      "18/18 [==============================] - 0s 236us/step - loss: 87.5300 - val_loss: 5.4633\n",
      "Epoch 368/500\n",
      "18/18 [==============================] - 0s 220us/step - loss: 87.1698 - val_loss: 5.4051\n",
      "Epoch 369/500\n",
      "18/18 [==============================] - 0s 206us/step - loss: 86.8169 - val_loss: 5.3453\n",
      "Epoch 370/500\n",
      "18/18 [==============================] - 0s 350us/step - loss: 86.4529 - val_loss: 5.2789\n",
      "Epoch 371/500\n",
      "18/18 [==============================] - 0s 209us/step - loss: 86.0852 - val_loss: 5.2067\n",
      "Epoch 372/500\n",
      "18/18 [==============================] - 0s 216us/step - loss: 85.7323 - val_loss: 5.1314\n",
      "Epoch 373/500\n",
      "18/18 [==============================] - 0s 221us/step - loss: 85.3936 - val_loss: 5.0524\n",
      "Epoch 374/500\n",
      "18/18 [==============================] - 0s 345us/step - loss: 85.0380 - val_loss: 4.9657\n",
      "Epoch 375/500\n",
      "18/18 [==============================] - 0s 214us/step - loss: 84.7128 - val_loss: 4.8867\n",
      "Epoch 376/500\n",
      "18/18 [==============================] - 0s 203us/step - loss: 84.3235 - val_loss: 4.8088\n",
      "Epoch 377/500\n",
      "18/18 [==============================] - 0s 292us/step - loss: 83.9892 - val_loss: 4.7252\n",
      "Epoch 378/500\n",
      "18/18 [==============================] - 0s 211us/step - loss: 83.6517 - val_loss: 4.6512\n",
      "Epoch 379/500\n",
      "18/18 [==============================] - 0s 193us/step - loss: 83.2850 - val_loss: 4.5827\n",
      "Epoch 380/500\n",
      "18/18 [==============================] - 0s 211us/step - loss: 82.9173 - val_loss: 4.5267\n",
      "Epoch 381/500\n",
      "18/18 [==============================] - 0s 262us/step - loss: 82.5896 - val_loss: 4.4657\n",
      "Epoch 382/500\n",
      "18/18 [==============================] - 0s 237us/step - loss: 82.2162 - val_loss: 4.4169\n",
      "Epoch 383/500\n",
      "18/18 [==============================] - 0s 203us/step - loss: 81.8797 - val_loss: 4.3685\n",
      "Epoch 384/500\n",
      "18/18 [==============================] - 0s 230us/step - loss: 81.5148 - val_loss: 4.3297\n",
      "Epoch 385/500\n",
      "18/18 [==============================] - 0s 263us/step - loss: 81.1730 - val_loss: 4.2883\n",
      "Epoch 386/500\n",
      "18/18 [==============================] - 0s 214us/step - loss: 80.8128 - val_loss: 4.2507\n",
      "Epoch 387/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 214us/step - loss: 80.4730 - val_loss: 4.2169\n",
      "Epoch 388/500\n",
      "18/18 [==============================] - 0s 249us/step - loss: 80.1639 - val_loss: 4.1628\n",
      "Epoch 389/500\n",
      "18/18 [==============================] - 0s 288us/step - loss: 79.7936 - val_loss: 4.1023\n",
      "Epoch 390/500\n",
      "18/18 [==============================] - 0s 216us/step - loss: 79.4818 - val_loss: 4.0267\n",
      "Epoch 391/500\n",
      "18/18 [==============================] - 0s 242us/step - loss: 79.1504 - val_loss: 3.9390\n",
      "Epoch 392/500\n",
      "18/18 [==============================] - 0s 229us/step - loss: 78.8026 - val_loss: 3.8613\n",
      "Epoch 393/500\n",
      "18/18 [==============================] - 0s 218us/step - loss: 78.4509 - val_loss: 3.7679\n",
      "Epoch 394/500\n",
      "18/18 [==============================] - 0s 243us/step - loss: 78.1460 - val_loss: 3.6866\n",
      "Epoch 395/500\n",
      "18/18 [==============================] - 0s 230us/step - loss: 77.8072 - val_loss: 3.6140\n",
      "Epoch 396/500\n",
      "18/18 [==============================] - 0s 241us/step - loss: 77.4403 - val_loss: 3.5516\n",
      "Epoch 397/500\n",
      "18/18 [==============================] - 0s 278us/step - loss: 77.1715 - val_loss: 3.4856\n",
      "Epoch 398/500\n",
      "18/18 [==============================] - 0s 208us/step - loss: 76.8141 - val_loss: 3.4270\n",
      "Epoch 399/500\n",
      "18/18 [==============================] - 0s 194us/step - loss: 76.4811 - val_loss: 3.3681\n",
      "Epoch 400/500\n",
      "18/18 [==============================] - 0s 224us/step - loss: 76.1666 - val_loss: 3.3102\n",
      "Epoch 401/500\n",
      "18/18 [==============================] - 0s 340us/step - loss: 75.8463 - val_loss: 3.2514\n",
      "Epoch 402/500\n",
      "18/18 [==============================] - 0s 259us/step - loss: 75.5463 - val_loss: 3.2013\n",
      "Epoch 403/500\n",
      "18/18 [==============================] - 0s 208us/step - loss: 75.1996 - val_loss: 3.1390\n",
      "Epoch 404/500\n",
      "18/18 [==============================] - 0s 220us/step - loss: 74.8974 - val_loss: 3.0792\n",
      "Epoch 405/500\n",
      "18/18 [==============================] - 0s 239us/step - loss: 74.5773 - val_loss: 3.0237\n",
      "Epoch 406/500\n",
      "18/18 [==============================] - 0s 191us/step - loss: 74.2561 - val_loss: 2.9669\n",
      "Epoch 407/500\n",
      "18/18 [==============================] - 0s 262us/step - loss: 73.9496 - val_loss: 2.9061\n",
      "Epoch 408/500\n",
      "18/18 [==============================] - 0s 268us/step - loss: 73.6223 - val_loss: 2.8543\n",
      "Epoch 409/500\n",
      "18/18 [==============================] - 0s 288us/step - loss: 73.3162 - val_loss: 2.8043\n",
      "Epoch 410/500\n",
      "18/18 [==============================] - 0s 234us/step - loss: 72.9900 - val_loss: 2.7519\n",
      "Epoch 411/500\n",
      "18/18 [==============================] - 0s 269us/step - loss: 72.6683 - val_loss: 2.7061\n",
      "Epoch 412/500\n",
      "18/18 [==============================] - 0s 203us/step - loss: 72.3180 - val_loss: 2.6556\n",
      "Epoch 413/500\n",
      "18/18 [==============================] - 0s 196us/step - loss: 71.9782 - val_loss: 2.6134\n",
      "Epoch 414/500\n",
      "18/18 [==============================] - 0s 191us/step - loss: 71.6432 - val_loss: 2.5787\n",
      "Epoch 415/500\n",
      "18/18 [==============================] - 0s 271us/step - loss: 71.2601 - val_loss: 2.5507\n",
      "Epoch 416/500\n",
      "18/18 [==============================] - 0s 203us/step - loss: 70.8986 - val_loss: 2.5395\n",
      "Epoch 417/500\n",
      "18/18 [==============================] - 0s 192us/step - loss: 70.5541 - val_loss: 2.5316\n",
      "Epoch 418/500\n",
      "18/18 [==============================] - 0s 210us/step - loss: 70.2374 - val_loss: 2.5367\n",
      "Epoch 419/500\n",
      "18/18 [==============================] - 0s 212us/step - loss: 69.9419 - val_loss: 2.5135\n",
      "Epoch 420/500\n",
      "18/18 [==============================] - 0s 217us/step - loss: 69.6471 - val_loss: 2.4372\n",
      "Epoch 421/500\n",
      "18/18 [==============================] - 0s 410us/step - loss: 69.3219 - val_loss: 2.3351\n",
      "Epoch 422/500\n",
      "18/18 [==============================] - 0s 231us/step - loss: 69.0049 - val_loss: 2.2498\n",
      "Epoch 423/500\n",
      "18/18 [==============================] - 0s 216us/step - loss: 68.6687 - val_loss: 2.1767\n",
      "Epoch 424/500\n",
      "18/18 [==============================] - 0s 260us/step - loss: 68.3594 - val_loss: 2.1150\n",
      "Epoch 425/500\n",
      "18/18 [==============================] - 0s 203us/step - loss: 68.0689 - val_loss: 2.0610\n",
      "Epoch 426/500\n",
      "18/18 [==============================] - 0s 189us/step - loss: 67.7733 - val_loss: 2.0094\n",
      "Epoch 427/500\n",
      "18/18 [==============================] - 0s 178us/step - loss: 67.4290 - val_loss: 1.9613\n",
      "Epoch 428/500\n",
      "18/18 [==============================] - 0s 187us/step - loss: 67.1526 - val_loss: 1.9140\n",
      "Epoch 429/500\n",
      "18/18 [==============================] - 0s 206us/step - loss: 66.8551 - val_loss: 1.8702\n",
      "Epoch 430/500\n",
      "18/18 [==============================] - 0s 189us/step - loss: 66.5426 - val_loss: 1.8265\n",
      "Epoch 431/500\n",
      "18/18 [==============================] - 0s 196us/step - loss: 66.2681 - val_loss: 1.7799\n",
      "Epoch 432/500\n",
      "18/18 [==============================] - 0s 202us/step - loss: 65.9552 - val_loss: 1.7348\n",
      "Epoch 433/500\n",
      "18/18 [==============================] - 0s 214us/step - loss: 65.6560 - val_loss: 1.6852\n",
      "Epoch 434/500\n",
      "18/18 [==============================] - 0s 202us/step - loss: 65.3823 - val_loss: 1.6359\n",
      "Epoch 435/500\n",
      "18/18 [==============================] - 0s 218us/step - loss: 65.1078 - val_loss: 1.5915\n",
      "Epoch 436/500\n",
      "18/18 [==============================] - 0s 237us/step - loss: 64.8098 - val_loss: 1.5522\n",
      "Epoch 437/500\n",
      "18/18 [==============================] - 0s 247us/step - loss: 64.5332 - val_loss: 1.5150\n",
      "Epoch 438/500\n",
      "18/18 [==============================] - 0s 175us/step - loss: 64.2371 - val_loss: 1.4760\n",
      "Epoch 439/500\n",
      "18/18 [==============================] - 0s 179us/step - loss: 63.9685 - val_loss: 1.4345\n",
      "Epoch 440/500\n",
      "18/18 [==============================] - 0s 185us/step - loss: 63.6669 - val_loss: 1.3929\n",
      "Epoch 441/500\n",
      "18/18 [==============================] - 0s 191us/step - loss: 63.3939 - val_loss: 1.3512\n",
      "Epoch 442/500\n",
      "18/18 [==============================] - 0s 206us/step - loss: 63.1139 - val_loss: 1.3100\n",
      "Epoch 443/500\n",
      "18/18 [==============================] - 0s 205us/step - loss: 62.8313 - val_loss: 1.2689\n",
      "Epoch 444/500\n",
      "18/18 [==============================] - 0s 223us/step - loss: 62.5783 - val_loss: 1.2300\n",
      "Epoch 445/500\n",
      "18/18 [==============================] - 0s 216us/step - loss: 62.3110 - val_loss: 1.1935\n",
      "Epoch 446/500\n",
      "18/18 [==============================] - 0s 231us/step - loss: 62.0242 - val_loss: 1.1590\n",
      "Epoch 447/500\n",
      "18/18 [==============================] - 0s 233us/step - loss: 61.7622 - val_loss: 1.1258\n",
      "Epoch 448/500\n",
      "18/18 [==============================] - 0s 178us/step - loss: 61.4863 - val_loss: 1.0948\n",
      "Epoch 449/500\n",
      "18/18 [==============================] - 0s 664us/step - loss: 61.1992 - val_loss: 1.0632\n",
      "Epoch 450/500\n",
      "18/18 [==============================] - 0s 258us/step - loss: 60.9284 - val_loss: 1.0332\n",
      "Epoch 451/500\n",
      "18/18 [==============================] - 0s 213us/step - loss: 60.6346 - val_loss: 1.0047\n",
      "Epoch 452/500\n",
      "18/18 [==============================] - 0s 223us/step - loss: 60.3746 - val_loss: 0.9775\n",
      "Epoch 453/500\n",
      "18/18 [==============================] - 0s 218us/step - loss: 60.1363 - val_loss: 0.9548\n",
      "Epoch 454/500\n",
      "18/18 [==============================] - 0s 434us/step - loss: 59.8375 - val_loss: 0.9442\n",
      "Epoch 455/500\n",
      "18/18 [==============================] - 0s 308us/step - loss: 59.5587 - val_loss: 0.9416\n",
      "Epoch 456/500\n",
      "18/18 [==============================] - 0s 251us/step - loss: 59.3022 - val_loss: 0.9470\n",
      "Epoch 457/500\n",
      "18/18 [==============================] - 0s 229us/step - loss: 59.0393 - val_loss: 0.9518\n",
      "Epoch 458/500\n",
      "18/18 [==============================] - 0s 237us/step - loss: 58.8028 - val_loss: 0.9490\n",
      "Epoch 459/500\n",
      "18/18 [==============================] - 0s 275us/step - loss: 58.4928 - val_loss: 0.9466\n",
      "Epoch 460/500\n",
      "18/18 [==============================] - 0s 251us/step - loss: 58.2608 - val_loss: 0.9374\n",
      "Epoch 461/500\n",
      "18/18 [==============================] - 0s 203us/step - loss: 58.0098 - val_loss: 0.9238\n",
      "Epoch 462/500\n",
      "18/18 [==============================] - 0s 212us/step - loss: 57.7682 - val_loss: 0.8812\n",
      "Epoch 463/500\n",
      "18/18 [==============================] - 0s 340us/step - loss: 57.4845 - val_loss: 0.8123\n",
      "Epoch 464/500\n",
      "18/18 [==============================] - 0s 192us/step - loss: 57.2380 - val_loss: 0.7458\n",
      "Epoch 465/500\n",
      "18/18 [==============================] - 0s 268us/step - loss: 56.9887 - val_loss: 0.6890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/500\n",
      "18/18 [==============================] - 0s 225us/step - loss: 56.7395 - val_loss: 0.6499\n",
      "Epoch 467/500\n",
      "18/18 [==============================] - 0s 229us/step - loss: 56.4731 - val_loss: 0.6169\n",
      "Epoch 468/500\n",
      "18/18 [==============================] - 0s 213us/step - loss: 56.2410 - val_loss: 0.5912\n",
      "Epoch 469/500\n",
      "18/18 [==============================] - 0s 240us/step - loss: 55.9848 - val_loss: 0.5686\n",
      "Epoch 470/500\n",
      "18/18 [==============================] - 0s 319us/step - loss: 55.7454 - val_loss: 0.5471\n",
      "Epoch 471/500\n",
      "18/18 [==============================] - 0s 242us/step - loss: 55.4998 - val_loss: 0.5263\n",
      "Epoch 472/500\n",
      "18/18 [==============================] - 0s 261us/step - loss: 55.2520 - val_loss: 0.5054\n",
      "Epoch 473/500\n",
      "18/18 [==============================] - 0s 280us/step - loss: 55.0171 - val_loss: 0.4862\n",
      "Epoch 474/500\n",
      "18/18 [==============================] - 0s 231us/step - loss: 54.7570 - val_loss: 0.4695\n",
      "Epoch 475/500\n",
      "18/18 [==============================] - 0s 298us/step - loss: 54.5296 - val_loss: 0.4550\n",
      "Epoch 476/500\n",
      "18/18 [==============================] - 0s 215us/step - loss: 54.2897 - val_loss: 0.4398\n",
      "Epoch 477/500\n",
      "18/18 [==============================] - 0s 217us/step - loss: 54.0478 - val_loss: 0.4229\n",
      "Epoch 478/500\n",
      "18/18 [==============================] - 0s 254us/step - loss: 53.8058 - val_loss: 0.4022\n",
      "Epoch 479/500\n",
      "18/18 [==============================] - 0s 210us/step - loss: 53.5597 - val_loss: 0.3854\n",
      "Epoch 480/500\n",
      "18/18 [==============================] - 0s 197us/step - loss: 53.3342 - val_loss: 0.3648\n",
      "Epoch 481/500\n",
      "18/18 [==============================] - 0s 248us/step - loss: 53.0984 - val_loss: 0.3475\n",
      "Epoch 482/500\n",
      "18/18 [==============================] - 0s 252us/step - loss: 52.8568 - val_loss: 0.3301\n",
      "Epoch 483/500\n",
      "18/18 [==============================] - 0s 195us/step - loss: 52.6154 - val_loss: 0.3147\n",
      "Epoch 484/500\n",
      "18/18 [==============================] - 0s 204us/step - loss: 52.4154 - val_loss: 0.2995\n",
      "Epoch 485/500\n",
      "18/18 [==============================] - 0s 348us/step - loss: 52.1759 - val_loss: 0.2845\n",
      "Epoch 486/500\n",
      "18/18 [==============================] - 0s 226us/step - loss: 51.9426 - val_loss: 0.2707\n",
      "Epoch 487/500\n",
      "18/18 [==============================] - 0s 248us/step - loss: 51.7065 - val_loss: 0.2569\n",
      "Epoch 488/500\n",
      "18/18 [==============================] - 0s 371us/step - loss: 51.4758 - val_loss: 0.2436\n",
      "Epoch 489/500\n",
      "18/18 [==============================] - 0s 215us/step - loss: 51.2345 - val_loss: 0.2312\n",
      "Epoch 490/500\n",
      "18/18 [==============================] - 0s 213us/step - loss: 51.0303 - val_loss: 0.2187\n",
      "Epoch 491/500\n",
      "18/18 [==============================] - 0s 217us/step - loss: 50.8079 - val_loss: 0.2054\n",
      "Epoch 492/500\n",
      "18/18 [==============================] - 0s 303us/step - loss: 50.5865 - val_loss: 0.1938\n",
      "Epoch 493/500\n",
      "18/18 [==============================] - 0s 210us/step - loss: 50.3442 - val_loss: 0.1812\n",
      "Epoch 494/500\n",
      "18/18 [==============================] - 0s 207us/step - loss: 50.1462 - val_loss: 0.1703\n",
      "Epoch 495/500\n",
      "18/18 [==============================] - 0s 208us/step - loss: 49.9164 - val_loss: 0.1606\n",
      "Epoch 496/500\n",
      "18/18 [==============================] - 0s 305us/step - loss: 49.7013 - val_loss: 0.1515\n",
      "Epoch 497/500\n",
      "18/18 [==============================] - 0s 217us/step - loss: 49.4684 - val_loss: 0.1426\n",
      "Epoch 498/500\n",
      "18/18 [==============================] - 0s 226us/step - loss: 49.2476 - val_loss: 0.1351\n",
      "Epoch 499/500\n",
      "18/18 [==============================] - 0s 284us/step - loss: 49.0497 - val_loss: 0.1246\n",
      "Epoch 500/500\n",
      "18/18 [==============================] - 0s 229us/step - loss: 48.8249 - val_loss: 0.1161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[11.37805]], dtype=float32),\n",
       " array([[12.149597]], dtype=float32),\n",
       " array([[13.094989]], dtype=float32),\n",
       " array([[14.160466]], dtype=float32),\n",
       " array([[15.288697]], dtype=float32),\n",
       " array([[16.210945]], dtype=float32),\n",
       " array([[16.562296]], dtype=float32),\n",
       " array([[16.626043]], dtype=float32),\n",
       " array([[16.635157]], dtype=float32),\n",
       " array([[16.636444]], dtype=float32),\n",
       " array([[16.636663]], dtype=float32),\n",
       " array([[16.636698]], dtype=float32),\n",
       " array([[16.636702]], dtype=float32),\n",
       " array([[16.636702]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32),\n",
       " array([[16.636703]], dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (maxlen)\n",
    "myrnn_model_v1 = MyRNNModelV1(maxlen=10)\n",
    "myrnn_model_v1.load_data([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30])\n",
    "myrnn_model_v1.build()\n",
    "myrnn_model_v1.train()\n",
    "myrnn_model_v1.predict(df_list=[1,2,3,4,5,6,7,8,9,10,11])\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22 samples, validate on 3 samples\n",
      "Epoch 1/500\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 241.6147 - val_loss: 43.0871\n",
      "Epoch 2/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 27.2553 - val_loss: 7.0299\n",
      "Epoch 3/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 31.4058 - val_loss: 23.0384\n",
      "Epoch 4/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 17.9811 - val_loss: 32.0140\n",
      "Epoch 5/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 31.2422 - val_loss: 6.3013\n",
      "Epoch 6/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 12.0668 - val_loss: 12.7888\n",
      "Epoch 7/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.5837 - val_loss: 23.2369\n",
      "Epoch 8/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 15.8876 - val_loss: 4.7142\n",
      "Epoch 9/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.8579 - val_loss: 5.2539\n",
      "Epoch 10/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.4012 - val_loss: 9.2055\n",
      "Epoch 11/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.5235 - val_loss: 3.2476\n",
      "Epoch 12/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.8118 - val_loss: 1.4658\n",
      "Epoch 13/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.6073 - val_loss: 2.5942\n",
      "Epoch 14/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.4733 - val_loss: 0.6801\n",
      "Epoch 15/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3567 - val_loss: 0.7671\n",
      "Epoch 16/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9980 - val_loss: 0.9832\n",
      "Epoch 17/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1902 - val_loss: 0.2483\n",
      "Epoch 18/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5842 - val_loss: 0.8663\n",
      "Epoch 19/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6479 - val_loss: 0.2080\n",
      "Epoch 20/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4533 - val_loss: 0.2754\n",
      "Epoch 21/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.1771 - val_loss: 0.6912\n",
      "Epoch 22/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4523 - val_loss: 0.1621\n",
      "Epoch 23/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2046 - val_loss: 0.0546\n",
      "Epoch 24/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.1105 - val_loss: 0.1409\n",
      "Epoch 25/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.1025 - val_loss: 0.0565\n",
      "Epoch 26/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.1398 - val_loss: 0.1954\n",
      "Epoch 27/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1556 - val_loss: 0.0649\n",
      "Epoch 28/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0856 - val_loss: 0.0727\n",
      "Epoch 29/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.2342\n",
      "Epoch 30/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.1409 - val_loss: 0.0457\n",
      "Epoch 31/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0096\n",
      "Epoch 32/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0316 - val_loss: 0.0787\n",
      "Epoch 33/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0355 - val_loss: 0.0183\n",
      "Epoch 34/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0165\n",
      "Epoch 35/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0173\n",
      "Epoch 36/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0084\n",
      "Epoch 37/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 38/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0082\n",
      "Epoch 39/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0084\n",
      "Epoch 40/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0086\n",
      "Epoch 41/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0098\n",
      "Epoch 42/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0219\n",
      "Epoch 43/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0135\n",
      "Epoch 44/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0117\n",
      "Epoch 45/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0045\n",
      "Epoch 46/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0192\n",
      "Epoch 47/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0266\n",
      "Epoch 48/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0347\n",
      "Epoch 49/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0020\n",
      "Epoch 50/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.0432\n",
      "Epoch 51/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.0161\n",
      "Epoch 52/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0443\n",
      "Epoch 53/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0740 - val_loss: 0.0190\n",
      "Epoch 54/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0605 - val_loss: 0.0114\n",
      "Epoch 55/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.0199\n",
      "Epoch 56/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0822\n",
      "Epoch 57/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.0033\n",
      "Epoch 58/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0793\n",
      "Epoch 59/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0936 - val_loss: 0.0233\n",
      "Epoch 00059: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[5.753784]], dtype=float32),\n",
       " array([[6.5739536]], dtype=float32),\n",
       " array([[7.483274]], dtype=float32),\n",
       " array([[8.412545]], dtype=float32),\n",
       " array([[9.3811]], dtype=float32),\n",
       " array([[10.271853]], dtype=float32),\n",
       " array([[11.162578]], dtype=float32),\n",
       " array([[12.0343275]], dtype=float32),\n",
       " array([[12.908538]], dtype=float32),\n",
       " array([[13.795935]], dtype=float32),\n",
       " array([[14.688182]], dtype=float32),\n",
       " array([[15.596578]], dtype=float32),\n",
       " array([[16.513298]], dtype=float32),\n",
       " array([[17.437914]], dtype=float32),\n",
       " array([[18.36411]], dtype=float32),\n",
       " array([[19.286518]], dtype=float32),\n",
       " array([[20.20328]], dtype=float32),\n",
       " array([[21.11589]], dtype=float32),\n",
       " array([[22.031984]], dtype=float32),\n",
       " array([[22.96326]], dtype=float32),\n",
       " array([[23.92392]], dtype=float32),\n",
       " array([[24.926064]], dtype=float32),\n",
       " array([[25.97169]], dtype=float32),\n",
       " array([[27.040457]], dtype=float32),\n",
       " array([[28.078175]], dtype=float32),\n",
       " array([[29.002594]], dtype=float32),\n",
       " array([[29.738544]], dtype=float32),\n",
       " array([[30.25855]], dtype=float32),\n",
       " array([[30.588598]], dtype=float32),\n",
       " array([[30.781055]], dtype=float32),\n",
       " array([[30.88684]], dtype=float32),\n",
       " array([[30.942913]], dtype=float32),\n",
       " array([[30.972061]], dtype=float32),\n",
       " array([[30.987064]], dtype=float32),\n",
       " array([[30.994766]], dtype=float32),\n",
       " array([[30.998714]], dtype=float32),\n",
       " array([[31.000732]], dtype=float32),\n",
       " array([[31.00176]], dtype=float32),\n",
       " array([[31.00229]], dtype=float32),\n",
       " array([[31.002552]], dtype=float32),\n",
       " array([[31.002691]], dtype=float32),\n",
       " array([[31.002764]], dtype=float32),\n",
       " array([[31.002802]], dtype=float32),\n",
       " array([[31.002817]], dtype=float32),\n",
       " array([[31.00283]], dtype=float32),\n",
       " array([[31.002834]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.00284]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.00284]], dtype=float32),\n",
       " array([[31.00284]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.00284]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.00284]], dtype=float32),\n",
       " array([[31.00284]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.00284]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.00284]], dtype=float32),\n",
       " array([[31.00284]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.00284]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.00284]], dtype=float32),\n",
       " array([[31.00284]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.00284]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.00284]], dtype=float32),\n",
       " array([[31.00284]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.00284]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32),\n",
       " array([[31.002838]], dtype=float32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "myrnn_model_v1 = MyRNNModelV1(maxlen=5,n_hidden=1000)\n",
    "myrnn_model_v1.load_data([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30])\n",
    "myrnn_model_v1.build()\n",
    "myrnn_model_v1.train()\n",
    "myrnn_model_v1.predict(df_list=[1,2,3,4,5,6])\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 810 samples, validate on 90 samples\n",
      "Epoch 1/500\n",
      "810/810 [==============================] - 1s 941us/step - loss: 0.0105 - val_loss: 5.6555e-05\n",
      "Epoch 2/500\n",
      "810/810 [==============================] - 1s 775us/step - loss: 2.0803e-05 - val_loss: 1.1828e-05\n",
      "Epoch 3/500\n",
      "810/810 [==============================] - 1s 788us/step - loss: 1.0365e-05 - val_loss: 6.5108e-06\n",
      "Epoch 4/500\n",
      "810/810 [==============================] - 1s 776us/step - loss: 6.1929e-06 - val_loss: 3.6907e-06\n",
      "Epoch 5/500\n",
      "810/810 [==============================] - 1s 782us/step - loss: 3.9519e-06 - val_loss: 4.5715e-06\n",
      "Epoch 6/500\n",
      "810/810 [==============================] - 1s 794us/step - loss: 3.2018e-06 - val_loss: 5.4566e-06\n",
      "Epoch 7/500\n",
      "810/810 [==============================] - 1s 792us/step - loss: 6.0646e-06 - val_loss: 6.1481e-06\n",
      "Epoch 8/500\n",
      "810/810 [==============================] - 1s 787us/step - loss: 2.3362e-05 - val_loss: 6.5165e-06\n",
      "Epoch 9/500\n",
      "810/810 [==============================] - 1s 833us/step - loss: 3.8939e-06 - val_loss: 2.7446e-06\n",
      "Epoch 10/500\n",
      "810/810 [==============================] - 1s 800us/step - loss: 2.0169e-06 - val_loss: 9.5087e-07\n",
      "Epoch 11/500\n",
      "810/810 [==============================] - 1s 811us/step - loss: 1.8208e-06 - val_loss: 3.1461e-06\n",
      "Epoch 12/500\n",
      "810/810 [==============================] - 1s 796us/step - loss: 3.4443e-06 - val_loss: 3.0369e-06\n",
      "Epoch 13/500\n",
      "810/810 [==============================] - 1s 854us/step - loss: 6.0893e-06 - val_loss: 7.8868e-06\n",
      "Epoch 14/500\n",
      "810/810 [==============================] - 1s 802us/step - loss: 2.3016e-06 - val_loss: 7.7381e-07\n",
      "Epoch 15/500\n",
      "810/810 [==============================] - 1s 819us/step - loss: 1.8603e-06 - val_loss: 4.4745e-06\n",
      "Epoch 16/500\n",
      "810/810 [==============================] - 1s 808us/step - loss: 2.3510e-06 - val_loss: 5.8624e-07\n",
      "Epoch 17/500\n",
      "810/810 [==============================] - 1s 841us/step - loss: 3.0163e-06 - val_loss: 8.0821e-07\n",
      "Epoch 18/500\n",
      "810/810 [==============================] - 1s 800us/step - loss: 6.6840e-07 - val_loss: 2.1364e-07\n",
      "Epoch 19/500\n",
      "810/810 [==============================] - 1s 830us/step - loss: 1.1767e-06 - val_loss: 1.2617e-06\n",
      "Epoch 20/500\n",
      "810/810 [==============================] - 1s 859us/step - loss: 5.8359e-06 - val_loss: 7.6544e-05\n",
      "Epoch 21/500\n",
      "810/810 [==============================] - 1s 788us/step - loss: 2.6754e-05 - val_loss: 3.6245e-06\n",
      "Epoch 22/500\n",
      "810/810 [==============================] - 1s 803us/step - loss: 5.6101e-06 - val_loss: 6.2070e-07\n",
      "Epoch 23/500\n",
      "810/810 [==============================] - 1s 789us/step - loss: 1.3162e-06 - val_loss: 8.4517e-07\n",
      "Epoch 24/500\n",
      "810/810 [==============================] - 1s 783us/step - loss: 2.3251e-06 - val_loss: 1.4809e-06\n",
      "Epoch 25/500\n",
      "810/810 [==============================] - 1s 792us/step - loss: 6.2032e-06 - val_loss: 8.3286e-07\n",
      "Epoch 26/500\n",
      "810/810 [==============================] - 1s 793us/step - loss: 8.0323e-07 - val_loss: 4.2279e-06\n",
      "Epoch 27/500\n",
      "810/810 [==============================] - 1s 819us/step - loss: 3.8350e-06 - val_loss: 5.4904e-06\n",
      "Epoch 28/500\n",
      "810/810 [==============================] - 1s 796us/step - loss: 8.7707e-06 - val_loss: 3.4284e-05\n",
      "Epoch 00028: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztnXeYHMWZ/781aWdz3tVKK2mVUEAggiyyydk2Djj7jNMP+5zO53AHzulsnM7GdzhgzjbmsMHG2GCDSUIc2ICQCMoSytLuStqcZ3d2Zur3R3f11PRU987s9PSk9/M8ejTb1dNd3T39rbfeeustxjkHQRAEUVp4cl0BgiAIwn1I/AmCIEoQEn+CIIgShMSfIAiiBCHxJwiCKEFI/AmCIEoQEn+CIIgShMSfIAiiBCHxJwiCKEF8ua6AFU1NTbyjoyPX1SAIgigoXnzxxT7OefNM++Wt+Hd0dGDz5s25rgZBEERBwRg7nMp+5PYhCIIoQUj8CYIgShASf4IgiBKExJ8gCKIEIfEnCIIoQUj8CYIgShASf4IgiBKExL8EefrVXuzrGc11NQiCyCEk/iVGOBLDe3/5Al7/X//IdVUIgsghJP4lxr6eMQBAaDqKv2zpxiPbj+e4RgRB5IK8Te9AZIfxcMT4/InfvQwAOHTLtbmqDkEQOYIs/xJjfCoy804EQRQ9JP4lxkQ4mrQtHInloCYEQeQSEv8SQyX+w6HpHNSEIIhcQuJfYkyEk90+o5Mk/gRRapD4lxgqy390ksYBCKLUIPEvMSYUA74k/gRRepD4lxgT4SjK/V5Ul/mwblEDAHL7EEQpQuJfYoyHo6gs82LLV67AD966BgBZ/gRRipD4lxihcAQVAR88HoaaoB8AMEKWP0GUHCT+JcZ4OIqKgBcAUBXUJniT5U8QpQeJf4kRksTf62GoDHhJ/AmiBCHxLzHGwxFUlsVTOlUH/RidnEYsxnNYK4Ig3IbEv8QI6dE+gppyH/7wYidO/dpj4JwaAIIoFRwRf8bYLxljPYyx7RbljDH2Y8bYPsbYVsbYGU6cl0gfs+XfUh0EAIxNRXC4fyJX1SIIwmWcsvx/DeAqm/KrASzT/90I4KcOnZdIk4mpKMoDccu/ttxvfO4eDuWiSgRB5ABHxJ9z/jSAAZtdrgPwG67xPIA6xlibE+cm0mMiHEWlJP5z64LG54HxcC6qRBBEDnDL5z8PwFHp7059G+EisRhHaDqK8kDc7fPZK5fjp+/WvHCDJP4EUTLk1UpejLEbobmFsGDBAtfOe2JkEp/9wxa8cmQIi5srccO5HXjT6fPAGHOtDm4QmtaSusmWf5nPi8tXtQIABsZpshdBlApuWf5dAOZLf7fr2xLgnN/OOV/LOV/b3NzsSsWmIlF88M5NeOnwIF63Zi7CUY5P/34Lfrx+nyvndxOxhGOFJP4A4PN6UBnw0kxfgigh3LL8HwTwccbYPQDOAjDMOT/m0rltuW3DfmzvGsEd712Ly1a1Ihbj+Ox9W/DDJ17F8jnVuGr1nFxX0TFG9EVbaqRBXkFNud8oJwii+HFE/BljvwNwEYAmxlgngK8A8AMA5/xnAB4GcA2AfQAmALzfifNmythUBL/6x0FcdfIcXKa7Pjwehm+96RTs7xnDv/9xK9Z21KOpqizHNXUGsWJXXUUgqawm6CfLnyBKCEfEn3P+zhnKOYCPOXEuJ1m/6wRGJyP4wPmLErYH/V784G1rcOWPnsHPntqPL75uVY5q6CxDE7r4Ky1/H0ZClOaBIEqFkp7h+/C2Y5hTE8TahfVJZUtbqvG6U9twz6ajRWMRG+JfoRB/svwJoqQoWfGPxjie3d+Pi5Y3w+NRR/X8vwsWY2wqgj++2Oly7bLD0cEJMAY0Vye7saqDPkrwRhAlRMmK/65jIxidjOCcJY2W+6yeV4vV82rwh83FIf47ukfQ0ViJikCyt6+mXLP8Xzw8iCgleSOIoqdkxf+5/f0AgLMXW4s/ALxt7XzsPDaC7V3DblQra8RiHM/t78fZixuU5TVBP4YmpvGWnz6L3zx3yNW6EQThPiUr/psODaCjsQKtNUHb/a5bMw8BrwcPvJI0LaGg6BufwthUBCvbapTlNeXx3sCe46NuVYsgiBxRsuK/o3sEp7TXzbhfbYUfZy1uwPrdPS7UKnucGJ4CAMvGrq48Hv5Jvn+CKH5KUvwHx8PoGgrh5LlqK9jMJStacKB3HIf6xrNcs+xxYmQSgLX4dzRVGp+HQpTjhyCKnZIU/53HRgAAq+fWprT/JStaAABP7Slc61+kdqgOqqd2nNRaZXwWIaEEQRQvJSn+YvA2Vct/YWMl2uvL8dyB/mxWK6tMhLWkbvIqXjJ1FQFs/9qVePMZ80j8CaIEKEnx33NiFK01ZaivTE5zYMXZixux8eBAwa51K8TfnNRNpqrMh/qKgJEGgiCI4qUkxf9g3ziWNFfNvKPE2YsbMTQxjT0nCjMSZlJP5xy0sPwFdeV+jE1FEI7E3KgWQRA5ouTEn3OOA73jWCQNcKbCWYu0+PjnC9T1MxGOwMOAMp/9IxepH37w2B7ctqH40loTBKFRcuI/MB7GcGgai9O0/Oc3VKC9vrxgxT8UjqEi4JtxgZpaPePnz58+gO89useNqhEEkQNKTvwP6OGai5vTs/yBuN9fS1JaWISmIzO6fIDkjJ/CXUQQRHFRcuJ/sFcT/yVN6Vn+AHDGgnoMTUzjyMCE09XKOqFw1HawV2DO+Nk3NpWtKhEEkUNKTvwPD4zD52GYV1+e9ndPbdfmBWztLLw8PxPhqGWYp4w80xfQYv4LeXIbQRBqSk78uwZDmFMbhNcijbMdy+dUI+DzYGvnUBZqll1C01GUp2D515os/x+v34uLvv8UthwtvGsmCMKakhP/7qFJzK1L3+oHAL/Xg1VtNdhSgJZ/qm6f6rLEGcCP7TwBAOgeCmWlXrmiZ2QS33t0d8HO2yCITCk58e8aCqF9luIPaK6fHV3DBZfzPlW3j8fDUKtY5rG3yHz///7Hrbhtw368cGgA7/vVC0WzYA9BpEpJiX8kGsPxkclZ+fsFp7bXYTwcxcG+MQdrln0mU3T7AMCzN12CjZ+/NGFbz8gUdh0bQShcHNE/IT2KKRyJ4ak9vfjMH7bg6MAEekYmwTnHwDgltyOKm5IS/xOjU4jG+KzdPkA8H9CO7hGnquUKqVr+AFBZ5kNrTRBVkgto57ERXH3rM/jYb1/KVhVd4SN3vYgv/Xk7GLQxH1nkL/juBqz71nr8+tlDOOMbj+MgDXQTRUxJiX/XoOa3npeB+C9prkLA6zEygxYKqQ74yshhn3t7tLQW/9jX52i93OaRHcdx1/OHjb97RrVU13K206df7QUAHOgdw+R0FJEopbogio+SEn8xaJmJ5R/webC0pQq7jhVWjp/QdOqWv6AmGBf/Tr3hnGGCcMEgrmNQz2AqD4b7vdprMRWJYcWXHsE/313YvR2CUFFS4t81lLnlDwCr5tZgZwG5fWIxjnAkltIMXxlZ6MWkZuEuKXTEtYkxDHn83ufVCkVyu8f1iCeCKCZKSvw7B0NorAyk7f4ws7KtBn1jU4bLIN+Z0kUsXfG3Cmi6/6VO/O6FI5lWK6eIRmxCX+RGTtnh0VsGSm1NFDMlJf7dQ6GMXD6CVfoi6IXi+hGRLeX+9B5376gW3tkuRUdxcHz691tw8/3bnKtgDojpYj+uW/5y6K5w+/QXWXgrQciUlPh3DYUydvkAcfEvFNdPqrn8zXz2ipNQE/Th/KVN0rHig5+FlPP/Px9/NSEjqxD/iamI/nd8XzH7u0+KBLr5/q34yF0vulBTgnCHkhF/zjm6h0IZxfgLaiv8mFdXXjARP4bln6a76x3rFmDrV69MSvkgKJSF3semIvjx+r149x0bjW2i4ZqOaqovz/T16eIvLP+Az4PfvXAUj+w4jsnpKJ4t8IgnggBKSPyHJqYxEY464vYBNL//rgIRf2H5l/lmN9ZhTvkgKJQJX/t6tAl5zVVlxjbh5pnWwzhjks9ffAzpvRw5DdQtf9uNd92xEa9QriOiwCkZ8Xcq0kewqq3aiAPPdyZnafkLqoNqy3+iQMRfuHbkcM6orvARvRGISuIvtolB4Jjk3drfqzUkx4cLY7B/NrxydAjDEzTYXeyQ+M+SZa3ViHHgQG/+zwIVfvrgDEs4WtFcXabcXijiLzw6snUv5m1FDMsfUpm2TeweVUQCTUdj+MuWbuw5rh70P+Mbj+Obf92JgfEwNuzuceIyssrQRBgPbzsGzjneeNs/8N5fbsREOGK8N4KxqUheT3oLhaMFudhSLigd8Rezex3w+QPAslZtMRgx8zWfEe6Z2Vr+CxsrACRP8NpzfBRv+9lzGJrIb9+/EH1ZxGOG2yfZ52/0Bkz/A3EXUDgSwyd+9zKu/NHTRlk0xrFNz/g6MB7GHX8/iHf94nm8/9ebcKB3DB/77UtGaGkm7OsZww8e26MUuT+/3IVFNz+EyekotncNY2wqfr6ekUkjRPcnT+3D7uNxt+Wn7n0FH737JezXjZktncN4+8+fx3m3PIln9/Xh4u8/hcnpKFZ/5VF87r6tyno9tacHJ0Ym8dKRQfz3k3sTyv7joZ14bn8/vvjnbei46SHl93d0D+OOZw4oy7qHQnhsx3EAwG83HklYZGh71zBu27APwxPTWPnlR/BfTyavPR2JxvChOzfhpSODmI7GEnrskWgM//Q/G7HxQD9+v/kovvLAdqOMc45bn9iLQ33j+PID23Hut9cr63fHMwfwvl+9AAA4OjCR8Gz+sqUbX3lgO8KRGL74520JIeI7uofxwCtd6B+bwrIvPIxNhwaUx88GamdumjDGrgJwKwAvgDs457eYyt8H4HsAuvRN/805v8OJc6dK91AI5X4v6i0GL9NlUVMlPCzuT85nJiOzi/YRrJxTg3+97CSc1FqVMNv12w/vwuhUBI/tOIG3vWa+I3V1kmf29uKDd27G99+6BkCi+yai/yH+jyb0CnhCmYyIBAorrN+fbNiHHzz+Kh742HnGtt16z+Dbf9uNx3eewGUrW1Bd5kdHUwWWtlSndT1/2HwUS1qq8InfvoyuoRD+6ZyF+N4je/COdQvw06f24bT5dfjdC0fBufZ7f91//R0XLGvCXR88CwDwkf99ES8dGcK5Sxrx3Uf24Kcb9uP+j56LXcdH0TOiiemJkbgwbesaNup+sG/cCHD408tdaK4uw+1PH8ChW6419n/frzahrTaIY7pL7OOXLMOO7mEsbanCL545iF88c9DYNxyJ4XP3bcHHL16K258+gMtWteLDejTV218zH6d89THc9q4zcO2pbQCAt/z0WRwbnsQTn74Qn//TNjy0rRu/+cBZYACu/9mzmJyO4dKVLQC0BnByOoqdx0Zw/tImfPOhXXjm3y7GE7t6sOvYKJqry/DK0SHs/9Y1mAhHMDYVwTN7+/DqiVGc0O/D165bjd7RKTAG/PCJV/H7zUeNXtD4VAQ3378Nn7tyOS747gZ8842r8c2HdgEAthwdwnW3/QP/8abVuGBpM9rqgvjE714GAKztaMD/Pn8Eo5MR/Ojtp4Exhmt//HcAwM/ecwamoxy/ePoANuzuwUQ4iq++4eS0fh/pkrH4M8a8AG4DcDmATgCbGGMPcs53mna9l3P+8UzPN1u6hkKYWxeccQHzVCnzedHRWIm9J/Jf/A3Lf5bi7/Ew/Mtlywx/t2BUtyqrgo7YEI5z6xN7EY7EjIF5WbCFMR+JCv9+/HsRU69ARoj/uGRRH+obx/+92otXdUNAlRBOpMroHwvjX+/don1PEs5UEBZ3Y6W22trAeBh/eLETT+w6gcGJaTyxqwcdei9tUO+NvXJkCJf/5//hpNZqDOl+/H49hHUyEsXlP9R6Lus6GhLKZJqqtPOJeR8AcPvTmoV+oHcMv3nuMD5/zUoAMIQfADYdGsBbf/Ycbrp6RdIxnz/Qjwde6cbx4UlsPDiAP0gptUWDefvT+/GXLd24cHmzcVzRyxwYn8bbf/4cekanjGc3EtKfCQN+8tR+AMALBzVLWvSApqMxY7D+e4/uwc/+bz+e/tzFABJDl5/cfQIf+PVm/Ofb1hj3WnD/S514cEu30Qv8+l/iUid+a5sPDeILf9qOq06eY5SJ4zMA1/z471jYUGGUiZ8mY8Cz+/sTkipmCyfOsA7APs75AQBgjN0D4DoAZvHPKV1DIcyrr5h5xzRY2lKFfb35L/6T+o+uLM1JXmYqA+qfS776/oU1L8RBfrmFVT+tsO6FT9vO8h+RZv9e9P2nAABvOaMdAJRuMLFGQt9Yai6yaIxjbDKC2go/BsfDCYnnRJMkclXVVwaMHEVigpo4TzDgxd6eMeztGcOKOVpPQ8xc9nqY0cBVlmmGwaBC/Bv1KKmekeRB7lvX78UDr3Tj9AV1SWUiQZ5qspyoe2NVIKlMCG3Q78UjO47jkR3H4WFagz0yKa6TYfPhQe36K/yYisSMBk827xqrApgYCBkN17RkAIgkhcLVIjf2f3xJc1Ic1685JLmJxLHqKrS6y0aFmDQoxoYe0V1VQHymfZRrjYQcLSiMCQaG7qEQLlrenHRfnMYJn/88AEelvzv1bWbewhjbyhi7jzHmuo+geyiEeXVBR4+5rLUKh/rG836y02SGlr9ACISZkTxNgyCse47EsE4AmI7orh2FdS9EQFUmXEJjU8kNXlBvXAcUkTJ+nyYGsq/52HAIv998NGlfAPjGX3dizdcfw4mRSZz+jcdx6/q9SfscHdAFtDIuoEL8hYjLzzygD/iLxsnvib/+FbqlqRJqMe9BnuAnaNIbhv0K96d4LzyK3na3bsk3SHUX5xF1VyXbEw2XT4q/rdCNkj5F3RsqtfqJ6CxZ4EUgQ/+49j2VK8+rqHuv3rDWVyQ3XKN64xRQBFeIhkvlexBlMc7ROzaFObXOjE3a4daA718AdHDOTwXwOIA7VTsxxm5kjG1mjG3u7e117OST01H0jYUdi/QRLGupRiTGcbg/vyN+ZjvD10yFheWftzlwbCx/0RCoXDvxCWDJYiD2l90+AjGPQmU9qxqSd/1iI/7tvq0Jg8AXfW8DvvXwLmNlsb/v1azTF3UrV6ZfspAFfp+w/DVBk8U/nrZC+57XG5chv+jRTCZflzEorhhgNuZLKBJBCfeZSlTF/ZPFVdRvQG+c5AAFIaai7j6p4RJGiRi3kF27ZfoxhdtHrovYSzRq8vMWDdaUwrAz3DcKFR80nkmytIqGQbV8uDCgojEOztXfdxonztAFQLbk2xEf2AUAcM77OeeiWb4DwJmqA3HOb+ecr+Wcr21udq7bI7qYTkX6CJa2iIif/Hb9hKaj8HqY8XLNFnnRe9nyEgPK+YbQI9H4RSSBmrZx7YSNMlWvQCsbU0TtiNs7pmgYVOGRYmxgOsqNwcRD/RO4/ekDxrmFYNQpAhXEdcmaHNAFXbh9ZFdfQK+gWJJTfoaibVJFI8UHx5Pvh2gQVL3fSNS6EY0aDYOcUynR8pcbNVF30eD5vPJvMbFXoLKspxV1EeKtuo/iulTzeMT9mFL87kXj6VMovKifxyM3eNpnMX4mqqDqcTiNE+K/CcAyxtgixlgAwDsAPCjvwBhrk/58A4BdDpw3ZcSLNdfhrtSS5iowhrwf9B2djCT4jDPhvKWNWNpSlWCV5Zvb61P3vIzvPrLb9gW2c+2I67ErG7OxkFX3Q4ic6p3+44udOO+WJ43BSSAujsLylNsoEUYYT0ednJRO1QD5Tdaz3JgLoVaN3wjBVF2X3TWL3oDyPirEWFj3yrqLsQzd3+6TDJmY6X6oEPVL7LxYu7Oi0cT7LyPqPKX4njltiMywPiAtu8HMBoq4FpWrzGkyVgTOeYQx9nEAj0IL9fwl53wHY+zrADZzzh8E8EnG2BsARAAMAHhfpudNB6dj/AXlAS/a68vzPtZ/KDSt9E/Ohrs+oIUNnnvLkxjVBVD1guSSP7/SDSCegE/1cqssQYFKmMxlSkvXsAiTy1RWokAslPPQ1u6kY4m6q1wuoelk8RcCKoRQJbxjhnUaF1AhVioBNQReacFb3yvRoKi+J8RO/p4Q+PEpURavuzHQbuM6mZhOHGwF1OM9RhkXAm9t3dsZDkqXkM1vZ0rRwxB1mDCtK+FRXaDDOGIOcs4fBvCwaduXpc83A7jZiXPNhu6hEDwMaK1xdsAX0Pz++R7rPzQRNqJNMkX8KCtMlv89LxzBoqZKnLW40ZHzOIFhESq77onpHWSmbdw+QoxV7iIxiKx+8UWYX/JLXVOuvYbjkvAaFmEk2WUlPhniL51OuBtUDYMQaiFQcplhzSoEzfDrKxs867BYsU1VZrjipDLhyhGuJ/l8oq6qHlvc8tcjZhSLEE2pGqeY6Bla92hU9yNi3CvrXpKdwSH/dsRjFeLPDcs/6euOUxIzfDuHQphTE8zY561iWUsVDvSO5/WU96GJaaXPOBNkt8+R/gncdP82YzKLG2w5OoT9vWMYm4rgL1u6lfuIF98u/1JUIfB2A77CegvbuDJUDYMQCpUFH7EZUFVZyEaZsO5VDZFS4BMbJ9UYiMpKt+slRW0GdcU1qxoN0cOQvycsdnFvE0Uyse7y9+LPOfmajcYpYj1YrRqzMspsLH+lu8hw11l/T/ksTY21t1As/3zHqVTOKpa2VCEcjeHoYAiLmiqzco5MOTYcwsq29GaTzoRs+R8b0dwWPaPuLX5y3W3/AABce0obHtp2DCe1VuOk1qqESA+PEaKY3oC0IY62FquN2Cm+Z8R42/Q0VGVCYGQ3kxDJScX5oiY/u3xMww2jqEvEsKitxV/V4EUMn3/yPVZF0dhdl5FLyXAlydeVWBf5mGIvVQRXxM4tJdx0SoG37gnFrXu7RiM9l6F5XMWpyah2lITl3+XQCl4qlrVqorr3RH76/YcmwugbC2NJc5Wjx5Utk1xmgBSzjrd2DmHRzQ/juf3xBVvs4tPtEC+8XSSQnWvHzrJT9wpm7mkkRKno/6ssybg7S1jB8WMZLpNYstCHFcJpHNN2INvazTE5nWzdC8wptQHZP59s+Qt3SERxzXbpue1ccXZCbWf5G64kpUvIZhzB1iWU2FgXSrRPXhONcRwbmnQ8xl+Q7+Ge27u0WYQr9MFPp5A9FKrYcLcQwnK4fwIAEhKDCcvfbrBVeUybiA27KCHDP6/sMdgNBgurz7rHoBblZBdI1OSDV/n1xfcSLH8bC9l2ADxi7f8WdVdFxYiZ1fK9ElU1QkSl+5Hk9lHM2RCNWsI1x5L3F0TsXDSizKbu6u9ZX3PEpkExZ5cln78D9I5OIRLjWbP8q8p8mFsbzNtB3+3dWnKu0+YnT7/PhGQpyg3ipRaDpn2qCVZWK9FboBI5c5nSx21j+QuhUIlQ3F1kbT3LZULcIgrrOWKymmWBN9wONta96l5NKVw05vqprFnD0lVawcljBYb4GxPHkgdGzb0XbVti/RIS+NlEKkVMvntPwkCxnQVvNxhsPY5gN5YUNln+bkT7FL34dw1pFmG2fP4AsLS1Om/DPbsGQ6ir8DsW7WOQJ+qfZF3aDKimil1bYTceYOu+SbPMmIAUSXadmK172UKOmCxquZ5my1/G1p2lqIO57iprNmyIa7o+9eS6m107CYn4TA1CwoCvzXWZLXHZz243qJtKRI+d5W/XixPfdyPOvwTEX8vp0Z4lyx/QIn729Ywl5ITPF7qHQo5PbgPi+VCcjiJKlymTX1l+AnE/cXo+fzvsIjamFGGZgrgFr4gSUoi/ebwi0fLX/lcJmzi82fev7W9dd7uJbXYDt2HDZWVt+SstZBuXi+q6zAO9UYXlrywT0Ug29VOFvtqFcxp1twkhVln+drPKza4rcvs4gJjglS23D6CJ/+R0LGnVo3ygfzyszJyYKe85eyEA4Bwprt8FYyUJczy2bBHa5Z3J/Lw2FrxNPhg714nsjmHSimHaMRURPYowy6hh+Sf6kOXvGYOL0s0yom/SdFlFYtbfi4ukTcMglXGTO0sWcVFV9VhGYk9BNc6hqp/Yyy6tt304p/V1KRMG2jSw8WvQ9nEj1LP4xX9oAnUVflRmMT92Pq/qNTI5beSSd5L3n7cIB799TULecc6BL/xpGz5812bHz2eFvLIWYJ7U5LzlL7CbuKRqbAzxT7PRUPU0oqbBT5XP3xw9AsQbgrCiYQgbg9XWDZd6Fq91b8Jwj9jEvMuWdXxd5UQrWC4zInps5ijI1xVRuMbiZdbPZNrG8rcL9bRLZicad2UacdM1U6inA3QPTWbF7SGztFmEe+bfoK+TeX3MMMYSUtd6GHD3xiN4dMeJrJxvYDyMD9+1OSF1rxHzrpgxGo8ecd7ytwvZVMfKW7sf7MVV4faxWWbSvAqZaoZvRCmg1v5ou/QOqYSIqmcGJ7uEzHMUVOGcRq9AMZEr3ttJvh9qgbduuMyNqKrMbsDXbl5BKmnE3Qj1LPpJXl2DISxodHYRFzO1FX60VJflZcTP6OR01sQfiKcxNsM5d9x6efCVLjy640TCgvLxcE6V/9va0soUe9+9oiyFcMmEmPekiB6VFZy4j1xmuEAUAq9yj6SSz0htPc8sdqnOHTC7pexcJ6rOnGpim2o+QVL9bMYk1O4sm8ba7pi2DWzieAD5/DOEcy1VbrZi/GWWtVblXay/tlB1DNVZcPsIZMtf7m5nI/a/XV+JbX9PfP0EY01dhVvFzv+aDewsePM+MiqRNIuWbOnGQyKTxznMYhxVCLzKPWK2rFXYC7xNb8fGrWIXpqocGDVCWK0bKfl+2Mb521n3Nt+zvy7rY9ql/zDPTqZQzwwZmdQWZ3ZF/PUEb5y7IzSpILJuZtfyV/+EVJEQmSKSUCYuuqGfTxErr7KMs4kq7t6MnYtBtsTjET3J1qz5ezJmEU+c4ZvsS7f6vop0xc5urEVVv0iS22dm94jqmOqBYhvBVS7laX0fIopGxlymnldgbYyY02tQqGeGZCuVs4olLVUYm4oYa37mA2IhELcsf5lsRNiotSTR7aOKa3cb+3kCCkGzWSxFNVkrfqyZBw5jCiG0E3g77MIllfWzOY/qWs29HVXjEY/gsi5T3yvrxkIl4rYNuF3vyKYsZtMQxSe26T5/F5S5qMWdLEucAAAgAElEQVRfrOCVzTBPwTKR5iGPBn1zafmrfJ6ZIl7qxNcrcfBNlecmn7AbJLQbKFahbCxMx4o62BNVWv6z7EWortXccNk2Hjb3RdUw2M3wVR4/zbqnUpbOsSnaJ0NE3L0bbh+R0TOf1vMdMSx/98Vf5dfMFOEWUaU+VuXAyZXlb4edbzxd14kyHbXJn++kF1I9iJle/QSqIrEtlRBdOwFVXbNdUjoV6dY9lbJ0jk2J3TKkayiEgM+DpixMcjLTUl2GoN9jJBjLB4Tln404f4FVtM90lOPogLP3wq5bL8YYVDM/8wn7Ad/0LGsV2bxmlVhms3Pl5LHzbanRmSCff4aISB83ulCMMXQ0VuJQHop/Ni3/Kotj/+nlLlzw3Q14dl+fY+eKmcIYtW3a/3bpDPIJO/eD3SBhqti5iTIlm8fONvloCNjhIZ9/ZnQNuhPmKVjYWJFXbh83BnytehWbD2mLke88NuLYuYT4Kyc1qWZ35qHP327gVuWuSPcSZjuYW+zk42/BDrL8M6R7KIS5dc6v22tFR2MlDg9M5E2Ct5FQ9i1/q2yhZv+tEwjjLWF5P8UkqEKj0ISJyD6U2ycDpiJR9IxOYV5ddmf3yixsrEQ4EsubcM/RyWkE/Z6srF0sqCyzmOGr/+9ktIk5rQEg57YvrG69DFnrhBma4ZsBx/RUzm7E+AsW6mkkDuWJ60fL65PdlMuNlVqqhbUL6xO2i8luUQct8qgp5UHCtgK2/AnCDLl9MiAe4++e20eIf75E/IxOZTevD6DlNdr61Svw2SuXJ2w3JhQ5YPn/fvNRdNz0EAb0VboSLH/d4LcL2yOIQoPEPwM6dfFvd9Ht01ZbjoDXkzeWf/9YGE2VZTPvmCE1QX/STF8jJt8Bl8Yv/34QANA5qDWqEZXbhyx/ooggn38GdA+FwBgwp9Y9y9/rYZjfUI7Dfflh+WdrIRcVAa9Z/LX/nRjMFBO4xAsRU7l9CtjnTxBm3FgYqWjFv2swhJbqMsvcM9lCi/XPD8t/wEXxNw8qi6yLTrh9pky5+hNTH0PfRpY/UTyQ2ycD3ErlbGZhYyWODEzkPLtn/9gUBsbDrkU7+b2JP9aJsHNZPY1F2kXyNoqOIYoccvtkgBbj7774dzRVYCIcRa+02lQu+OjdLwEA1i2qn2FPZzBb/kL8OQee3deH3cdnP9krLv7JKRwIohihUM9ZEotxdA9NuhrmKVjQkPuIn+GJaWw8OIC3nNGOMxc2uHJOs3ttIqxNMIvGON51x0Zc9aNnZn1sEckjFvsm8SeKHXL7zJK+8SmEo7GcuH06GrXsnof6cuf339erLST/ulPbXDunz2SqTDoo1OLIYiFwcvsQxQ6J/ywxFnHJgfi36fMKRDrpXNAzormcWmvci3TyW63oFcnc9y9eBGH5E0SxUzA+f8bYVYyxPYyxfYyxmxTlZYyxe/XyjYyxDifOa4WRxz8Hbp8ynxdNVWXGDONc0DOqiX9LTfZj/AXmUE9B31g442OLF2HSgYaEIAqBggj1ZIx5AdwG4GoAqwC8kzG2yrTbBwEMcs6XAvghgO9kel473FzBS8XcuiC6h3No+Y9OwudhaKhwJ8wTSB7wFQxNZC7+xjq9ZPkTJUKhWP7rAOzjnB/gnIcB3APgOtM+1wG4U/98H4BLWRaT7HcNhlAd9GV1ERM72mqDOD6cO8v/xMgUmqrK4HEjZEDH6seqWrZwtsd24lgy4hdoHq8giFxTKD7/eQCOSn936tuU+3DOIwCGATQ6cG4lXUOTOfH3C9pqy3Esh+LfMzrlqsvHjCymTljrhs/fYbePX18xw+cl8Sfyi0IRf8dgjN3IGNvMGNvc29s76+PkaoKXYG5dEGNTEWMNXbfpGZlES7V7g71mgv54mmcnEq55smT5C9H3u7FsEkGkQaHE+XcBmC/93a5vU+7DGPMBqAXQbz4Q5/x2zvlazvna5ubm2VdocCIng72Ctlrt3Lka9O3NteUvWdJOrJ0qFrOenHbW8hc9FLL8iXyjUHz+mwAsY4wtYowFALwDwIOmfR4EcIP++XoAT/Is5T8YnZzGyGQkZ4O9QDyNdC4GfaejMfSPh9FSnUu3T/xn5YS1Lt4DpxfhFoPUPsVgtTgnDQcQucCNdcczFn/dh/9xAI8C2AXg95zzHYyxrzPG3qDv9j8AGhlj+wB8GkBSOKhTxGLAja9djNd0uJPWQEUuLX8x0DzHxRh/wXlLtWEcOc+Pk356p+d2xd0+yS+aXcNAENnGDcvfkZU+OOcPA3jYtO3L0udJAG914lwzUVvhx+evWenGqSxpqS6DhwHHcmD5v3RkEACwrLXK9XPf9YGzAAAXfn+DsS0Ta/1PL3eiqSp7PRifx1rg/V4PpiIx+D0MmQerEkR6uNHjzO4yTyWKz+tBa00Q3S5b/p2DE/iXe15BZcCL5XNqXD03EB+Y9Vu4ff78chdGpyL4p7MXpnS8f713C4DszdQWlr/K5+83yjwAEnsvXg+j/EJEVnEj2ofEP0u01gTRM+qu+P9jXx8A4DvXn4qqstw9WqsB1E/d+woApCz+TuJhyW4jn6KxMsr03oA5VTWgzWYOxWi2MZE9Si7Us5iYUxPEiRF3xf/IwAS8HoarTp7j6nnN+PIwdNLKtaOVqQUeUPteVQ0CQThJoUT7EApaa8pcn+V7dECb35DrQcqZxDHdkE0njCBV7iFjwFfZMOhuH0VD5vbqcETpUShx/oSClpogRiYjCDm4otVMHBmYwPyG3IW4Cqzy/AhGQulNfnMiKFhl3QthD/qtewWqhmym6yMKj2xb2ukeviBCPQk1Ip2ym66fzsEJYzGZXDLTpKl01/V1YnBVlb9HCHuZz5tU5lOEeor3sZDF3yr7ar4fG8hujyvbrrx8/M3kX42KhDkui//4VAR9Y2G01+de/Gf6oacr5k4sAq+qk7D85TLRRgR0MfBKFphoQNIVoXyaKJZNkcu2gGazccm2OOejqzD/alQktOrpFU6MurOWb6e+gE1eWP4zqF264u/EZHCl28crxDxeJrrbQgzk3reqsbBCvgW5HoORsVp0J2GfWYp4tgUum41L1nstefQbEORfjYqEFmH5uzToe2RAWzN4fh6I/0xhaukuw+iE20cZzumxHvAVDYN8LUZjoRw/SNwmC75qBnGmiGrZ+apVRUKE7KokD3LbPUpzmaoHpULU2c5IUJ1X1SBbHTtdUrX8U0kDriryp3Df3e4hkvhniZqgD0G/xzW3z1Fd/PPB8p9JqmMuir8hNErL39rtYwz4StasN4XGQiALfjYsf18KAqo6r7DOVVFMqmPaNeTmBlW+L3bXnEpCPVVjbTwTm1Di2a7N4Pel9j3hBrSru+19t7svLvcOSPyzBGMMc2qCOO6S+B/oG0N1mQ/1FblZwEZmJjdNupZ/Jgu2xwVN8UIqXjYGllAmW/nik8q9IURBaI9sgcbDRmcWmFSDPOxcUEYDpjifYfkr3nzVjGfjmsUAeEKjlnh8+b6Ic9tZ8CoRNyxr1dwLQ0Cte152FrzdvVV9Lz7ALzWGNhMD7e67OIaqLD7Z0F3Tn8Q/i7TUBI3F1LPNK0eHcPK8GldCxGZiJqlOxZKXG5DpDNYEiItC8n2pDvqS6iNun1iTQGX5qoUiUXxk8U9vrCC152efmsI+Z5HVeVTfMwugfA1e0zHke5xKL8m27jYNlzpyy7phUNVdIC4hoLzm5F6SOLVdT9J+QmF6ZdmExD+LtFSX4YQLKR72HB/F9q4RXLS8JevnSoWZxmejMY7+MftGUW4fpqMZWP42L1ZNud+oj5mKgCb+sr4JgVdZ/mYRkcVfZUEa9TMJmfynnf9aJUzmMuUcBV/yWEbS9+S667a/X2F1m/3fsriKz8rJdXYJ9WwaDVH3dCflqa4rfj69nj5Z4BMt8YRGzXD7WPf+lClBfHbzRqy/l01I/LNIU1UZBsaynxPy8Z3HAQBvWzt/hj3dQUipavIUADy8/RjO/OYTeP5A0no+BpGYM7n747H8yXWpLku2/MXKYw2VAQBx8ZNRCZohGL5ky9rOXWS2IOXzGaGlSgG1FoxUhFDtjlEIm8kKTrSQExtDubHymuqXEP1k4+ZQNTLmutu5hGyFV3H/y/zJvTKv6VkmjglZ1z0+kG3tYrR7Jm6kdJAh8c8ijZUBjE5FHF971syh/gm01pQZgpVrhMtGXs5R5vkDAwCArZ1DlsdwKmumeLGU4q9w+4heiyH+suVvHDP5JTXcAZ5ky9oQSaWla9omHdrelWHj/07heyqZUR0zPu/B2vIXz1nu8ZndPgluMFUjI8o8M4ukerB65mtW9RjEBD87t4+qF2fcY0/yvVLVwT7wwLrRyCYk/lmkUc9FPzCeXev/cP84FjZUZvUcs6HcQvwFdgO5Tol/PJbf2u3DGPDOdQtw6ztOM8pq9TInfP6CMn+yKynZ8k8us/ObqwYeAzZiFx/wtXP7SEKIxJ6Tqkcjyrg02hNvKEVPI/69VPzzdsn2lO4zu1xMNi6oMkWvwM6F5zGJuEfZ27EeHFe7rKyvK5uQ+GcRYT32Z9n1c7h/Agsacx/iKRibigCAdVpp3URUhXwOjIfxsd++5FiDKcRAlcLh5Lm1AIBzlzTi228+BdedNs8oqw7GGwYzKveB2Q0ja5A4hhCaRIFPPFaqk8rsLEm76KK4G8a6TGXpltkMgBvir2ivhetPNZZhF85pW/c0B4PLbFxJwu2jmrsRr3uyz98YK5DdRaZQ2QRXkiexIUmMBsvNgC/l888iTVW6+GfR8p8IR9AzOoWOPBJ/8eNfM78Oe3vGksqFRqiCeO5+/jAe2noMNcHUQ1Z9HmbZi7BLybB8TjVe+MKlaFasFqaywlSRIebzxN0qyRZh3PJnhlLKjYZ5YFvUQSVM/lTcIzbx5iobUzSQqqgdldtMWPMqt4/5mCoBtXOBKHstYmxB0QDZuZICCt+9IKjXT3UfRd1Vg/7xespun8Q6+L0MIoeh2E2eSyF6t6lMessGZPlnkbjln71wTzGzd0Fj/rh9bn3H6fjJu89A8wyLyKty9jTp3+keSn0JzFQm3FilHmipDia4JC5a3gwg/pInWrqJDYlc5PUmCmGiBa8LqGKWp6i7EBr5lhgCYzNQrHaB2A1+Sg2QCaXA6/8LK1g1BhJ3+yQjvqfqTQR8yfdDNbYgsAtTVTVc8ToIgbe2/OX6iWegKjP34vwKy99otBMmCCbunzBzPIU5CtmALP8s4obP/3C/Jv4L82Bmr2BuXTnm1pVj17ER2/2iioieOt3Xns7MaL/Hg0moo4NU0T7rP3MhDvePK/e/471rEY7G8Nx+LRJJ1gtzyKaHMaMBSyU9dJkhoAxCKv3S98amEgXUKLPJOlqmGFdJxe2jcmcZFry0TXxWW8GJZarJfaoB1XhZXAhj+nftBnVVjW687jO7fdQDvsnH5KYyn6phMBqb+DENy18R9SN2i6cNiZ/Pbgwkm5Dln0Vqgj74vQx9WfT5HxHin0duH4FV6Jp4gVSeGrEtnMbELvHSqM6nis1f0lyFS1a0WhzLg4qAD8vnVAMA3nj6vKR9VHla4u4R68gXdepo6zLxPWWDYuOOsRVQRd0FytBcQ+yS3VmCMouQXrlMFjazgKoGwK2Wz9T2t7b8VW4f0UAqff4+RYNnilZTNhpirECeH2AIfHKPwRi/8SQPuMdn/7orxyT+WYQxhobKAAbGs+f2OTwwjtpyP+oq8iPMU0blmwXiUSGqAV8R3x9JY2KXnZtDKE1Zml3q9voKHLrlWlx32jw0VZUlvOTic0J4oP6/EFA58iXu80/2twtr0RDxFBsN2wbFdD4ZW9eJwnfPTWVM2eBZjweoooTEvbFtUBTXZZccLei3/g0EbcY5jAZPumbhi1f1GETDoOoVxI+pj3NIt8U8QC83DHZpK7IJuX2yTENlWVajfQ73T+Sl1Q/E/eBmhLiowjmF6KcT6imHNk5Om3oMuuiUB3xY2lKFT166LOXjCv5x08XgHDjt648B0OZvAJogjusrtZlFUoXKxWCUGS4XOdWEtYjHv2ftHlHNs7ATf5V7SbhjVAIab7iSvxcXSUWDYvjU9e+x5DJVL0SVaVUgjuVVDdzaRCoFfMn3PWbqmciiHDVdV2LDoNdd0eDFxT+5zBwe7Na4L4l/lmmqCmQ12udw/wROba/N2vEzwcryF7l6IjGOzsEJlPu9xviIEH0r8ZcCZQx80mDr6GRE+T2fh+GJT1+Y9jUA8RddNCwt1UF9u3X0iEzM5EZIN1xSdR6zX1pGiIlS/H2JFmjCeRSDuubBzwQL3lSW4OoynsnMdWeqMkXdjdm1Suvem3SseJlNo5tCmKos8OZegcrVqHrO3NSIyl8z9zDcmulLbp8s01AZQH+W3D6T01F0DYXQkUeRPjJWP2Ihoh7GcP53NuCsb603ykTIplV6B/WKXNZCI1DFhs8WEcUlC2/cT5zsyoj7uJPFzmcSSVWTp7KsYVjI1m4f1SCr3YQnIaCVgbhNGLf89YFb6ZpjZuteqr1dr8AcJZTgSmKJdZER51NFbtkNBqtSOBhlNgvQqCKIhKtS1VCKa1ZFRok7E69ncq/Abg5GNiDxzzKNldnL77OvZwzRGMeKtuqsHD9TrMVfc5WI33gkxhGLcfSMTMZ9/haWf9DG0rXzf6sii9Ll365ajo7GCqW/PZ7PKDmsMGYr1Il1V0bMKBo1c8ihjN9GCI0cPTZ5bkTaC0C2xJO/FzM1anLVY6bGUMbslkrIZ2T0WhQ9Bi6+P7NrLXFbcsNlLrPrccn1i5oaw0Q3GPS6J5fFjLrr1r3i4VTqkyJJ/IuExqoAxsNRQ/Cc5KUjgwCAU+fVOX5sJ7CatCIieWTXzvce24N131pvpMC2cvsoBdQmeZvwzw9NTKdRczUfvWgpnvrcxYbbSiUmQWV0i26xepOte3MoaqqWvxBopaDZDG6beyEyosYJxzT5v9W9neSIGdHWqixysa3MxgWies6G5W8zMKqaHCjOp0o3YtdbVA6Yi8Y6IWxXw2P0QJPdPjGTu0i+ZvFM6sq136oTa1anAol/lhHikw2//6ZDg2irDWJ+Q7njx3YCK1dLOJIs/nc/fxhAPDWEVbSPvfWc/HOeW6fdGyfnWkRMLzKAJJFUDzwm19Oou+K6zBFEMiIvkSpiSjQMqrsvXDMVgeThPnGkhEFMJLpa5Psfd/sIy18erIZelmxZB0w9NVlAhcvJp5iPkDRQrKi9uC8yop61irKA0egm30eV6ynecCmin4TbRzHgK3q0ysFx/f86fSEm8X5kGxL/LJPNWb5bO4ewpr0uLxZwUWFp+QvxlxRhRB+oFRlQrS1/ldsn0eKSOXtxIwDgzIX1qVZ7RoTln2Dd6/+rQgBFDqF6PRxXrqdoI+zcN0rL30hHnVy/apvUGEK86hUZYINGwxWv+8q2GgBS+KjK7aPwqYu8TqrcPuaZvaqZ0sLVIv+CxPEbFXUXPyWV5S8MCVWuKXEN8jiHOSWIXD9zlli5fslpPJLrIOoujByt7taNUzahaJ8sI6JYnLb8hybCONw/gbe/Jj9y+KtQWb9A3HKOKqz7kB46adX1VQmhEFOVgK6ZX4uXvnS5o8tbijrMrY33uESDpkqn/NU3rMI71s2XBFGynmPiGpL95gEbd5YQGNVYRtDw3Sdfs2g0VMds0HNRyQ3Xt950CnYfH41bvFLdzQPL8liB+DylD+431wTRPTyZsL/4HajCR8X5ZBtAtC0tirQhlabGRkYYEirjQLhj5brXlPsxMB7GuC7Qcu4n89oFsuElPguBHw7FXY3Teh1aarRjjUriL+6D2+JPln+WacxSZs9XT2gJ01bpllk+MlOKWpXAh6bTt/zt/MQBrwcNlQFHe0dnLKjDd68/Fd9442pjW5eei2hurRYGKgtoddCP13Q0JLlJgOSIGRlxPcroFl0Jq4I+nNpei5uuXmGU2a045jFFlgDAWYsaAMQtUK+Hwe9laK0pw+p5tbj+zHZDJGVXSLueUkTMYJcta9HwHNPTdKycEw9KMHofFX5UlfnwuSuXG2WiWu11ya5MkfiuXOGyEvdRnuH7mctPwuvXzEVlWbJxIObGiNDgKkXDdUxvrOZKdRF1b68vh4cB/3zhknjd9cMvaakCYA4R1RtBveGSf/rit15T7q4tTpZ/lmnUrSmnZ/l2DWlpHebnUU4fM8oQRQmVwCdN0tIJ+DwIR2K2Pn9Vmd2kq9nCGDNWTasIeDERjuLcJY14dn+/Yb15PQwvfenyhPWHxbWVB6QoIZsBWDFrW7gMmqoChtDKk7Ue/Pj5AIBb/rbb2KYdm+NHbz8NVWU+fOg3mxOO5fN4UBP0oa22HHd/6CxEOcf4VBT3bjqKD792Cb78+lUJUS4L9N/Z2o56/PGlTgDAJy9Zig/eudnoVck9jbee2Y4nd/fgg+cvQkdjBd5z9kLcs+mofl3afi01QWz76hVgjOFLD+xIqLvHw3DhSc147UnN+MZfd2p11wVUNFzz6srxyUuXIhSOYn/vuH5d8Tp/Qp/Q9039+/IA7t0fOgv3bjoquZLi1v0nL1mGz/xhCz556TLEOHDjhYvx3xv2AYi7cRc2VmL/t65JHPCV1nT42XvOwMq2Glz4vacASA2XX5Pc689sR2XAi9pyPzYd0gI3ZnpfnCYj8WeMNQC4F0AHgEMA3sY5H1TsFwWwTf/zCOf8DZmct5CoKvMh4PU4bvl3DmiW5jyFhZQv2MVQA1bir46K8nsYwpgpP056cdxO8MIXLkOMc/g8DMOhadSW+7F6Xg2+eO2qpJXVRNrt95+3CC8feRlA8gQwGWOlMX2fd5+1ELeu3wsAeMuZ83DX84dx/Zntxv7/74JF2HlsBBcsa8J3HgEuXdmKdbpV/z83rEXXUAhNugtjYWMFXvnyFWBMa8x80O7tQ5+8QHmdZy9uxBOffi2WNFfhe4/uQUXAi0tXtuLQLdeic3AC3/7bbrz3nIV4cEs3AODqU9pw8NuaOC5p1izht+sN5s3XrERzdRBXrGo1xLPc70U4GsOyVq2H0FpThjs/sA4AcGwohPFwFK365LqW6jJs/PylKA94DR//ju5h3PX8YVy6sgUr5lQb2WEB4KrVc3DH3w/iwpNa8K2Hd2NBQwXa6yvwmSuWIxSOIhrjeM/ZC/H1v+7EKfNq8ZYz2/EW/b7+4G1rAGgN7+p5tfjuW07F7zcfxYo51UbdFzZWYFlLNS5a3oytncNory/HafO1CLyfvedM1Ff48fLRIbxwcADzG8qx9z+uhs/DjO/fvfEwnjvQj8XNlfj6dScb3802TBVXnPKXGfsugAHO+S2MsZsA1HPO/12x3xjnvCqdY69du5Zv3rx51nXLJ8759nqct7QJ33/rGseO+e/3bcX63T3Y/MXLHDum0zy7rw/vumOjZfm1p7ThoW3HErataa/Fls7hpH2rgz6MTkbwulPb8Netid950+nz8KeXu3DDOQtx53OHE8qEAOUbHTc9BABY19GAFw4N4KarV+CWv+2Gh8X93B9+7WL8/OkD+LerluOtZ85HU1UAzx3oR/9YGK9fM3dW5+Wc46k9vbjwpOZZT3wTEUaq7x/sG4eHaZZxOkxOR8G51lg/f7Af5y5pStonEo3hsZ0ncPXqObN+psOhaQS8noTel3x8xtisZ9gKLVXVjXOOwYlp5VKrnHOEozHHLH/G2Iuc87Uz7ZepWXQdgDv1z3cCeGOGxytKGioDjkf7dA2F0F6fv1Y/YJ1DX6Cy/EMWln989qRNkjNVuGQeCr/MHH2MQAwOyoN+V66eAwA4Z3EjmqvLwBjDuUuaZi38gHY/Ll7RktGMZ4+HWX5/UVNl2sIPaM+1POCFx8OUwg9o/vxrTmnL6JnWlvuVwi+On0lqBcaYZd1EkkerMrddPkDmPv9Wzrkww44DUOfJBYKMsc0AIgBu4Zz/OcPzFhSNVWWO5/Q/OjiB1fPyM6ePYKYf9LQiTnHKIsZZvJMqN45dOoN85ZfvW4uhiWlEYhwPbuk2RL+m3I9BfULaGQvqceiWa3NZTaKImVH8GWNPAJijKPqC/AfnnDPGrHxICznnXYyxxQCeZIxt45zvV5zrRgA3AsCCBQtmrHyh0FgZwH7FcoazJRrj6BoM4dpT2hw7ZjaYyfJX5eyfshjwtbP844usxM938twa7Oi2X0wml4j1BDjnWN5abViczVVlxgI9BJFNZhR/zrmlU5kxdoIx1sY5P8YYawPQY3GMLv3/A4yxpwCcDiBJ/DnntwO4HdB8/ildQQHQ6HByt2PDIURiPK8jfYCZB1tVVv5kRO32ia8Xqwhf1Mti0vjVfR8519KFlE8wxrBmfh1iMY6PXLgE7zu3AydGJjEymXk6CoKwI9N+8oMAbtA/3wDgAfMOjLF6xliZ/rkJwHkAdmZ43oKisaoMk9MxTITV6YbT5age6bMgz8VftfasjCz+wvK1svyFUW9kl5SsfBGHLS/9WB7wWvpY8xGPh+Gmq1dgTm0Qa+bX4YJlzbmuElHkZCr+twC4nDG2F8Bl+t9gjK1ljN2h77MSwGbG2BYAG6D5/EtL/B2e6HVkQItpnl+f3+JvRIVYjKHJOUzEPlbLN4qY8/jatfGf7nlLtQFCsfSiXbIugiA0Mhrw5Zz3A7hUsX0zgA/pn58FcEom5yl0xESv/vGwI66arZ3DqC7z5X20z7y6crxtbTuuXt2G9/96U1L5lOTi0cSdW87sFY1DXYUfteV+fO0NJ2P1vBocHQzhtPl1eO7mS9BSHcTTr/biA+cvysblEERRQTN8XcDI7+NQuOfLR4Zw2oI6RxcoyQYeD8N3r1+DntFJZbls+auyKpqPBWhW/ZavXGFsX9qiWfttep6dX71/XUZ1JohSgfrHLuBkWufxqQh2Hx/B6S7NAnQCq+UcZfGfac1eY9p/nsftE0ShQOLvAobbxwGf/9bOYWRrQxoAAAwLSURBVMQ4cLqDKYqzjdXEGdm/P9N67RUB6/VvCYJIH3L7uEBFwIeg3+NIcrdXT4wCyO9snmas3FNWkT0q/vmiJXhuf7+Rn58giMwg8XeJxsoyRyz/g33jqAx4lTnN8xVLt49FZI+K1fNqcd1p85yqEkGUPOT2cYmmqgD6HPD5H+gbx6LmyrzPWSNj5faZyc8vU0ipGwiiEKA3yiUaKgOOuH0O9o1hUVNaCVJzjhN+ej+JP0E4Cr1RLtFYlbnbZyoSRedgCIua0s+amEsyyZQomClPEEEQ6UFvlEs0VgXQPxZGJusnHOmfAOfA4gITf1n7Z9sOzLQkJEEQ6UHi7xKNlQGEozGMTc0+v88+PTPo4ubCEn95fEKVlTMVyO1DEM5Cb5RLiDVCM3H97NXFf2lLYfn8ZWa7rCKJP0E4C71RLtFQlfks3709Y2ivL0dFoHAjdGdr+TsxbkAQRBwSf5doqsw8v8+e4yNYVsBWP5D9BdUJgkgNehNdojFDy//EyCRePTGG1yxqcLJarkPuG4LID+hNdIkGI6f/7Cz/p/Zoi6RdvLzFsTrlAsrNQxD5AYm/SwT92spSXUPq9MYzsWF3L9pqg1ihL1hSqKSbhrqpqnDSWBBEIVG4I4cFyPz6cnQOzm5x7peODOL8pU0FldZBRSraH/B5jHTP6z99Ia1nSxBZgCx/F2lvqMDRgfTFv2dkEj2jU1g9rzYLtXIXXwrqXyaNC9RW+PN+oXqCKERI/F1kfn0FuoZCaSU0A4BtXcMAgFPaC1f8T56rpaBOJWSTUjkQRPaht8xF5jeUYzrKcWIkPb//tq5hMAasLKAc/mbu/+i52Pn1K+HzzPyTo3BQgsg+9Ja5yPx6zX2Rrutne9cwFjdVoqqscIdoynxeVAR8ZPkTRJ5Ab5mLCN/1kTTEn3OOrZ3DOKUI/P0A4POKtXit9yHxJ4jsQ2+Zi8yrK4fXw3Cofzzl7zyy/Th6RqdwUYHH9wuE5V/ms07zQOJPENmH3jIXCfg8WNhQgQO9qYl/NMbx/cf2YGlLFV6/Zm6Wa+cOYknHMr/1T698lvl/CIJIHRJ/l1ncXJmy+D+9txf7e8fxqcuWFU1iMzFPwW5ZxtkmfyMIInVI/F1mSXMVDvaPpxTu+ej246gq8+HyVa0u1Mxd7Cx/O5cQQRDOQOLvMoubKxGOxNA1GLLdLxrjeHznCVyyoqXIxFBr9OyuKag3DKlMCCMIYnaQ+LvMkmYtJfP+3rGkMrHE4w8ffxVLPv8w+sfDeN2pba7Wzy3sYvmF24fi/QkiexRu4HiBsnxONRgDtnYO4+IV8QientFJvPknz2JyOoq+sTA6Gitw5eo5uGxlcbl8xBLGdsIeHxQuph4PQeQXJP4uUx30Y1VbDdbvPoFPXLIUI5PT+K8n9+H/Xu1F52AIHga015fjwU+cj5qgP9fVzRp2bp+m6gBWzKnG565c7mKNCKK0IPHPAe9ctwBf/PN23PCrF1AT9OOhbccAAF+8diXefEY7ynweVBbwbF47xDC33YBv0OfFI596rTsVIogSpTgVJs9591kLEI1xfOXBHQCAf75oCT5+8dKiFXwVtm4fLw30EkS2yUhtGGNvBfBVACsBrOOcb7bY7yoAtwLwAriDc35LJuctdBhjuOHcDlSW+bC9axifuGRpQS/Kng5iUFvl9vF6GKIxDn8Kyd8IgsiMTBVnO4A3A/i51Q6MMS+A2wBcDqATwCbG2IOc850Znrvguf7Mdlx/Znuuq5ETVJa/EP9imdBGEPlMRuLPOd8FYKbVpdYB2Mc5P6Dvew+A6wCUvPiXImJum8rnL6J8/OT2IYis40b/eh6Ao9Lfnfq2JBhjNzLGNjPGNvf29rpQNcJtDvZpqS0WN1UllYlJXV5y+xBE1pnxLWOMPcEY2674d53TleGc3845X8s5X9vc3Oz04Yk84D/etBoXLGvCirbkhejFQK+PLH+CyDozun0455dleI4uAPOlv9v1bUQJcsGyZlywrBmbDg0klQnLn9I6EET2caN/vQnAMsbYIsZYAMA7ADzownmJPEY1qCu2+WwyfhIE4QwZvWWMsTcxxjoBnAPgIcbYo/r2uYyxhwGAcx4B8HEAjwLYBeD3nPMdmVWbKHS8iiABsb4vWf4EkX0yjfb5E4A/KbZ3A7hG+vthAA9nci6iuFBZ/lORGACgqarM7eoQRMlRGjOLiLxDJf5fet1KPH+gH2sX1uegRgRRWpD4EzlB5do5e3EjrjtNGQVMEITD0MgakRM8CvH300AvQbgGvW1ETlBZ/gFavIUgXIPeNiIneBTRPnaLuhME4Sz0thE5QTXgSzl9CMI9SPyJnKCazTtDgkCCIByExJ/ICWLAt5zW6SWInEDiT+SEmJ7bmRZpJ4jcQOJP5IS6igDqKvz46htW5boqBFGS0CQvIicEfB688uUrAAAt1UEc7BvLcY0IorQg8SdyzrpFDVi3qCHX1SCIkoLcPgRBECUIiT9BEEQJQuJPEARRgpD4EwRBlCAk/gRBECUIiT9BEEQJQuJPEARRgpD4EwRBlCCMc57rOihhjPUCOJzBIZoA9DlUnUKBrrn4KbXrBeia02Uh57x5pp3yVvwzhTG2mXO+Ntf1cBO65uKn1K4XoGvOFuT2IQiCKEFI/AmCIEqQYhb/23NdgRxA11z8lNr1AnTNWaFoff4EQRCENcVs+RMEQRAWFJ34M8auYoztYYztY4zdlOv6OAVjbD5jbANjbCdjbAdj7F/07Q2MsccZY3v1/+v17Ywx9mP9PmxljJ2R2yuYPYwxL2PsZcbYX/W/FzHGNurXdi9jLKBvL9P/3qeXd+Sy3rOFMVbHGLuPMbabMbaLMXZOsT9nxti/6r/r7Yyx3zHGgsX2nBljv2SM9TDGtkvb0n6ujLEb9P33MsZumG19ikr8GWNeALcBuBrAKgDvZIwVyzqBEQCf4ZyvAnA2gI/p13YTgPWc82UA1ut/A9o9WKb/uxHAT92vsmP8C4Bd0t/fAfBDzvlSAIMAPqhv/yCAQX37D/X9CpFbATzCOV8BYA20ay/a58wYmwfgkwDWcs5XA/ACeAeK7zn/GsBVpm1pPVfGWAOArwA4C8A6AF8RDUbacM6L5h+AcwA8Kv19M4Cbc12vLF3rAwAuB7AHQJu+rQ3AHv3zzwG8U9rf2K+Q/gFo11+KSwD8FQCDNvnFZ37mAB4FcI7+2afvx3J9DWleby2Ag+Z6F/NzBjAPwFEADfpz+yuAK4vxOQPoALB9ts8VwDsB/FzanrBfOv+KyvJH/Eck6NS3FRV6N/d0ABsBtHLOj+lFxwG06p+L5V78CMC/AYjpfzcCGOKcR/S/5esyrlkvH9b3LyQWAegF8Cvd1XUHY6wSRfycOeddAL4P4AiAY9Ce24so7ucsSPe5Ova8i038ix7GWBWAPwL4FOd8RC7jmilQNOFbjLHXAejhnL+Y67q4iA/AGQB+yjk/HcA44q4AAEX5nOsBXAet4ZsLoBLJ7pGix+3nWmzi3wVgvvR3u76tKGCM+aEJ/92c8/v1zScYY216eRuAHn17MdyL8wC8gTF2CMA90Fw/twKoY4z59H3k6zKuWS+vBdDvZoUdoBNAJ+d8o/73fdAag2J+zpcBOMg57+WcTwO4H9qzL+bnLEj3uTr2vItN/DcBWKZHCQSgDRo9mOM6OQJjjAH4HwC7OOf/KRU9CECM+N8AbSxAbH+vHjVwNoBhqXtZEHDOb+act3POO6A9yyc55+8GsAHA9fpu5msW9+J6ff+CspA558cBHGWMLdc3XQpgJ4r4OUNz95zNGKvQf+fimov2OUuk+1wfBXAFY6xe7zFdoW9Ln1wPgGRhQOUaAK8C2A/gC7muj4PXdT60LuFWAK/o/66B5utcD2AvgCcANOj7M2iRT/sBbIMWSZHz68jg+i8C8Ff982IALwDYB+APAMr07UH97316+eJc13uW13oagM36s/4zgPpif84AvgZgN4DtAO4CUFZszxnA76CNaUxD6+F9cDbPFcAH9GvfB+D9s60PzfAlCIIoQYrN7UMQBEGkAIk/QRBECULiTxAEUYKQ+BMEQZQgJP4EQRAlCIk/QRBECULiTxAEUYKQ+BMEQZQg/x9TspR+79tTJwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sin\n",
    "import numpy as np\n",
    "t = np.arange(1000)\n",
    "wave = np.sin(0.01 * np.pi * t)\n",
    "myrnn_model_v1 = MyRNNModelV1(maxlen=100,n_hidden=100)\n",
    "myrnn_model_v1.load_data(wave)\n",
    "myrnn_model_v1.build()\n",
    "myrnn_model_v1.train()\n",
    "myrnn_model_v1.predict(df_list=list(wave),stop=1000)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "predicted_data = myrnn_model_v1.predicted_data\n",
    "\n",
    "x = np.arange(len(predicted_data))\n",
    "plt.plot(x,predicted_data)\n",
    "plt.show()\n",
    "\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 810 samples, validate on 90 samples\n",
      "Epoch 1/500\n",
      "810/810 [==============================] - 3s 4ms/step - loss: 0.1900 - val_loss: 0.0040\n",
      "Epoch 2/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 3/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 4/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 6.9221e-04 - val_loss: 3.6355e-04\n",
      "Epoch 5/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 4.2012e-04 - val_loss: 2.3336e-04\n",
      "Epoch 6/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 2.3059e-04 - val_loss: 2.2180e-04\n",
      "Epoch 7/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 1.3168e-04 - val_loss: 1.6372e-04\n",
      "Epoch 8/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 3.8401e-04 - val_loss: 1.8854e-04\n",
      "Epoch 9/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 1.3150e-04 - val_loss: 1.5351e-04\n",
      "Epoch 10/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 7.6805e-05 - val_loss: 5.0862e-05\n",
      "Epoch 11/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 9.0869e-05 - val_loss: 1.3318e-04\n",
      "Epoch 12/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 7.1082e-05 - val_loss: 3.2162e-05\n",
      "Epoch 13/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 4.1042e-05 - val_loss: 2.6966e-05\n",
      "Epoch 14/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 4.6983e-04 - val_loss: 3.4931e-04\n",
      "Epoch 15/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 2.9216e-04 - val_loss: 9.9393e-05\n",
      "Epoch 16/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 2.8177e-04 - val_loss: 2.6828e-04\n",
      "Epoch 17/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 1.7773e-04 - val_loss: 7.4775e-05\n",
      "Epoch 18/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 2.2716e-04 - val_loss: 1.4843e-04\n",
      "Epoch 19/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 1.4530e-04 - val_loss: 1.1773e-04\n",
      "Epoch 20/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 4.0829e-05 - val_loss: 8.0189e-05\n",
      "Epoch 21/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 3.1282e-05 - val_loss: 1.9667e-05\n",
      "Epoch 22/500\n",
      "810/810 [==============================] - 3s 3ms/step - loss: 3.1122e-05 - val_loss: 1.7320e-05\n",
      "Epoch 23/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 4.7316e-05 - val_loss: 3.2760e-05\n",
      "Epoch 24/500\n",
      "810/810 [==============================] - 3s 3ms/step - loss: 2.7115e-05 - val_loss: 1.8391e-05\n",
      "Epoch 25/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 3.0677e-05 - val_loss: 2.5856e-05\n",
      "Epoch 26/500\n",
      "810/810 [==============================] - 3s 3ms/step - loss: 3.7871e-05 - val_loss: 2.1053e-05\n",
      "Epoch 27/500\n",
      "810/810 [==============================] - 3s 3ms/step - loss: 1.9992e-05 - val_loss: 1.3572e-05\n",
      "Epoch 28/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 3.0279e-05 - val_loss: 1.0686e-04\n",
      "Epoch 29/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 3.5907e-05 - val_loss: 1.0017e-05\n",
      "Epoch 30/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 3.4903e-05 - val_loss: 3.4947e-05\n",
      "Epoch 31/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 7.6201e-05 - val_loss: 3.2513e-05\n",
      "Epoch 32/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 1.3971e-04 - val_loss: 1.8669e-04\n",
      "Epoch 33/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 9.7425e-04 - val_loss: 0.0039\n",
      "Epoch 34/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 35/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 0.0014 - val_loss: 3.9719e-04\n",
      "Epoch 36/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 3.3399e-04 - val_loss: 8.7162e-05\n",
      "Epoch 37/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 3.1169e-04 - val_loss: 6.5652e-05\n",
      "Epoch 38/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 6.2040e-05 - val_loss: 2.5386e-05\n",
      "Epoch 39/500\n",
      "810/810 [==============================] - 2s 3ms/step - loss: 1.0097e-04 - val_loss: 3.1039e-05\n",
      "Epoch 00039: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DeepRNN\n",
    "# DeepRNN\n",
    "import numpy as np\n",
    "t = np.arange(1000)\n",
    "wave = np.sin(0.01 * np.pi * t)\n",
    "myrnn_model_v1 = MyDeepRNNModelV1(maxlen=100,n_hidden=30)\n",
    "myrnn_model_v1.load_data(wave)\n",
    "myrnn_model_v1.build()\n",
    "myrnn_model_v1.train()\n",
    "myrnn_model_v1.predict(df_list=list(wave),stop=1000)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "predicted_data = myrnn_model_v1.predicted_data\n",
    "\n",
    "x = np.arange(len(predicted_data))\n",
    "plt.plot(x,predicted_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib #only needed to determine Matplotlib version number\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(32,input_shape=(25,1),return_sequences=True))\n",
    "model.add(SimpleRNN(32,return_sequences=True))\n",
    "model.add(SimpleRNN(32,return_sequences=True))\n",
    "model.add(SimpleRNN(32,return_sequences=True))\n",
    "model.add(Dense(1))\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
