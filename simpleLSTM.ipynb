{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-b2e6e0648048>:66: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 0\n",
      "Step 0 Loss 0.69344735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Loss 0.5562319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 Loss 0.49225113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300 Loss 0.36813375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400 Loss 0.26165506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 Loss 0.05430108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 Loss 0.027884267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 1\n",
      "Step 0 Loss 0.62995553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Loss 0.011270922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 Loss 0.0050988616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300 Loss 0.006674574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400 Loss 0.0043556085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 Loss 0.005243041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 Loss 0.0039501013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 2\n",
      "Step 0 Loss 0.5080183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Loss 0.0031599586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 Loss 0.0018141997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300 Loss 0.0020761662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400 Loss 0.0023746705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 Loss 0.0021275813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 Loss 0.0017382387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 3\n",
      "Step 0 Loss 0.624832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Loss 0.0010763784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 Loss 0.0016332115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300 Loss 0.0011270604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400 Loss 0.0010981325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 Loss 0.0019068259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b2e6e0648048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0mbatchYHolder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatchY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mcellState\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_current_cell_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                     \u001b[0mhiddenState\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_current_hidden_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m                 })\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pylab/myvenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pylab/myvenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pylab/myvenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pylab/myvenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pylab/myvenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1319\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m~/pylab/myvenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "\"\"\"\n",
    "define all the constants\n",
    "\"\"\"\n",
    "numEpochs = 10\n",
    "seriesLength = 50000\n",
    "backpropagationLength = 15\n",
    "stateSize = 4\n",
    "numClasses = 2\n",
    "echoStep = 3\n",
    "batchSize = 5\n",
    "num_batches = seriesLength // batchSize // backpropagationLength\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "generate data\n",
    "\"\"\"\n",
    "def generateData():\n",
    "    x = np.array(np.random.choice(2, seriesLength, p=[0.5, 0.5]))\n",
    "    y = np.roll(x, echoStep)\n",
    "    y[0:echoStep] = 0\n",
    "\n",
    "    x = x.reshape((batchSize, -1))\n",
    "    y = y.reshape((batchSize, -1))\n",
    "\n",
    "    return (x, y)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "start computational graph\n",
    "\"\"\"\n",
    "batchXHolder = tf.placeholder(tf.float32, [batchSize, backpropagationLength], name=\"x_input\")\n",
    "batchYHolder = tf.placeholder(tf.int32, [batchSize, backpropagationLength], name=\"y_input\")\n",
    "\n",
    "# rnn replace\n",
    "#initState = tf.placeholder(tf.float32, [batchSize, stateSize], \"rnn_init_state\")\n",
    "\n",
    "cellState = tf.placeholder(tf.float32, [batchSize, stateSize])\n",
    "hiddenState = tf.placeholder(tf.float32, [batchSize, stateSize])\n",
    "initState = rnn.LSTMStateTuple(cellState, hiddenState)\n",
    "\n",
    "W = tf.Variable(np.random.rand(stateSize+1, stateSize), dtype=tf.float32, name=\"weight1\")\n",
    "bias1 = tf.Variable(np.zeros((1,stateSize)), dtype=tf.float32)\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(stateSize, numClasses),dtype=tf.float32, name=\"weight2\")\n",
    "bias2 = tf.Variable(np.zeros((1,numClasses)), dtype=tf.float32)\n",
    "\n",
    "tf.summary.histogram(name=\"weights\", values=W)\n",
    "\n",
    "\n",
    "# Unpack columns\n",
    "inputsSeries = tf.split(axis=1, num_or_size_splits=backpropagationLength, value=batchXHolder)\n",
    "labelsSeries = tf.unstack(batchYHolder, axis=1)\n",
    "\n",
    "# Forward passes\n",
    "\n",
    "# rnn replace\n",
    "# cell = rnn.BasicRNNCell(stateSize)\n",
    "# statesSeries, currentState = rnn.static_rnn(cell, inputsSeries, initState)\n",
    "\n",
    "cell = rnn.BasicLSTMCell(stateSize, state_is_tuple=True)\n",
    "statesSeries, currentState = rnn.static_rnn(cell, inputsSeries, initState)\n",
    "\n",
    "# calculate loss\n",
    "logits_series = [tf.matmul(state, W2) + bias2 for state in statesSeries]\n",
    "predictions_series = [tf.nn.softmax(logits) for logits in logits_series]\n",
    "\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits) for logits, labels in zip(logits_series,labelsSeries)]\n",
    "total_loss = tf.reduce_mean(losses, name=\"total_loss\")\n",
    "\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss, name=\"training\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "plot computation\n",
    "\"\"\"\n",
    "def plot(loss_list, predictions_series, batchX, batchY):\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.cla()\n",
    "    plt.plot(loss_list)\n",
    "\n",
    "    for batchSeriesIdx in range(5):\n",
    "        oneHotOutputSeries = np.array(predictions_series)[:, batchSeriesIdx, :]\n",
    "        singleOutputSeries = np.array([(1 if out[0] < 0.5 else 0) for out in oneHotOutputSeries])\n",
    "\n",
    "        plt.subplot(2, 3, batchSeriesIdx + 2)\n",
    "        plt.cla()\n",
    "        plt.axis([0, backpropagationLength, 0, 2])\n",
    "        left_offset = range(backpropagationLength)\n",
    "        plt.bar(left_offset, batchX[batchSeriesIdx, :], width=1, color=\"blue\")\n",
    "        plt.bar(left_offset, batchY[batchSeriesIdx, :] * 0.5, width=1, color=\"red\")\n",
    "        plt.bar(left_offset, singleOutputSeries * 0.3, width=1, color=\"green\")\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.0001)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "run the graph\n",
    "\"\"\"\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(\"logs\", graph=tf.get_default_graph())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    plt.ion()\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch_idx in range(numEpochs):\n",
    "        x,y = generateData()\n",
    "\n",
    "        # rnn remove\n",
    "        # _current_state = np.zeros((batchSize, stateSize))\n",
    "\n",
    "        _current_cell_state = np.zeros((batchSize, stateSize))\n",
    "        _current_hidden_state = np.zeros((batchSize, stateSize))\n",
    "\n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * backpropagationLength\n",
    "            end_idx = start_idx + backpropagationLength\n",
    "\n",
    "            batchX = x[:,start_idx:end_idx]\n",
    "            batchY = y[:,start_idx:end_idx]\n",
    "\n",
    "            _total_loss, _train_step, _current_state, _predictions_series = sess.run(\n",
    "                [total_loss, train_step, currentState, predictions_series],\n",
    "                feed_dict={\n",
    "                    batchXHolder:batchX,\n",
    "                    batchYHolder:batchY,\n",
    "                    cellState: _current_cell_state,\n",
    "                    hiddenState: _current_hidden_state\n",
    "                })\n",
    "\n",
    "            _current_cell_state, _current_hidden_state = _current_state\n",
    "\n",
    "            loss_list.append(_total_loss)\n",
    "\n",
    "            # fix the cost summary later\n",
    "            tf.summary.scalar(name=\"totalloss\", tensor=_total_loss)\n",
    "\n",
    "            if batch_idx%100 == 0:\n",
    "                print(\"Step\",batch_idx, \"Loss\", _total_loss)\n",
    "                plot(loss_list, _predictions_series, batchX, batchY)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 14,  2,  5, 19, 15,  9, 16, 18,  1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(np.arange(20))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  3,  0,  5,  0,  7])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = np.array([10,3,4,5,6,7])\n",
    "sample_data[np.array([2,4])] = 0\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(np.arange(3))[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a8667782c469>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "sample_data[np.random.permutation(np.arange(3))[:2]]= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(10)\n",
    "indices = np.random.permutation(np.arange(10))[:2]\n",
    "mask[indices] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0. 100.   1. 100.   0.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "mask[np.array([2,4])] = 100\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = np.random.uniform(low=0.0, high=1.0, size=(10,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45324177 0.39524983 0.66662199 0.50177989 0.88715725 0.59072731\n",
      "  0.5058612  0.91245671 0.05789386 0.9456987  0.5337271  0.46340839\n",
      "  0.10770084 0.75555994 0.80571872 0.73744444 0.91039156 0.43462645\n",
      "  0.48423017 0.13484443 0.95240136 0.71414801 0.19982145 0.4350095\n",
      "  0.67460294 0.47264362 0.92360068 0.91862431 0.99873758 0.18765307\n",
      "  0.05547406 0.37856128 0.38905897 0.80372172 0.13466623 0.52235018\n",
      "  0.62078519 0.41700153 0.18860545 0.36424287 0.76518253 0.79549792\n",
      "  0.40671591 0.65911169 0.50007392 0.17337722 0.92839697 0.54140628\n",
      "  0.91461166 0.39021597 0.46729536 0.76714563 0.49514301 0.5373988\n",
      "  0.09532923 0.72800938 0.85036218 0.49794856 0.89099277 0.27214015\n",
      "  0.81174906 0.26698658 0.5632097  0.7333262  0.40407986 0.49445847\n",
      "  0.93025618 0.53776366 0.66344353 0.53544005 0.97100923 0.59238622\n",
      "  0.28314594 0.9465687  0.85864679 0.34161472 0.21179968 0.25955219\n",
      "  0.49075958 0.26349919 0.71779037 0.74089657 0.15568176 0.23110257\n",
      "  0.18727243 0.61685824 0.88908788 0.20414685 0.26672538 0.20974731\n",
      "  0.06228499 0.27916102 0.30900266 0.07727431 0.6454684  0.98322437\n",
      "  0.69941723 0.2682276  0.93089168 0.7287367 ]\n",
      " [0.23613582 0.20761292 0.8208386  0.56289098 0.22986851 0.0348684\n",
      "  0.7411428  0.71905515 0.34805191 0.23873581 0.34170354 0.91740038\n",
      "  0.5743288  0.31754221 0.54261992 0.45595537 0.15670212 0.56222962\n",
      "  0.63996841 0.89821304 0.93152907 0.19220861 0.59824584 0.54695142\n",
      "  0.35471422 0.12522144 0.44058163 0.08278223 0.01196764 0.09035405\n",
      "  0.59388785 0.2156364  0.86027968 0.85144435 0.13104106 0.81083802\n",
      "  0.88634603 0.91835999 0.45604272 0.51302701 0.77960297 0.82891738\n",
      "  0.99706814 0.64103129 0.80789302 0.27425775 0.23406824 0.00131081\n",
      "  0.35592878 0.37865494 0.6550962  0.14448722 0.57402966 0.25086506\n",
      "  0.3065037  0.84696573 0.13661345 0.97791345 0.24270902 0.62692477\n",
      "  0.83237732 0.67320182 0.62546989 0.42815229 0.66080532 0.55227579\n",
      "  0.13276158 0.28402075 0.63923386 0.8697453  0.62921311 0.06641504\n",
      "  0.03194004 0.84150983 0.02442793 0.39483026 0.56990875 0.79847679\n",
      "  0.8458896  0.58033001 0.30309042 0.31714341 0.72625745 0.60091402\n",
      "  0.36718295 0.79644388 0.25902061 0.98854193 0.51705633 0.21649083\n",
      "  0.61301629 0.73985058 0.02573542 0.52680712 0.70090975 0.35953452\n",
      "  0.50366521 0.92590843 0.92844725 0.53431103]\n",
      " [0.32265017 0.83185992 0.42942032 0.73756273 0.72788413 0.76801331\n",
      "  0.01759197 0.69615628 0.59391938 0.54907385 0.86900995 0.41599533\n",
      "  0.51040884 0.12185141 0.2805551  0.28380731 0.72278952 0.02137585\n",
      "  0.56153924 0.77456156 0.08623597 0.63129382 0.03169271 0.67818361\n",
      "  0.55530747 0.95910779 0.9409746  0.98379942 0.2856584  0.40666558\n",
      "  0.76429192 0.23040785 0.95764525 0.2719504  0.84373735 0.08731787\n",
      "  0.49883979 0.41633641 0.86765065 0.29941653 0.26940788 0.8630046\n",
      "  0.0497839  0.41065099 0.71774295 0.28226658 0.04044828 0.25027894\n",
      "  0.93776507 0.81712777 0.00299734 0.70618578 0.19630477 0.14885347\n",
      "  0.62235892 0.26552626 0.08273056 0.72424882 0.51092108 0.47667039\n",
      "  0.70428281 0.54308    0.14051838 0.48879552 0.97743498 0.00654059\n",
      "  0.10911562 0.95125891 0.17320692 0.70757716 0.25089137 0.05808855\n",
      "  0.27321376 0.63906974 0.67890898 0.08397712 0.97186325 0.30418657\n",
      "  0.97207486 0.19777245 0.41702124 0.3829873  0.4513288  0.02457004\n",
      "  0.40469242 0.47506132 0.8081737  0.03243191 0.65797741 0.19658642\n",
      "  0.53375669 0.80472729 0.68428834 0.79160347 0.66950089 0.32590779\n",
      "  0.88204459 0.22689828 0.01646961 0.78014193]\n",
      " [0.87737142 0.14550658 0.40355572 0.8556548  0.78415767 0.51032614\n",
      "  0.23264236 0.49338328 0.59827348 0.35427987 0.71812148 0.33117679\n",
      "  0.91852481 0.81561054 0.45231838 0.36379406 0.76951376 0.22908258\n",
      "  0.14628216 0.21785135 0.2441869  0.6884342  0.47356245 0.50438492\n",
      "  0.59408706 0.28145003 0.20463907 0.43496039 0.3916046  0.46175669\n",
      "  0.42341741 0.92731891 0.21588023 0.78755482 0.40445075 0.19258483\n",
      "  0.29118376 0.89471874 0.33538929 0.22125946 0.33829694 0.03757314\n",
      "  0.25324075 0.48977667 0.64756187 0.8666748  0.4886914  0.21102939\n",
      "  0.73178243 0.02674938 0.40702799 0.56654625 0.26715776 0.28873563\n",
      "  0.97548752 0.8911559  0.0302144  0.90494987 0.27299026 0.99093845\n",
      "  0.97312816 0.01587059 0.41929465 0.76787485 0.88790012 0.80132749\n",
      "  0.82146203 0.04740438 0.87155841 0.74455907 0.38641734 0.28549907\n",
      "  0.12899677 0.87838811 0.43152122 0.7757016  0.42946632 0.43323663\n",
      "  0.53370443 0.34630188 0.22463212 0.68741352 0.48897148 0.1080154\n",
      "  0.49783529 0.4004421  0.85129135 0.37278074 0.29030382 0.17843962\n",
      "  0.69946159 0.83851041 0.14144449 0.28499449 0.03692738 0.64062377\n",
      "  0.01656016 0.03205526 0.39346449 0.3759822 ]\n",
      " [0.50596466 0.8866624  0.26142817 0.48580951 0.70915428 0.35459796\n",
      "  0.4842585  0.42646971 0.43802943 0.79461677 0.89510062 0.53184217\n",
      "  0.7591666  0.8821236  0.99001819 0.00986227 0.89370683 0.16618031\n",
      "  0.14814228 0.64501047 0.63327255 0.63449679 0.66500353 0.30735134\n",
      "  0.66876745 0.19885119 0.54104164 0.67776127 0.87973704 0.70944708\n",
      "  0.96254148 0.68527867 0.10519186 0.55170354 0.550955   0.36284311\n",
      "  0.69936582 0.8523869  0.77023722 0.840268   0.40660578 0.35893293\n",
      "  0.04309937 0.30815937 0.88381901 0.47535524 0.62065974 0.8157871\n",
      "  0.58829402 0.3205177  0.3824994  0.64275561 0.66748545 0.31909266\n",
      "  0.24543846 0.01011612 0.97056409 0.78561423 0.90936411 0.13294696\n",
      "  0.32768481 0.44660752 0.83435473 0.12895267 0.34959053 0.53551858\n",
      "  0.25397722 0.01660351 0.7332229  0.66920262 0.76746565 0.23099782\n",
      "  0.33541755 0.36175477 0.99230394 0.61781712 0.19505163 0.47076483\n",
      "  0.6514933  0.60991859 0.92497044 0.35190232 0.6789748  0.56541333\n",
      "  0.37316394 0.61640525 0.32545022 0.35421513 0.56760869 0.09622573\n",
      "  0.51902799 0.43533447 0.04029765 0.98696932 0.4469132  0.57535378\n",
      "  0.7827527  0.37869056 0.29284958 0.89048416]\n",
      " [0.85567808 0.88639104 0.0522589  0.70453438 0.68405458 0.13587731\n",
      "  0.74459119 0.72867206 0.86549282 0.73606439 0.35305731 0.64260552\n",
      "  0.00199955 0.62250275 0.6021851  0.33920435 0.30662771 0.50727806\n",
      "  0.02325722 0.56490278 0.51178989 0.03305472 0.5672836  0.79942233\n",
      "  0.4470622  0.06869543 0.19819284 0.1857793  0.02517513 0.07159134\n",
      "  0.86082277 0.22671362 0.1236726  0.14193897 0.10970271 0.08767196\n",
      "  0.17300428 0.66129045 0.14480903 0.27481968 0.93663387 0.61040293\n",
      "  0.07099968 0.92102356 0.11492083 0.00679178 0.41388355 0.71774594\n",
      "  0.2935005  0.60522584 0.01712654 0.53780805 0.47083356 0.48421434\n",
      "  0.66084601 0.5889181  0.59365332 0.149003   0.25723721 0.00848395\n",
      "  0.84725146 0.68744139 0.47820814 0.6294206  0.27667458 0.45008801\n",
      "  0.47149126 0.98095268 0.73550928 0.87863997 0.00768213 0.62413075\n",
      "  0.13239834 0.87644102 0.39131949 0.09461741 0.31450565 0.66965744\n",
      "  0.64316836 0.15825649 0.56990488 0.39359084 0.04343979 0.53726183\n",
      "  0.66982851 0.11886205 0.62049761 0.87948565 0.56569693 0.8756859\n",
      "  0.12965775 0.2518394  0.52703012 0.58274346 0.18520651 0.1079998\n",
      "  0.00199039 0.43852814 0.69127928 0.57909127]\n",
      " [0.64658315 0.74454786 0.55471176 0.30004281 0.42729304 0.89084706\n",
      "  0.5768436  0.55828744 0.58916925 0.15051497 0.77230605 0.63240888\n",
      "  0.41293896 0.16988809 0.7115048  0.43905531 0.83063281 0.86310228\n",
      "  0.32045437 0.45773503 0.96048174 0.22507015 0.70859961 0.28351162\n",
      "  0.39984581 0.15851911 0.52498284 0.44383133 0.30875404 0.99511418\n",
      "  0.31487222 0.95273095 0.09790234 0.62206208 0.75307904 0.07187211\n",
      "  0.46479758 0.0055251  0.38500921 0.00511714 0.40047923 0.7443765\n",
      "  0.19920023 0.1884181  0.94201556 0.02779382 0.52452997 0.4582084\n",
      "  0.52585963 0.58444406 0.11954835 0.50905763 0.12528803 0.09968793\n",
      "  0.28854974 0.90052759 0.55039507 0.98896571 0.64537157 0.64056548\n",
      "  0.23005146 0.80410657 0.78194345 0.87849737 0.6319503  0.5209032\n",
      "  0.66781959 0.50839006 0.13645287 0.09550276 0.77380929 0.06218262\n",
      "  0.33767982 0.08210882 0.68719115 0.44936617 0.45962911 0.39508729\n",
      "  0.04025086 0.54311139 0.71339837 0.08289416 0.50858261 0.41597579\n",
      "  0.82764892 0.30668654 0.28393188 0.40174922 0.7304195  0.72779093\n",
      "  0.55365549 0.52391357 0.07474726 0.82957922 0.99391412 0.81402826\n",
      "  0.75418504 0.09305754 0.85316513 0.49846456]\n",
      " [0.10253719 0.23924329 0.16516955 0.47033886 0.93309775 0.63475416\n",
      "  0.07787512 0.11701201 0.44388997 0.89287619 0.19737936 0.22073969\n",
      "  0.50736666 0.5793602  0.45747803 0.92803566 0.91423035 0.0738932\n",
      "  0.74121517 0.40795786 0.90131695 0.38222646 0.56869072 0.3970424\n",
      "  0.32882014 0.33896618 0.34015717 0.18052254 0.96056807 0.09742943\n",
      "  0.93113208 0.29279275 0.08082821 0.07039688 0.8828612  0.31134955\n",
      "  0.99323961 0.94521758 0.75858789 0.94566023 0.64563909 0.6845204\n",
      "  0.14309852 0.6991597  0.81186424 0.20847078 0.88313485 0.99410811\n",
      "  0.87404671 0.80900234 0.70539795 0.2427735  0.40575839 0.97034299\n",
      "  0.1591166  0.47236961 0.23795829 0.54592676 0.58380604 0.43406955\n",
      "  0.77508632 0.71580909 0.54885739 0.46974314 0.73947001 0.45087907\n",
      "  0.07197881 0.47387497 0.70151877 0.82705771 0.9685898  0.10114906\n",
      "  0.17719596 0.5611447  0.87293213 0.16953862 0.46738101 0.07686539\n",
      "  0.49564362 0.07571512 0.61286367 0.27947025 0.45556531 0.38077024\n",
      "  0.10064906 0.68867149 0.80541886 0.85337499 0.76669112 0.75749379\n",
      "  0.22735965 0.3150603  0.41760025 0.21313677 0.07140652 0.07405771\n",
      "  0.88053975 0.53784122 0.76912922 0.08712312]\n",
      " [0.72282415 0.66597619 0.40757728 0.06452864 0.37273485 0.57109357\n",
      "  0.9806741  0.36761278 0.22691978 0.21551322 0.31004763 0.36176148\n",
      "  0.34991863 0.03494175 0.66222535 0.48595151 0.2288458  0.13380348\n",
      "  0.26509984 0.393155   0.84577421 0.5031301  0.90839521 0.96693611\n",
      "  0.59605657 0.54720188 0.68350809 0.66134352 0.69580514 0.24332062\n",
      "  0.04247727 0.08873759 0.46264511 0.16599489 0.74455724 0.85701768\n",
      "  0.62093181 0.63501504 0.25391545 0.83542634 0.58208882 0.64277222\n",
      "  0.57295072 0.58206157 0.81624031 0.36708457 0.1887527  0.79525497\n",
      "  0.58827638 0.72949453 0.70648716 0.16167815 0.1694934  0.53853174\n",
      "  0.7184416  0.69922615 0.29140532 0.47677567 0.53356837 0.68575245\n",
      "  0.15126083 0.67954307 0.05300261 0.23549784 0.3486054  0.01038388\n",
      "  0.48118983 0.12818286 0.74808656 0.87066067 0.87677427 0.1264275\n",
      "  0.86351414 0.69883436 0.91864744 0.25490724 0.16927523 0.09553563\n",
      "  0.49289455 0.05193516 0.57144331 0.860163   0.78961407 0.89809572\n",
      "  0.59312224 0.953694   0.02070003 0.69534456 0.60348165 0.87535793\n",
      "  0.79405328 0.21704507 0.47690535 0.31081116 0.42717883 0.34499163\n",
      "  0.99756112 0.15236318 0.8547084  0.4458349 ]\n",
      " [0.29390355 0.23725318 0.53482908 0.99715978 0.34581605 0.9920597\n",
      "  0.57155669 0.66958148 0.58854452 0.09443754 0.16741769 0.85953558\n",
      "  0.9649925  0.58339898 0.85648491 0.91229222 0.35733053 0.53720242\n",
      "  0.15869746 0.68944128 0.98421597 0.66145688 0.58648881 0.19639528\n",
      "  0.32520636 0.06713324 0.68769398 0.51480739 0.53269751 0.21603025\n",
      "  0.19451426 0.1379103  0.4278757  0.97191409 0.3223899  0.33621769\n",
      "  0.01256205 0.08237444 0.60215652 0.25939579 0.72558202 0.84570008\n",
      "  0.43028012 0.03158781 0.28488123 0.93536379 0.7412806  0.56215103\n",
      "  0.796534   0.47212364 0.51148011 0.97479145 0.27520002 0.50646588\n",
      "  0.10257367 0.04845175 0.33648285 0.50812775 0.48050582 0.84157748\n",
      "  0.72078933 0.0840385  0.15630385 0.13802318 0.71851361 0.14625826\n",
      "  0.38686609 0.49823471 0.03648811 0.07646782 0.76762678 0.23262776\n",
      "  0.90738963 0.2903435  0.03248152 0.59426139 0.67854541 0.73334629\n",
      "  0.21195615 0.07902318 0.79723116 0.67701413 0.98868728 0.11860637\n",
      "  0.09921234 0.691977   0.77352676 0.14821129 0.48262417 0.25675363\n",
      "  0.91418243 0.29936008 0.80371705 0.56276047 0.08193013 0.3513401\n",
      "  0.88787986 0.03745875 0.59268634 0.51493338]]\n"
     ]
    }
   ],
   "source": [
    "print(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.arange(0,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
